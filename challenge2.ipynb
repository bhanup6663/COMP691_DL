{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhanup6663/COMP691_DL/blob/main/challenge2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L8mstr8fACDr"
      },
      "outputs": [],
      "source": [
        "#Cell 1\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Prepare Training and Validation Data\n",
        "def prepare_data(random_classes=True, num_classes=2, samples_per_class=25, val_samples_per_class=5, seed=None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    full_train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    if random_classes:\n",
        "        selected_classes = np.random.choice(range(10), num_classes, replace=False)\n",
        "    else:\n",
        "        selected_classes = np.arange(num_classes)\n",
        "\n",
        "    class_indices = [i for i in range(len(full_train_set)) if full_train_set.targets[i] in selected_classes]\n",
        "    train_indices = []\n",
        "    val_indices = []\n",
        "\n",
        "    for cls in selected_classes:\n",
        "        cls_indices = [i for i in class_indices if full_train_set.targets[i] == cls]\n",
        "        np.random.shuffle(cls_indices)\n",
        "        train_indices.extend(cls_indices[val_samples_per_class:])\n",
        "        val_indices.extend(cls_indices[:val_samples_per_class])\n",
        "\n",
        "    class RemappedSubset(torch.utils.data.Dataset):\n",
        "        def __init__(self, dataset, indices, target_transform=None):\n",
        "            self.dataset = dataset\n",
        "            self.indices = indices\n",
        "            self.target_transform = target_transform\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            img, target = self.dataset[self.indices[idx]]\n",
        "            if self.target_transform:\n",
        "                target = self.target_transform(target)\n",
        "            return img, target\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.indices)\n",
        "\n",
        "    target_transform = lambda x: selected_classes.tolist().index(x)\n",
        "    train_subset = RemappedSubset(full_train_set, train_indices, target_transform=target_transform)\n",
        "    val_subset = RemappedSubset(full_train_set, val_indices, target_transform=target_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_subset, batch_size=10, shuffle=True)\n",
        "    val_loader = DataLoader(val_subset, batch_size=10, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, selected_classes\n",
        "\n",
        "train_loader, val_loader, classes_used = prepare_data(seed=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBs7GScqpqgk",
        "outputId": "f43c85f8-95f4-41a0-cea9-4d3789fbc3ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 13008644.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 3\n",
        "def load_model():\n",
        "    model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = load_model()\n"
      ],
      "metadata": {
        "id": "XV0OR1gOAQyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e505b71f-f090-4987-a304-74d5bbb8f247"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 107MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Training the Model with Validation Reporting\n",
        "def train_model_with_validation(model, train_loader, val_loader, epochs=10, print_interval=2):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "    best_val_acc = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
        "\n",
        "        for batch, (inputs, labels) in enumerate(train_loader, 1):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Print for the first and last batch of each epoch only\n",
        "            if batch == 1 or batch == len(train_loader):\n",
        "                print(f'Epoch {epoch+1}, Batch {batch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_acc = train_correct / train_total\n",
        "\n",
        "        # Validation phase\n",
        "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = val_correct / val_total\n",
        "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc*100:.2f}%')\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            print(f\"New best model found at Epoch {epoch+1} with Validation Accuracy {best_val_acc*100:.2f}%.\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    return model\n",
        "\n",
        "model = train_model_with_validation(model, train_loader, val_loader, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCSoLi22p-VE",
        "outputId": "43c53919-0dd1-4414-88c3-935346d5e34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 1, Loss: 0.7634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Prepare Filtered Test Data with Corrected Class Mapping\n",
        "def prepare_filtered_test_data(classes_used, seed=None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "    class_indices = [i for i in range(len(test_set)) if test_set.targets[i] in classes_used]\n",
        "\n",
        "    class RemappedSubset(torch.utils.data.Dataset):\n",
        "        def __init__(self, dataset, indices, target_transform=None):\n",
        "            self.dataset = dataset\n",
        "            self.indices = indices\n",
        "            self.target_transform = target_transform\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            img, target = self.dataset[self.indices[idx]]\n",
        "            if self.target_transform:\n",
        "                target = self.target_transform(target)\n",
        "            return img, target\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.indices)\n",
        "\n",
        "    if isinstance(classes_used, np.ndarray):\n",
        "        classes_used = classes_used.tolist()\n",
        "\n",
        "    target_transform = lambda x: classes_used.index(x) if x in classes_used else -1\n",
        "    remapped_test_subset = RemappedSubset(test_set, class_indices, target_transform=target_transform)\n",
        "    test_loader = DataLoader(remapped_test_subset, batch_size=10, shuffle=False)\n",
        "\n",
        "    return test_loader\n",
        "\n",
        "test_loader = prepare_filtered_test_data(classes_used)\n"
      ],
      "metadata": {
        "id": "PW3ydGwtAZYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Evaluate Model with Confusion Matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_loader, class_indices):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "    class_labels = [classes[i] for i in class_indices]\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the model on the test images: {accuracy:.2f}%')\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_predictions, labels=class_indices)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "evaluate_model_with_confusion_matrix(model, test_loader, classes_used)\n"
      ],
      "metadata": {
        "id": "h9bWzlGmA-q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 7\n",
        "def show_misclassified_images(model, test_loader, classes):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    misclassified = []\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            wrong_indices = predicted != labels\n",
        "            if any(wrong_indices):\n",
        "                wrong_images = images[wrong_indices].cpu()\n",
        "                wrong_labels = labels[wrong_indices].cpu()\n",
        "                wrong_preds = predicted[wrong_indices].cpu()\n",
        "                misclassified.extend([(img, pred, true) for img, pred, true in zip(wrong_images, wrong_preds, wrong_labels)])\n",
        "            if len(misclassified) >= 10:\n",
        "                break\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i, (img, pred, true) in enumerate(misclassified[:10]):\n",
        "        img = img.numpy().transpose((1, 2, 0))\n",
        "        mean = np.array([0.5, 0.5, 0.5])\n",
        "        std = np.array([0.5, 0.5, 0.5])\n",
        "        img = std * img + mean\n",
        "        img = np.clip(img, 0, 1)\n",
        "        plt.subplot(5, 2, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'True: {classes[true]}, Pred: {classes[pred]}')\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "show_misclassified_images(model, test_loader, classes)\n"
      ],
      "metadata": {
        "id": "lGuTuXQDF7Mu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}