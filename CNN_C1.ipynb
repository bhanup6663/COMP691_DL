{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset,DataLoader, Subset, random_split\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.subset[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 6]\n"
     ]
    }
   ],
   "source": [
    "selected_classes = np.random.choice(range(10), 2, replace=False)\n",
    "print(selected_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),  \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_accuracy = 0\n",
    "best_model_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, targets) in enumerate(val_loader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 1.8708, Train Acc: 32.50%, Val Loss: 8.1884, Val Acc: 60.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 0.8780, Train Acc: 62.50%, Val Loss: 2.5252, Val Acc: 60.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 0.6694, Train Acc: 72.50%, Val Loss: 1.7510, Val Acc: 60.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 0.6435, Train Acc: 82.50%, Val Loss: 0.5807, Val Acc: 70.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 1.0180, Train Acc: 80.00%, Val Loss: 0.8558, Val Acc: 50.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 0.6822, Train Acc: 77.50%, Val Loss: 0.3431, Val Acc: 90.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 0.5907, Train Acc: 75.00%, Val Loss: 0.4559, Val Acc: 70.00%\n",
      "Starting epoch 8\n",
      "Train Loss: 0.6336, Train Acc: 77.50%, Val Loss: 2.2122, Val Acc: 40.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 0.7365, Train Acc: 77.50%, Val Loss: 0.2916, Val Acc: 100.00%\n",
      "Starting epoch 10\n",
      "Train Loss: 0.4762, Train Acc: 80.00%, Val Loss: 0.5386, Val Acc: 70.00%\n",
      "Starting epoch 11\n",
      "Train Loss: 0.4563, Train Acc: 87.50%, Val Loss: 0.5727, Val Acc: 70.00%\n",
      "Starting epoch 12\n",
      "Train Loss: 0.3142, Train Acc: 85.00%, Val Loss: 0.5497, Val Acc: 70.00%\n",
      "Starting epoch 13\n",
      "Train Loss: 0.5299, Train Acc: 77.50%, Val Loss: 0.3712, Val Acc: 70.00%\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 14\n",
      "Train Loss: 0.3284, Train Acc: 80.00%, Val Loss: 0.3519, Val Acc: 80.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.4468, Train Acc: 80.00%, Val Loss: 0.3599, Val Acc: 80.00%\n",
      "Starting epoch 16\n",
      "Train Loss: 0.2960, Train Acc: 82.50%, Val Loss: 0.3110, Val Acc: 80.00%\n",
      "Starting epoch 17\n",
      "Train Loss: 0.7212, Train Acc: 70.00%, Val Loss: 0.2967, Val Acc: 80.00%\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 18\n",
      "Train Loss: 0.7053, Train Acc: 80.00%, Val Loss: 0.2146, Val Acc: 90.00%\n",
      "Starting epoch 19\n",
      "Train Loss: 0.2800, Train Acc: 87.50%, Val Loss: 0.1706, Val Acc: 90.00%\n",
      "Starting epoch 20\n",
      "Train Loss: 0.2609, Train Acc: 90.00%, Val Loss: 0.1622, Val Acc: 100.00%\n",
      "Starting epoch 21\n",
      "Train Loss: 0.2400, Train Acc: 90.00%, Val Loss: 0.1568, Val Acc: 100.00%\n",
      "Starting epoch 22\n",
      "Train Loss: 0.3158, Train Acc: 87.50%, Val Loss: 0.1546, Val Acc: 100.00%\n",
      "Starting epoch 23\n",
      "Train Loss: 0.3242, Train Acc: 85.00%, Val Loss: 0.1419, Val Acc: 100.00%\n",
      "Starting epoch 24\n",
      "Train Loss: 0.5077, Train Acc: 85.00%, Val Loss: 0.1393, Val Acc: 100.00%\n",
      "Starting epoch 25\n",
      "Train Loss: 0.5568, Train Acc: 77.50%, Val Loss: 0.1377, Val Acc: 100.00%\n",
      "Starting epoch 26\n",
      "Train Loss: 0.3522, Train Acc: 92.50%, Val Loss: 0.1420, Val Acc: 100.00%\n",
      "Starting epoch 27\n",
      "Train Loss: 0.6485, Train Acc: 75.00%, Val Loss: 0.1569, Val Acc: 90.00%\n",
      "Starting epoch 28\n",
      "Train Loss: 0.2640, Train Acc: 90.00%, Val Loss: 0.1592, Val Acc: 90.00%\n",
      "Starting epoch 29\n",
      "Train Loss: 0.2609, Train Acc: 92.50%, Val Loss: 0.1523, Val Acc: 100.00%\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 30\n",
      "Train Loss: 0.4968, Train Acc: 82.50%, Val Loss: 0.1339, Val Acc: 100.00%\n",
      "Starting epoch 31\n",
      "Train Loss: 0.7101, Train Acc: 75.00%, Val Loss: 0.1125, Val Acc: 100.00%\n",
      "Starting epoch 32\n",
      "Train Loss: 0.4506, Train Acc: 82.50%, Val Loss: 0.1065, Val Acc: 100.00%\n",
      "Starting epoch 33\n",
      "Train Loss: 0.5192, Train Acc: 85.00%, Val Loss: 0.1017, Val Acc: 100.00%\n",
      "Starting epoch 34\n",
      "Train Loss: 0.2690, Train Acc: 87.50%, Val Loss: 0.1184, Val Acc: 100.00%\n",
      "Starting epoch 35\n",
      "Train Loss: 0.3032, Train Acc: 85.00%, Val Loss: 0.1092, Val Acc: 100.00%\n",
      "Starting epoch 36\n",
      "Train Loss: 0.4983, Train Acc: 85.00%, Val Loss: 0.1050, Val Acc: 100.00%\n",
      "Starting epoch 37\n",
      "Train Loss: 0.2295, Train Acc: 92.50%, Val Loss: 0.1088, Val Acc: 100.00%\n",
      "Epoch 00037: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 38\n",
      "Train Loss: 0.5075, Train Acc: 82.50%, Val Loss: 0.1055, Val Acc: 100.00%\n",
      "Starting epoch 39\n",
      "Train Loss: 0.3467, Train Acc: 85.00%, Val Loss: 0.1083, Val Acc: 100.00%\n",
      "Starting epoch 40\n",
      "Train Loss: 0.3813, Train Acc: 85.00%, Val Loss: 0.1097, Val Acc: 100.00%\n",
      "Starting epoch 41\n",
      "Train Loss: 0.4141, Train Acc: 90.00%, Val Loss: 0.1166, Val Acc: 100.00%\n",
      "Epoch 00041: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 42\n",
      "Train Loss: 0.2332, Train Acc: 87.50%, Val Loss: 0.1169, Val Acc: 100.00%\n",
      "Starting epoch 43\n",
      "Train Loss: 0.3076, Train Acc: 87.50%, Val Loss: 0.1106, Val Acc: 100.00%\n",
      "Starting epoch 44\n",
      "Train Loss: 0.3382, Train Acc: 90.00%, Val Loss: 0.1106, Val Acc: 100.00%\n",
      "Starting epoch 45\n",
      "Train Loss: 0.4039, Train Acc: 82.50%, Val Loss: 0.1098, Val Acc: 100.00%\n",
      "Epoch 00045: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 46\n",
      "Train Loss: 0.5339, Train Acc: 82.50%, Val Loss: 0.1054, Val Acc: 100.00%\n",
      "Starting epoch 47\n",
      "Train Loss: 0.2739, Train Acc: 85.00%, Val Loss: 0.1074, Val Acc: 100.00%\n",
      "Starting epoch 48\n",
      "Train Loss: 0.2870, Train Acc: 92.50%, Val Loss: 0.1075, Val Acc: 100.00%\n",
      "Starting epoch 49\n",
      "Train Loss: 0.2373, Train Acc: 87.50%, Val Loss: 0.1196, Val Acc: 100.00%\n",
      "Starting epoch 50\n",
      "Train Loss: 0.3827, Train Acc: 85.00%, Val Loss: 0.1203, Val Acc: 100.00%\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 1.0996, Train Acc: 60.00%, Val Loss: 7.3972, Val Acc: 60.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 0.4622, Train Acc: 90.00%, Val Loss: 1.0569, Val Acc: 80.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 1.3462, Train Acc: 75.00%, Val Loss: 2.5668, Val Acc: 70.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 1.1141, Train Acc: 72.50%, Val Loss: 5.5628, Val Acc: 70.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 1.2434, Train Acc: 72.50%, Val Loss: 0.7724, Val Acc: 80.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 0.5260, Train Acc: 82.50%, Val Loss: 0.5572, Val Acc: 70.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 0.8102, Train Acc: 62.50%, Val Loss: 0.4113, Val Acc: 70.00%\n",
      "Starting epoch 8\n",
      "Train Loss: 0.4119, Train Acc: 82.50%, Val Loss: 0.5043, Val Acc: 80.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 0.5126, Train Acc: 82.50%, Val Loss: 0.5049, Val Acc: 80.00%\n",
      "Starting epoch 10\n",
      "Train Loss: 0.4876, Train Acc: 85.00%, Val Loss: 0.4789, Val Acc: 70.00%\n",
      "Starting epoch 11\n",
      "Train Loss: 0.5991, Train Acc: 75.00%, Val Loss: 0.4526, Val Acc: 60.00%\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 12\n",
      "Train Loss: 0.7031, Train Acc: 80.00%, Val Loss: 0.4451, Val Acc: 60.00%\n",
      "Starting epoch 13\n",
      "Train Loss: 0.5518, Train Acc: 72.50%, Val Loss: 0.4479, Val Acc: 60.00%\n",
      "Starting epoch 14\n",
      "Train Loss: 0.6674, Train Acc: 80.00%, Val Loss: 0.4319, Val Acc: 70.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.6082, Train Acc: 75.00%, Val Loss: 0.3867, Val Acc: 70.00%\n",
      "Starting epoch 16\n",
      "Train Loss: 0.3746, Train Acc: 85.00%, Val Loss: 0.3855, Val Acc: 70.00%\n",
      "Starting epoch 17\n",
      "Train Loss: 0.4994, Train Acc: 82.50%, Val Loss: 0.3867, Val Acc: 80.00%\n",
      "Starting epoch 18\n",
      "Train Loss: 0.7873, Train Acc: 77.50%, Val Loss: 0.3822, Val Acc: 80.00%\n",
      "Starting epoch 19\n",
      "Train Loss: 0.4085, Train Acc: 82.50%, Val Loss: 0.3529, Val Acc: 80.00%\n",
      "Starting epoch 20\n",
      "Train Loss: 0.5019, Train Acc: 75.00%, Val Loss: 0.3502, Val Acc: 80.00%\n",
      "Starting epoch 21\n",
      "Train Loss: 0.3814, Train Acc: 85.00%, Val Loss: 0.3283, Val Acc: 80.00%\n",
      "Starting epoch 22\n",
      "Train Loss: 0.3777, Train Acc: 80.00%, Val Loss: 0.3113, Val Acc: 80.00%\n",
      "Starting epoch 23\n",
      "Train Loss: 0.6209, Train Acc: 80.00%, Val Loss: 0.2819, Val Acc: 80.00%\n",
      "Starting epoch 24\n",
      "Train Loss: 0.3884, Train Acc: 85.00%, Val Loss: 0.2913, Val Acc: 80.00%\n",
      "Starting epoch 25\n",
      "Train Loss: 0.3649, Train Acc: 80.00%, Val Loss: 0.2855, Val Acc: 80.00%\n",
      "Starting epoch 26\n",
      "Train Loss: 0.2757, Train Acc: 90.00%, Val Loss: 0.2867, Val Acc: 80.00%\n",
      "Starting epoch 27\n",
      "Train Loss: 0.1688, Train Acc: 92.50%, Val Loss: 0.2463, Val Acc: 90.00%\n",
      "Starting epoch 28\n",
      "Train Loss: 0.6094, Train Acc: 80.00%, Val Loss: 0.2460, Val Acc: 80.00%\n",
      "Starting epoch 29\n",
      "Train Loss: 0.5579, Train Acc: 85.00%, Val Loss: 0.2491, Val Acc: 80.00%\n",
      "Starting epoch 30\n",
      "Train Loss: 0.4073, Train Acc: 80.00%, Val Loss: 0.2540, Val Acc: 80.00%\n",
      "Starting epoch 31\n",
      "Train Loss: 0.2764, Train Acc: 85.00%, Val Loss: 0.2003, Val Acc: 100.00%\n",
      "Starting epoch 32\n",
      "Train Loss: 0.4603, Train Acc: 80.00%, Val Loss: 0.1736, Val Acc: 100.00%\n",
      "Starting epoch 33\n",
      "Train Loss: 0.2109, Train Acc: 87.50%, Val Loss: 0.1699, Val Acc: 100.00%\n",
      "Starting epoch 34\n",
      "Train Loss: 0.3871, Train Acc: 87.50%, Val Loss: 0.1414, Val Acc: 100.00%\n",
      "Starting epoch 35\n",
      "Train Loss: 0.2799, Train Acc: 90.00%, Val Loss: 0.1985, Val Acc: 90.00%\n",
      "Starting epoch 36\n",
      "Train Loss: 0.3844, Train Acc: 87.50%, Val Loss: 0.2038, Val Acc: 90.00%\n",
      "Starting epoch 37\n",
      "Train Loss: 0.2598, Train Acc: 87.50%, Val Loss: 0.2045, Val Acc: 100.00%\n",
      "Starting epoch 38\n",
      "Train Loss: 0.2299, Train Acc: 90.00%, Val Loss: 0.1498, Val Acc: 90.00%\n",
      "Epoch 00038: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 39\n",
      "Train Loss: 0.5542, Train Acc: 82.50%, Val Loss: 0.1470, Val Acc: 90.00%\n",
      "Starting epoch 40\n",
      "Train Loss: 0.3019, Train Acc: 85.00%, Val Loss: 0.1439, Val Acc: 90.00%\n",
      "Starting epoch 41\n",
      "Train Loss: 0.2382, Train Acc: 87.50%, Val Loss: 0.1592, Val Acc: 90.00%\n",
      "Starting epoch 42\n",
      "Train Loss: 0.1887, Train Acc: 90.00%, Val Loss: 0.1492, Val Acc: 90.00%\n",
      "Epoch 00042: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 43\n",
      "Train Loss: 0.3393, Train Acc: 87.50%, Val Loss: 0.1357, Val Acc: 90.00%\n",
      "Starting epoch 44\n",
      "Train Loss: 0.8050, Train Acc: 80.00%, Val Loss: 0.1750, Val Acc: 90.00%\n",
      "Starting epoch 45\n",
      "Train Loss: 0.1910, Train Acc: 92.50%, Val Loss: 0.1985, Val Acc: 90.00%\n",
      "Starting epoch 46\n",
      "Train Loss: 0.3650, Train Acc: 87.50%, Val Loss: 0.1835, Val Acc: 90.00%\n",
      "Starting epoch 47\n",
      "Train Loss: 0.2613, Train Acc: 87.50%, Val Loss: 0.1869, Val Acc: 90.00%\n",
      "Epoch 00047: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 48\n",
      "Train Loss: 0.1970, Train Acc: 92.50%, Val Loss: 0.1833, Val Acc: 90.00%\n",
      "Starting epoch 49\n",
      "Train Loss: 0.6113, Train Acc: 82.50%, Val Loss: 0.1702, Val Acc: 90.00%\n",
      "Starting epoch 50\n",
      "Train Loss: 0.2410, Train Acc: 90.00%, Val Loss: 0.1627, Val Acc: 90.00%\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 1.3446, Train Acc: 57.50%, Val Loss: 6.1575, Val Acc: 40.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 0.9141, Train Acc: 67.50%, Val Loss: 1.6756, Val Acc: 80.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 0.3522, Train Acc: 87.50%, Val Loss: 2.7960, Val Acc: 80.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 0.3684, Train Acc: 82.50%, Val Loss: 0.7823, Val Acc: 80.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 0.5341, Train Acc: 82.50%, Val Loss: 6.5616, Val Acc: 40.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 1.2308, Train Acc: 57.50%, Val Loss: 0.3077, Val Acc: 70.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 1.3467, Train Acc: 87.50%, Val Loss: 0.7027, Val Acc: 60.00%\n",
      "Starting epoch 8\n",
      "Train Loss: 1.5144, Train Acc: 62.50%, Val Loss: 0.7745, Val Acc: 60.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 1.2401, Train Acc: 75.00%, Val Loss: 1.6202, Val Acc: 60.00%\n",
      "Starting epoch 10\n",
      "Train Loss: 0.9951, Train Acc: 67.50%, Val Loss: 0.8668, Val Acc: 40.00%\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 11\n",
      "Train Loss: 0.4534, Train Acc: 75.00%, Val Loss: 1.1702, Val Acc: 60.00%\n",
      "Starting epoch 12\n",
      "Train Loss: 0.6658, Train Acc: 75.00%, Val Loss: 0.9463, Val Acc: 60.00%\n",
      "Starting epoch 13\n",
      "Train Loss: 0.6820, Train Acc: 80.00%, Val Loss: 0.4238, Val Acc: 70.00%\n",
      "Starting epoch 14\n",
      "Train Loss: 0.3701, Train Acc: 90.00%, Val Loss: 0.2686, Val Acc: 90.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.6475, Train Acc: 87.50%, Val Loss: 0.2459, Val Acc: 90.00%\n",
      "Starting epoch 16\n",
      "Train Loss: 0.2826, Train Acc: 82.50%, Val Loss: 0.2188, Val Acc: 90.00%\n",
      "Starting epoch 17\n",
      "Train Loss: 0.3543, Train Acc: 85.00%, Val Loss: 0.1968, Val Acc: 100.00%\n",
      "Starting epoch 18\n",
      "Train Loss: 0.3924, Train Acc: 82.50%, Val Loss: 0.1953, Val Acc: 100.00%\n",
      "Starting epoch 19\n",
      "Train Loss: 0.5223, Train Acc: 75.00%, Val Loss: 0.2045, Val Acc: 90.00%\n",
      "Starting epoch 20\n",
      "Train Loss: 0.7718, Train Acc: 77.50%, Val Loss: 0.2079, Val Acc: 90.00%\n",
      "Starting epoch 21\n",
      "Train Loss: 0.7042, Train Acc: 75.00%, Val Loss: 0.2886, Val Acc: 80.00%\n",
      "Starting epoch 22\n",
      "Train Loss: 0.4751, Train Acc: 75.00%, Val Loss: 0.2177, Val Acc: 90.00%\n",
      "Epoch 00022: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 23\n",
      "Train Loss: 0.4400, Train Acc: 80.00%, Val Loss: 0.2399, Val Acc: 90.00%\n",
      "Starting epoch 24\n",
      "Train Loss: 0.2556, Train Acc: 92.50%, Val Loss: 0.2430, Val Acc: 90.00%\n",
      "Starting epoch 25\n",
      "Train Loss: 0.6334, Train Acc: 82.50%, Val Loss: 0.2491, Val Acc: 90.00%\n",
      "Starting epoch 26\n",
      "Train Loss: 0.3816, Train Acc: 82.50%, Val Loss: 0.2563, Val Acc: 90.00%\n",
      "Epoch 00026: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 27\n",
      "Train Loss: 0.7872, Train Acc: 85.00%, Val Loss: 0.2581, Val Acc: 90.00%\n",
      "Starting epoch 28\n",
      "Train Loss: 0.2586, Train Acc: 90.00%, Val Loss: 0.2476, Val Acc: 90.00%\n",
      "Starting epoch 29\n",
      "Train Loss: 0.5382, Train Acc: 75.00%, Val Loss: 0.2472, Val Acc: 90.00%\n",
      "Starting epoch 30\n",
      "Train Loss: 0.6940, Train Acc: 85.00%, Val Loss: 0.2357, Val Acc: 90.00%\n",
      "Epoch 00030: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 31\n",
      "Train Loss: 0.4507, Train Acc: 90.00%, Val Loss: 0.2252, Val Acc: 90.00%\n",
      "Starting epoch 32\n",
      "Train Loss: 0.3776, Train Acc: 77.50%, Val Loss: 0.2256, Val Acc: 90.00%\n",
      "Starting epoch 33\n",
      "Train Loss: 0.2873, Train Acc: 90.00%, Val Loss: 0.2266, Val Acc: 90.00%\n",
      "Starting epoch 34\n",
      "Train Loss: 0.4795, Train Acc: 77.50%, Val Loss: 0.2419, Val Acc: 90.00%\n",
      "Epoch 00034: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 35\n",
      "Train Loss: 0.3625, Train Acc: 87.50%, Val Loss: 0.2295, Val Acc: 90.00%\n",
      "Starting epoch 36\n",
      "Train Loss: 0.3606, Train Acc: 85.00%, Val Loss: 0.2359, Val Acc: 90.00%\n",
      "Starting epoch 37\n",
      "Train Loss: 0.5293, Train Acc: 77.50%, Val Loss: 0.2246, Val Acc: 90.00%\n",
      "Starting epoch 38\n",
      "Train Loss: 0.3921, Train Acc: 87.50%, Val Loss: 0.2346, Val Acc: 90.00%\n",
      "Epoch 00038: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 39\n",
      "Train Loss: 0.4571, Train Acc: 87.50%, Val Loss: 0.2399, Val Acc: 90.00%\n",
      "Starting epoch 40\n",
      "Train Loss: 0.3337, Train Acc: 90.00%, Val Loss: 0.2453, Val Acc: 90.00%\n",
      "Starting epoch 41\n",
      "Train Loss: 0.3206, Train Acc: 87.50%, Val Loss: 0.2430, Val Acc: 90.00%\n",
      "Starting epoch 42\n",
      "Train Loss: 0.5309, Train Acc: 75.00%, Val Loss: 0.2411, Val Acc: 90.00%\n",
      "Starting epoch 43\n",
      "Train Loss: 0.3880, Train Acc: 80.00%, Val Loss: 0.2408, Val Acc: 90.00%\n",
      "Early stopping triggered.\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 0.7624, Train Acc: 60.00%, Val Loss: 9.2840, Val Acc: 40.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 1.2510, Train Acc: 82.50%, Val Loss: 18.9335, Val Acc: 60.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 0.9366, Train Acc: 80.00%, Val Loss: 6.2971, Val Acc: 40.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 0.7778, Train Acc: 70.00%, Val Loss: 2.1659, Val Acc: 80.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 1.2301, Train Acc: 80.00%, Val Loss: 0.9038, Val Acc: 80.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 1.0915, Train Acc: 72.50%, Val Loss: 1.8126, Val Acc: 50.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 0.6363, Train Acc: 75.00%, Val Loss: 0.4825, Val Acc: 80.00%\n",
      "Starting epoch 8\n",
      "Train Loss: 0.5772, Train Acc: 80.00%, Val Loss: 0.3095, Val Acc: 80.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 0.7549, Train Acc: 77.50%, Val Loss: 0.5414, Val Acc: 80.00%\n",
      "Starting epoch 10\n",
      "Train Loss: 0.8427, Train Acc: 67.50%, Val Loss: 0.5581, Val Acc: 80.00%\n",
      "Starting epoch 11\n",
      "Train Loss: 0.4713, Train Acc: 75.00%, Val Loss: 0.5474, Val Acc: 70.00%\n",
      "Starting epoch 12\n",
      "Train Loss: 0.7446, Train Acc: 75.00%, Val Loss: 0.6357, Val Acc: 60.00%\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 13\n",
      "Train Loss: 0.2922, Train Acc: 85.00%, Val Loss: 0.2220, Val Acc: 100.00%\n",
      "Starting epoch 14\n",
      "Train Loss: 0.3441, Train Acc: 90.00%, Val Loss: 0.2096, Val Acc: 90.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.4623, Train Acc: 77.50%, Val Loss: 0.2391, Val Acc: 90.00%\n",
      "Starting epoch 16\n",
      "Train Loss: 0.4596, Train Acc: 77.50%, Val Loss: 0.2736, Val Acc: 90.00%\n",
      "Starting epoch 17\n",
      "Train Loss: 0.4746, Train Acc: 80.00%, Val Loss: 0.1999, Val Acc: 90.00%\n",
      "Starting epoch 18\n",
      "Train Loss: 0.4010, Train Acc: 85.00%, Val Loss: 0.2481, Val Acc: 90.00%\n",
      "Starting epoch 19\n",
      "Train Loss: 0.3210, Train Acc: 90.00%, Val Loss: 0.2142, Val Acc: 90.00%\n",
      "Starting epoch 20\n",
      "Train Loss: 0.3537, Train Acc: 85.00%, Val Loss: 0.1496, Val Acc: 100.00%\n",
      "Starting epoch 21\n",
      "Train Loss: 0.3257, Train Acc: 85.00%, Val Loss: 0.1457, Val Acc: 100.00%\n",
      "Starting epoch 22\n",
      "Train Loss: 0.3022, Train Acc: 90.00%, Val Loss: 0.1529, Val Acc: 100.00%\n",
      "Starting epoch 23\n",
      "Train Loss: 0.2209, Train Acc: 95.00%, Val Loss: 0.1534, Val Acc: 100.00%\n",
      "Starting epoch 24\n",
      "Train Loss: 0.2724, Train Acc: 95.00%, Val Loss: 0.1550, Val Acc: 90.00%\n",
      "Starting epoch 25\n",
      "Train Loss: 0.2497, Train Acc: 90.00%, Val Loss: 0.1707, Val Acc: 90.00%\n",
      "Epoch 00025: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 26\n",
      "Train Loss: 0.4407, Train Acc: 90.00%, Val Loss: 0.1663, Val Acc: 90.00%\n",
      "Starting epoch 27\n",
      "Train Loss: 0.6837, Train Acc: 70.00%, Val Loss: 0.1674, Val Acc: 90.00%\n",
      "Starting epoch 28\n",
      "Train Loss: 0.2529, Train Acc: 92.50%, Val Loss: 0.1763, Val Acc: 90.00%\n",
      "Starting epoch 29\n",
      "Train Loss: 0.3442, Train Acc: 85.00%, Val Loss: 0.1793, Val Acc: 90.00%\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 30\n",
      "Train Loss: 0.4012, Train Acc: 82.50%, Val Loss: 0.1768, Val Acc: 90.00%\n",
      "Starting epoch 31\n",
      "Train Loss: 0.5750, Train Acc: 72.50%, Val Loss: 0.1859, Val Acc: 90.00%\n",
      "Starting epoch 32\n",
      "Train Loss: 0.3866, Train Acc: 85.00%, Val Loss: 0.1796, Val Acc: 90.00%\n",
      "Starting epoch 33\n",
      "Train Loss: 0.1858, Train Acc: 95.00%, Val Loss: 0.1753, Val Acc: 90.00%\n",
      "Epoch 00033: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 34\n",
      "Train Loss: 0.3363, Train Acc: 82.50%, Val Loss: 0.1759, Val Acc: 90.00%\n",
      "Starting epoch 35\n",
      "Train Loss: 0.2738, Train Acc: 90.00%, Val Loss: 0.1943, Val Acc: 90.00%\n",
      "Starting epoch 36\n",
      "Train Loss: 0.0817, Train Acc: 100.00%, Val Loss: 0.1787, Val Acc: 90.00%\n",
      "Starting epoch 37\n",
      "Train Loss: 0.2036, Train Acc: 92.50%, Val Loss: 0.1730, Val Acc: 90.00%\n",
      "Epoch 00037: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 38\n",
      "Train Loss: 0.3086, Train Acc: 82.50%, Val Loss: 0.1783, Val Acc: 90.00%\n",
      "Starting epoch 39\n",
      "Train Loss: 0.3355, Train Acc: 80.00%, Val Loss: 0.1821, Val Acc: 90.00%\n",
      "Starting epoch 40\n",
      "Train Loss: 0.1276, Train Acc: 95.00%, Val Loss: 0.1736, Val Acc: 90.00%\n",
      "Starting epoch 41\n",
      "Train Loss: 0.5814, Train Acc: 77.50%, Val Loss: 0.1692, Val Acc: 90.00%\n",
      "Epoch 00041: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 42\n",
      "Train Loss: 0.3280, Train Acc: 85.00%, Val Loss: 0.1731, Val Acc: 90.00%\n",
      "Starting epoch 43\n",
      "Train Loss: 0.5308, Train Acc: 82.50%, Val Loss: 0.1903, Val Acc: 90.00%\n",
      "Starting epoch 44\n",
      "Train Loss: 0.2984, Train Acc: 90.00%, Val Loss: 0.1854, Val Acc: 90.00%\n",
      "Starting epoch 45\n",
      "Train Loss: 0.3275, Train Acc: 87.50%, Val Loss: 0.1874, Val Acc: 90.00%\n",
      "Starting epoch 46\n",
      "Train Loss: 0.4092, Train Acc: 85.00%, Val Loss: 0.1764, Val Acc: 90.00%\n",
      "Early stopping triggered.\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 1.0027, Train Acc: 62.50%, Val Loss: 0.5011, Val Acc: 80.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 0.8972, Train Acc: 77.50%, Val Loss: 8.4490, Val Acc: 70.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 1.2491, Train Acc: 72.50%, Val Loss: 2.5538, Val Acc: 80.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 1.3840, Train Acc: 57.50%, Val Loss: 1.6310, Val Acc: 70.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 0.7458, Train Acc: 82.50%, Val Loss: 0.4066, Val Acc: 80.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 0.3866, Train Acc: 87.50%, Val Loss: 1.4175, Val Acc: 50.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 0.8379, Train Acc: 77.50%, Val Loss: 0.3590, Val Acc: 80.00%\n",
      "Starting epoch 8\n",
      "Train Loss: 1.3865, Train Acc: 77.50%, Val Loss: 0.5165, Val Acc: 80.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 0.9690, Train Acc: 67.50%, Val Loss: 0.4977, Val Acc: 70.00%\n",
      "Starting epoch 10\n",
      "Train Loss: 0.3452, Train Acc: 87.50%, Val Loss: 0.7770, Val Acc: 60.00%\n",
      "Starting epoch 11\n",
      "Train Loss: 0.4908, Train Acc: 85.00%, Val Loss: 0.3248, Val Acc: 80.00%\n",
      "Starting epoch 12\n",
      "Train Loss: 0.3625, Train Acc: 85.00%, Val Loss: 0.5860, Val Acc: 70.00%\n",
      "Starting epoch 13\n",
      "Train Loss: 0.5516, Train Acc: 75.00%, Val Loss: 0.7413, Val Acc: 40.00%\n",
      "Starting epoch 14\n",
      "Train Loss: 0.3692, Train Acc: 80.00%, Val Loss: 0.3845, Val Acc: 90.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.3598, Train Acc: 87.50%, Val Loss: 0.3125, Val Acc: 80.00%\n",
      "Starting epoch 16\n",
      "Train Loss: 1.0808, Train Acc: 80.00%, Val Loss: 0.8033, Val Acc: 40.00%\n",
      "Starting epoch 17\n",
      "Train Loss: 0.4294, Train Acc: 82.50%, Val Loss: 1.9204, Val Acc: 70.00%\n",
      "Starting epoch 18\n",
      "Train Loss: 0.3785, Train Acc: 82.50%, Val Loss: 0.6503, Val Acc: 70.00%\n",
      "Starting epoch 19\n",
      "Train Loss: 0.4170, Train Acc: 85.00%, Val Loss: 1.7918, Val Acc: 40.00%\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 20\n",
      "Train Loss: 0.6074, Train Acc: 82.50%, Val Loss: 0.4106, Val Acc: 80.00%\n",
      "Starting epoch 21\n",
      "Train Loss: 0.4252, Train Acc: 80.00%, Val Loss: 0.5889, Val Acc: 80.00%\n",
      "Starting epoch 22\n",
      "Train Loss: 0.5016, Train Acc: 80.00%, Val Loss: 0.5385, Val Acc: 80.00%\n",
      "Starting epoch 23\n",
      "Train Loss: 0.2961, Train Acc: 82.50%, Val Loss: 0.4491, Val Acc: 80.00%\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 24\n",
      "Train Loss: 0.3438, Train Acc: 95.00%, Val Loss: 0.4430, Val Acc: 80.00%\n",
      "Starting epoch 25\n",
      "Train Loss: 0.2687, Train Acc: 90.00%, Val Loss: 0.4539, Val Acc: 90.00%\n",
      "Starting epoch 26\n",
      "Train Loss: 0.3602, Train Acc: 85.00%, Val Loss: 0.4210, Val Acc: 90.00%\n",
      "Starting epoch 27\n",
      "Train Loss: 0.5087, Train Acc: 80.00%, Val Loss: 0.4421, Val Acc: 90.00%\n",
      "Epoch 00027: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 28\n",
      "Train Loss: 0.2809, Train Acc: 85.00%, Val Loss: 0.4228, Val Acc: 90.00%\n",
      "Starting epoch 29\n",
      "Train Loss: 0.2825, Train Acc: 85.00%, Val Loss: 0.4031, Val Acc: 80.00%\n",
      "Starting epoch 30\n",
      "Train Loss: 0.5867, Train Acc: 77.50%, Val Loss: 0.4247, Val Acc: 90.00%\n",
      "Starting epoch 31\n",
      "Train Loss: 0.3536, Train Acc: 85.00%, Val Loss: 0.4366, Val Acc: 90.00%\n",
      "Epoch 00031: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 32\n",
      "Train Loss: 0.6655, Train Acc: 77.50%, Val Loss: 0.4275, Val Acc: 90.00%\n",
      "Starting epoch 33\n",
      "Train Loss: 0.5698, Train Acc: 85.00%, Val Loss: 0.4424, Val Acc: 90.00%\n",
      "Starting epoch 34\n",
      "Train Loss: 0.2803, Train Acc: 90.00%, Val Loss: 0.4374, Val Acc: 90.00%\n",
      "Starting epoch 35\n",
      "Train Loss: 0.3576, Train Acc: 90.00%, Val Loss: 0.4442, Val Acc: 90.00%\n",
      "Epoch 00035: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 36\n",
      "Train Loss: 0.5037, Train Acc: 80.00%, Val Loss: 0.4390, Val Acc: 90.00%\n",
      "Starting epoch 37\n",
      "Train Loss: 0.2383, Train Acc: 95.00%, Val Loss: 0.4313, Val Acc: 90.00%\n",
      "Starting epoch 38\n",
      "Train Loss: 0.3031, Train Acc: 90.00%, Val Loss: 0.4271, Val Acc: 90.00%\n",
      "Starting epoch 39\n",
      "Train Loss: 0.3728, Train Acc: 90.00%, Val Loss: 0.4354, Val Acc: 90.00%\n",
      "Epoch 00039: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 40\n",
      "Train Loss: 0.3239, Train Acc: 87.50%, Val Loss: 0.4217, Val Acc: 90.00%\n",
      "Early stopping triggered.\n",
      "--------------------------------\n",
      "Best validation accuracy of 0.00% achieved, model saved as best_model.pth\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(trainset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    train_indices = [i for i, (_, label) in enumerate(trainset) if label in selected_classes]\n",
    "\n",
    "    N = 25  \n",
    "    class_counts = {label: 0 for label in selected_classes}\n",
    "    filtered_train_indices = []\n",
    "\n",
    "    for i in train_indices:\n",
    "        _, label = trainset[i]\n",
    "        if class_counts[label] < N:\n",
    "            filtered_train_indices.append(i)\n",
    "            class_counts[label] += 1\n",
    "    \n",
    "    \n",
    "    np.random.seed(42)  \n",
    "    np.random.shuffle(filtered_train_indices)  \n",
    "    split = int(0.8 * len(filtered_train_indices))  \n",
    "    train_idx, val_idx = filtered_train_indices[:split], filtered_train_indices[split:]\n",
    "    \n",
    "    train_subset = Subset(trainset, train_idx)\n",
    "    transformed_train_subset = TransformSubset(train_subset, transform=train_transform)\n",
    "\n",
    "    val_subset = Subset(trainset, val_idx)\n",
    "    transformed_val_subset = TransformSubset(val_subset, transform=test_transform)\n",
    "    \n",
    "    train_loader = DataLoader(transformed_train_subset, batch_size=5, shuffle=True)\n",
    "    val_loader = DataLoader(transformed_val_subset, batch_size=5, shuffle=False)\n",
    "    \n",
    "    \n",
    "    # Init the neural network\n",
    "    model = CustomCNN().to(device)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.005) \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initilization of scheduler\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 25\n",
    "\n",
    "    \n",
    "    # Run the training loop for defined number of epochs\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "        \n",
    "        # Perform training and validation\n",
    "        train_loss, train_accuracy = train(model, device, train_loader, optimizer, criterion)\n",
    "        val_loss, val_accuracy = validate(model, device, val_loader, criterion)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "        \n",
    "        # Save the model if it has the best val accuracy so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "             # Save the best model weights\n",
    "            best_model_weights = model.state_dict().copy() \n",
    "            patience_counter = 0 \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            # Stop training if no improvement\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break  \n",
    "        \n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step(val_loss)\n",
    "            \n",
    "    print('--------------------------------')\n",
    "    \n",
    "# Save the best model weights\n",
    "torch.save(best_model_weights, 'best_model.pth')\n",
    "print(f'Best validation accuracy of {best_val_accuracy:.2f}% achieved, model saved as best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomCNN()\n",
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = [i for i, (_, label) in enumerate(testset) if label in selected_classes]\n",
    "N = 1000 \n",
    "class_counts = {label: 0 for label in selected_classes}\n",
    "filtered_train_indices = []\n",
    "\n",
    "for i in test_indices:\n",
    "    _, label = testset[i]\n",
    "    if class_counts[label] < N:\n",
    "        filtered_train_indices.append(i)\n",
    "        class_counts[label] += 1\n",
    "\n",
    "test_subset = Subset(testset, filtered_train_indices)\n",
    "test_loader = DataLoader(test_subset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3323, Test Accuracy: 87.05%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluation\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradient is needed for evaluation\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, targets)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "avg_loss = test_loss / len(test_loader)\n",
    "accuracy = 100. * correct / total\n",
    "\n",
    "print(f'Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f10e0bbdcb8a5227530b5aed21b374411d613e5cbe3bc0662ba6adc52ae7b0de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
