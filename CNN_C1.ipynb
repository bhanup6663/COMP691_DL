{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset,DataLoader, Subset, random_split\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.subset[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_classes = np.random.choice(range(10), 2, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),  # Additional conv layer\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_accuracy = 0\n",
    "best_model_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, targets) in enumerate(val_loader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 1.3853, Train Acc: 40.00%, Val Loss: 2.1202, Val Acc: 70.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 0.5847, Train Acc: 77.50%, Val Loss: 0.3866, Val Acc: 80.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 0.7506, Train Acc: 70.00%, Val Loss: 0.7802, Val Acc: 70.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 1.3162, Train Acc: 67.50%, Val Loss: 0.6277, Val Acc: 70.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 1.0114, Train Acc: 65.00%, Val Loss: 0.4434, Val Acc: 90.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 0.9994, Train Acc: 65.00%, Val Loss: 1.4553, Val Acc: 40.00%\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 7\n",
      "Train Loss: 0.5768, Train Acc: 77.50%, Val Loss: 1.1201, Val Acc: 50.00%\n",
      "Starting epoch 8\n",
      "Train Loss: 0.9523, Train Acc: 65.00%, Val Loss: 0.9074, Val Acc: 50.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 0.7643, Train Acc: 77.50%, Val Loss: 0.8773, Val Acc: 50.00%\n",
      "Starting epoch 10\n",
      "Train Loss: 0.6869, Train Acc: 72.50%, Val Loss: 0.9001, Val Acc: 50.00%\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 11\n",
      "Train Loss: 0.8139, Train Acc: 67.50%, Val Loss: 0.9154, Val Acc: 50.00%\n",
      "Starting epoch 12\n",
      "Train Loss: 0.5065, Train Acc: 80.00%, Val Loss: 0.9274, Val Acc: 50.00%\n",
      "Starting epoch 13\n",
      "Train Loss: 0.5476, Train Acc: 77.50%, Val Loss: 0.8610, Val Acc: 50.00%\n",
      "Starting epoch 14\n",
      "Train Loss: 0.8012, Train Acc: 67.50%, Val Loss: 0.8275, Val Acc: 50.00%\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 15\n",
      "Train Loss: 0.5908, Train Acc: 72.50%, Val Loss: 0.8228, Val Acc: 50.00%\n",
      "Starting epoch 16\n",
      "Train Loss: 0.7186, Train Acc: 70.00%, Val Loss: 0.8709, Val Acc: 50.00%\n",
      "Starting epoch 17\n",
      "Train Loss: 0.8323, Train Acc: 60.00%, Val Loss: 0.9060, Val Acc: 50.00%\n",
      "Starting epoch 18\n",
      "Train Loss: 0.8540, Train Acc: 67.50%, Val Loss: 0.8722, Val Acc: 50.00%\n",
      "Epoch 00018: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 19\n",
      "Train Loss: 0.7045, Train Acc: 75.00%, Val Loss: 0.8692, Val Acc: 50.00%\n",
      "Starting epoch 20\n",
      "Train Loss: 0.6663, Train Acc: 77.50%, Val Loss: 0.8612, Val Acc: 50.00%\n",
      "Starting epoch 21\n",
      "Train Loss: 0.5715, Train Acc: 82.50%, Val Loss: 0.8927, Val Acc: 50.00%\n",
      "Starting epoch 22\n",
      "Train Loss: 0.7059, Train Acc: 67.50%, Val Loss: 0.8848, Val Acc: 50.00%\n",
      "Epoch 00022: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 23\n",
      "Train Loss: 0.8717, Train Acc: 60.00%, Val Loss: 0.8852, Val Acc: 50.00%\n",
      "Starting epoch 24\n",
      "Train Loss: 0.6379, Train Acc: 75.00%, Val Loss: 0.8976, Val Acc: 50.00%\n",
      "Starting epoch 25\n",
      "Train Loss: 0.4845, Train Acc: 80.00%, Val Loss: 0.8750, Val Acc: 50.00%\n",
      "Starting epoch 26\n",
      "Train Loss: 0.5059, Train Acc: 75.00%, Val Loss: 0.8492, Val Acc: 50.00%\n",
      "Epoch 00026: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 27\n",
      "Train Loss: 0.8388, Train Acc: 72.50%, Val Loss: 0.8649, Val Acc: 50.00%\n",
      "Early stopping triggered.\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 1.7522, Train Acc: 50.00%, Val Loss: 0.5401, Val Acc: 80.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 0.7251, Train Acc: 70.00%, Val Loss: 0.6709, Val Acc: 90.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 0.7520, Train Acc: 72.50%, Val Loss: 0.5682, Val Acc: 70.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 0.6255, Train Acc: 77.50%, Val Loss: 0.7201, Val Acc: 70.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 0.9520, Train Acc: 52.50%, Val Loss: 5.1463, Val Acc: 30.00%\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 6\n",
      "Train Loss: 1.2757, Train Acc: 55.00%, Val Loss: 2.1851, Val Acc: 30.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 0.7386, Train Acc: 65.00%, Val Loss: 0.5278, Val Acc: 70.00%\n",
      "Starting epoch 8\n",
      "Train Loss: 0.8467, Train Acc: 65.00%, Val Loss: 0.4241, Val Acc: 70.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 0.6260, Train Acc: 72.50%, Val Loss: 0.4355, Val Acc: 70.00%\n",
      "Starting epoch 10\n",
      "Train Loss: 0.6588, Train Acc: 70.00%, Val Loss: 0.4902, Val Acc: 70.00%\n",
      "Starting epoch 11\n",
      "Train Loss: 0.3862, Train Acc: 82.50%, Val Loss: 0.5391, Val Acc: 70.00%\n",
      "Starting epoch 12\n",
      "Train Loss: 0.5266, Train Acc: 75.00%, Val Loss: 0.5729, Val Acc: 70.00%\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 13\n",
      "Train Loss: 0.5620, Train Acc: 70.00%, Val Loss: 0.5997, Val Acc: 70.00%\n",
      "Starting epoch 14\n",
      "Train Loss: 0.5099, Train Acc: 85.00%, Val Loss: 0.5994, Val Acc: 70.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.6221, Train Acc: 77.50%, Val Loss: 0.5843, Val Acc: 70.00%\n",
      "Starting epoch 16\n",
      "Train Loss: 0.4820, Train Acc: 82.50%, Val Loss: 0.6060, Val Acc: 70.00%\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 17\n",
      "Train Loss: 0.4729, Train Acc: 77.50%, Val Loss: 0.6079, Val Acc: 70.00%\n",
      "Starting epoch 18\n",
      "Train Loss: 0.4855, Train Acc: 80.00%, Val Loss: 0.6081, Val Acc: 70.00%\n",
      "Starting epoch 19\n",
      "Train Loss: 0.6919, Train Acc: 70.00%, Val Loss: 0.5621, Val Acc: 70.00%\n",
      "Starting epoch 20\n",
      "Train Loss: 0.5390, Train Acc: 75.00%, Val Loss: 0.5475, Val Acc: 70.00%\n",
      "Epoch 00020: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 21\n",
      "Train Loss: 0.6588, Train Acc: 72.50%, Val Loss: 0.5761, Val Acc: 70.00%\n",
      "Starting epoch 22\n",
      "Train Loss: 0.5303, Train Acc: 77.50%, Val Loss: 0.5623, Val Acc: 70.00%\n",
      "Starting epoch 23\n",
      "Train Loss: 0.7015, Train Acc: 72.50%, Val Loss: 0.5680, Val Acc: 70.00%\n",
      "Starting epoch 24\n",
      "Train Loss: 0.8132, Train Acc: 70.00%, Val Loss: 0.5585, Val Acc: 70.00%\n",
      "Epoch 00024: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 25\n",
      "Train Loss: 0.5592, Train Acc: 72.50%, Val Loss: 0.5821, Val Acc: 70.00%\n",
      "Starting epoch 26\n",
      "Train Loss: 0.6701, Train Acc: 82.50%, Val Loss: 0.6062, Val Acc: 70.00%\n",
      "Starting epoch 27\n",
      "Train Loss: 0.4811, Train Acc: 85.00%, Val Loss: 0.5740, Val Acc: 70.00%\n",
      "Starting epoch 28\n",
      "Train Loss: 0.5432, Train Acc: 80.00%, Val Loss: 0.5509, Val Acc: 70.00%\n",
      "Epoch 00028: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 29\n",
      "Train Loss: 0.4971, Train Acc: 82.50%, Val Loss: 0.5387, Val Acc: 70.00%\n",
      "Starting epoch 30\n",
      "Train Loss: 0.6188, Train Acc: 77.50%, Val Loss: 0.5853, Val Acc: 70.00%\n",
      "Starting epoch 31\n",
      "Train Loss: 0.5893, Train Acc: 75.00%, Val Loss: 0.5525, Val Acc: 70.00%\n",
      "Starting epoch 32\n",
      "Train Loss: 0.6077, Train Acc: 75.00%, Val Loss: 0.5862, Val Acc: 70.00%\n",
      "Starting epoch 33\n",
      "Train Loss: 0.5348, Train Acc: 85.00%, Val Loss: 0.5569, Val Acc: 70.00%\n",
      "Early stopping triggered.\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 2.4388, Train Acc: 50.00%, Val Loss: 26.7200, Val Acc: 30.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 1.0913, Train Acc: 50.00%, Val Loss: 0.8265, Val Acc: 70.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 0.7277, Train Acc: 75.00%, Val Loss: 0.8859, Val Acc: 70.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 1.3608, Train Acc: 52.50%, Val Loss: 0.6071, Val Acc: 60.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 1.2461, Train Acc: 55.00%, Val Loss: 0.3866, Val Acc: 80.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 0.6128, Train Acc: 67.50%, Val Loss: 0.8457, Val Acc: 60.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 0.7070, Train Acc: 65.00%, Val Loss: 0.7588, Val Acc: 60.00%\n",
      "Starting epoch 8\n",
      "Train Loss: 0.6430, Train Acc: 75.00%, Val Loss: 0.9805, Val Acc: 60.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 0.5164, Train Acc: 77.50%, Val Loss: 0.4190, Val Acc: 90.00%\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 10\n",
      "Train Loss: 0.5156, Train Acc: 82.50%, Val Loss: 0.5214, Val Acc: 80.00%\n",
      "Starting epoch 11\n",
      "Train Loss: 0.3953, Train Acc: 82.50%, Val Loss: 0.5945, Val Acc: 70.00%\n",
      "Starting epoch 12\n",
      "Train Loss: 0.7726, Train Acc: 72.50%, Val Loss: 0.5427, Val Acc: 80.00%\n",
      "Starting epoch 13\n",
      "Train Loss: 0.5957, Train Acc: 70.00%, Val Loss: 0.5163, Val Acc: 80.00%\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 14\n",
      "Train Loss: 0.5841, Train Acc: 77.50%, Val Loss: 0.5179, Val Acc: 80.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.5182, Train Acc: 77.50%, Val Loss: 0.4927, Val Acc: 80.00%\n",
      "Starting epoch 16\n",
      "Train Loss: 0.4404, Train Acc: 82.50%, Val Loss: 0.4988, Val Acc: 80.00%\n",
      "Starting epoch 17\n",
      "Train Loss: 0.5890, Train Acc: 80.00%, Val Loss: 0.5118, Val Acc: 80.00%\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 18\n",
      "Train Loss: 0.5862, Train Acc: 82.50%, Val Loss: 0.4974, Val Acc: 80.00%\n",
      "Starting epoch 19\n",
      "Train Loss: 0.6619, Train Acc: 62.50%, Val Loss: 0.4971, Val Acc: 80.00%\n",
      "Starting epoch 20\n",
      "Train Loss: 0.6120, Train Acc: 77.50%, Val Loss: 0.5002, Val Acc: 80.00%\n",
      "Starting epoch 21\n",
      "Train Loss: 0.6818, Train Acc: 77.50%, Val Loss: 0.4953, Val Acc: 80.00%\n",
      "Epoch 00021: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 22\n",
      "Train Loss: 0.4319, Train Acc: 80.00%, Val Loss: 0.4740, Val Acc: 80.00%\n",
      "Starting epoch 23\n",
      "Train Loss: 0.5037, Train Acc: 80.00%, Val Loss: 0.4701, Val Acc: 80.00%\n",
      "Starting epoch 24\n",
      "Train Loss: 0.6071, Train Acc: 75.00%, Val Loss: 0.4818, Val Acc: 80.00%\n",
      "Starting epoch 25\n",
      "Train Loss: 0.5434, Train Acc: 77.50%, Val Loss: 0.4762, Val Acc: 80.00%\n",
      "Epoch 00025: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 26\n",
      "Train Loss: 0.5816, Train Acc: 80.00%, Val Loss: 0.4683, Val Acc: 80.00%\n",
      "Starting epoch 27\n",
      "Train Loss: 0.5653, Train Acc: 75.00%, Val Loss: 0.4891, Val Acc: 80.00%\n",
      "Starting epoch 28\n",
      "Train Loss: 0.8709, Train Acc: 67.50%, Val Loss: 0.4890, Val Acc: 80.00%\n",
      "Starting epoch 29\n",
      "Train Loss: 0.6590, Train Acc: 75.00%, Val Loss: 0.5038, Val Acc: 80.00%\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 30\n",
      "Train Loss: 0.7171, Train Acc: 70.00%, Val Loss: 0.4988, Val Acc: 80.00%\n",
      "Early stopping triggered.\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 1.5375, Train Acc: 50.00%, Val Loss: 1.5912, Val Acc: 80.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 0.9562, Train Acc: 62.50%, Val Loss: 0.6233, Val Acc: 80.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 0.9979, Train Acc: 67.50%, Val Loss: 0.5266, Val Acc: 80.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 1.0656, Train Acc: 72.50%, Val Loss: 0.8319, Val Acc: 70.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 1.0179, Train Acc: 60.00%, Val Loss: 0.6611, Val Acc: 60.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 1.0314, Train Acc: 57.50%, Val Loss: 1.2432, Val Acc: 50.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 0.5333, Train Acc: 80.00%, Val Loss: 0.5542, Val Acc: 80.00%\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 8\n",
      "Train Loss: 0.6825, Train Acc: 80.00%, Val Loss: 0.6551, Val Acc: 80.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 0.9401, Train Acc: 75.00%, Val Loss: 0.7643, Val Acc: 70.00%\n",
      "Starting epoch 10\n",
      "Train Loss: 0.5844, Train Acc: 80.00%, Val Loss: 0.8431, Val Acc: 60.00%\n",
      "Starting epoch 11\n",
      "Train Loss: 0.5019, Train Acc: 77.50%, Val Loss: 0.7904, Val Acc: 60.00%\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 12\n",
      "Train Loss: 0.4042, Train Acc: 87.50%, Val Loss: 0.7595, Val Acc: 60.00%\n",
      "Starting epoch 13\n",
      "Train Loss: 0.6702, Train Acc: 72.50%, Val Loss: 0.7649, Val Acc: 70.00%\n",
      "Starting epoch 14\n",
      "Train Loss: 0.6351, Train Acc: 67.50%, Val Loss: 0.7191, Val Acc: 70.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.5689, Train Acc: 77.50%, Val Loss: 0.6864, Val Acc: 80.00%\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 16\n",
      "Train Loss: 0.5970, Train Acc: 80.00%, Val Loss: 0.6572, Val Acc: 80.00%\n",
      "Starting epoch 17\n",
      "Train Loss: 0.8604, Train Acc: 60.00%, Val Loss: 0.6915, Val Acc: 70.00%\n",
      "Starting epoch 18\n",
      "Train Loss: 0.5912, Train Acc: 85.00%, Val Loss: 0.6779, Val Acc: 70.00%\n",
      "Starting epoch 19\n",
      "Train Loss: 0.5057, Train Acc: 80.00%, Val Loss: 0.6842, Val Acc: 70.00%\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 20\n",
      "Train Loss: 0.8615, Train Acc: 67.50%, Val Loss: 0.6775, Val Acc: 80.00%\n",
      "Starting epoch 21\n",
      "Train Loss: 0.6979, Train Acc: 70.00%, Val Loss: 0.6511, Val Acc: 80.00%\n",
      "Starting epoch 22\n",
      "Train Loss: 0.4731, Train Acc: 85.00%, Val Loss: 0.6787, Val Acc: 80.00%\n",
      "Starting epoch 23\n",
      "Train Loss: 0.5395, Train Acc: 72.50%, Val Loss: 0.6956, Val Acc: 70.00%\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 24\n",
      "Train Loss: 0.5640, Train Acc: 80.00%, Val Loss: 0.6637, Val Acc: 80.00%\n",
      "Starting epoch 25\n",
      "Train Loss: 0.3333, Train Acc: 82.50%, Val Loss: 0.6635, Val Acc: 80.00%\n",
      "Starting epoch 26\n",
      "Train Loss: 0.3723, Train Acc: 80.00%, Val Loss: 0.6497, Val Acc: 80.00%\n",
      "Starting epoch 27\n",
      "Train Loss: 0.6395, Train Acc: 67.50%, Val Loss: 0.6169, Val Acc: 80.00%\n",
      "Epoch 00027: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 28\n",
      "Train Loss: 0.5518, Train Acc: 77.50%, Val Loss: 0.6501, Val Acc: 80.00%\n",
      "Early stopping triggered.\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 0.9041, Train Acc: 55.00%, Val Loss: 1.4507, Val Acc: 80.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 1.2103, Train Acc: 62.50%, Val Loss: 1.0120, Val Acc: 70.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 1.2952, Train Acc: 70.00%, Val Loss: 0.9463, Val Acc: 70.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 1.5580, Train Acc: 57.50%, Val Loss: 1.3866, Val Acc: 60.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 1.3141, Train Acc: 75.00%, Val Loss: 1.0854, Val Acc: 70.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 0.9174, Train Acc: 65.00%, Val Loss: 0.4760, Val Acc: 70.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 1.1659, Train Acc: 62.50%, Val Loss: 0.6041, Val Acc: 70.00%\n",
      "Starting epoch 8\n",
      "Train Loss: 0.5681, Train Acc: 67.50%, Val Loss: 0.5461, Val Acc: 70.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 0.5382, Train Acc: 75.00%, Val Loss: 0.9076, Val Acc: 60.00%\n",
      "Starting epoch 10\n",
      "Train Loss: 0.8545, Train Acc: 67.50%, Val Loss: 1.1519, Val Acc: 50.00%\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 11\n",
      "Train Loss: 0.7094, Train Acc: 67.50%, Val Loss: 0.8486, Val Acc: 50.00%\n",
      "Starting epoch 12\n",
      "Train Loss: 0.6805, Train Acc: 72.50%, Val Loss: 0.6219, Val Acc: 60.00%\n",
      "Starting epoch 13\n",
      "Train Loss: 0.4946, Train Acc: 75.00%, Val Loss: 0.5307, Val Acc: 70.00%\n",
      "Starting epoch 14\n",
      "Train Loss: 0.5417, Train Acc: 77.50%, Val Loss: 0.4733, Val Acc: 70.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.6499, Train Acc: 77.50%, Val Loss: 0.5190, Val Acc: 70.00%\n",
      "Starting epoch 16\n",
      "Train Loss: 0.4321, Train Acc: 77.50%, Val Loss: 0.5937, Val Acc: 70.00%\n",
      "Starting epoch 17\n",
      "Train Loss: 0.3498, Train Acc: 82.50%, Val Loss: 0.6856, Val Acc: 70.00%\n",
      "Starting epoch 18\n",
      "Train Loss: 0.7912, Train Acc: 67.50%, Val Loss: 0.6184, Val Acc: 70.00%\n",
      "Epoch 00018: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 19\n",
      "Train Loss: 0.6377, Train Acc: 77.50%, Val Loss: 0.5556, Val Acc: 70.00%\n",
      "Starting epoch 20\n",
      "Train Loss: 0.4871, Train Acc: 80.00%, Val Loss: 0.5378, Val Acc: 70.00%\n",
      "Starting epoch 21\n",
      "Train Loss: 0.4951, Train Acc: 72.50%, Val Loss: 0.5515, Val Acc: 70.00%\n",
      "Starting epoch 22\n",
      "Train Loss: 0.6304, Train Acc: 72.50%, Val Loss: 0.5061, Val Acc: 70.00%\n",
      "Epoch 00022: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 23\n",
      "Train Loss: 0.4139, Train Acc: 77.50%, Val Loss: 0.5370, Val Acc: 70.00%\n",
      "Starting epoch 24\n",
      "Train Loss: 0.4458, Train Acc: 80.00%, Val Loss: 0.5678, Val Acc: 70.00%\n",
      "Starting epoch 25\n",
      "Train Loss: 0.4384, Train Acc: 77.50%, Val Loss: 0.5719, Val Acc: 70.00%\n",
      "Starting epoch 26\n",
      "Train Loss: 0.6465, Train Acc: 75.00%, Val Loss: 0.6043, Val Acc: 70.00%\n",
      "Epoch 00026: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 27\n",
      "Train Loss: 0.4889, Train Acc: 77.50%, Val Loss: 0.5559, Val Acc: 70.00%\n",
      "Starting epoch 28\n",
      "Train Loss: 0.7004, Train Acc: 75.00%, Val Loss: 0.5529, Val Acc: 70.00%\n",
      "Starting epoch 29\n",
      "Train Loss: 0.5382, Train Acc: 77.50%, Val Loss: 0.5130, Val Acc: 70.00%\n",
      "Starting epoch 30\n",
      "Train Loss: 0.4955, Train Acc: 80.00%, Val Loss: 0.5235, Val Acc: 70.00%\n",
      "Epoch 00030: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 31\n",
      "Train Loss: 0.5170, Train Acc: 72.50%, Val Loss: 0.5334, Val Acc: 70.00%\n",
      "Starting epoch 32\n",
      "Train Loss: 0.3970, Train Acc: 80.00%, Val Loss: 0.5755, Val Acc: 70.00%\n",
      "Starting epoch 33\n",
      "Train Loss: 0.3567, Train Acc: 92.50%, Val Loss: 0.5522, Val Acc: 70.00%\n",
      "Starting epoch 34\n",
      "Train Loss: 0.6133, Train Acc: 75.00%, Val Loss: 0.5578, Val Acc: 70.00%\n",
      "Epoch 00034: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 35\n",
      "Train Loss: 0.3720, Train Acc: 87.50%, Val Loss: 0.5194, Val Acc: 70.00%\n",
      "Starting epoch 36\n",
      "Train Loss: 0.4252, Train Acc: 80.00%, Val Loss: 0.5206, Val Acc: 70.00%\n",
      "Starting epoch 37\n",
      "Train Loss: 0.6247, Train Acc: 70.00%, Val Loss: 0.5116, Val Acc: 70.00%\n",
      "Starting epoch 38\n",
      "Train Loss: 0.5274, Train Acc: 77.50%, Val Loss: 0.5106, Val Acc: 70.00%\n",
      "Starting epoch 39\n",
      "Train Loss: 0.5581, Train Acc: 67.50%, Val Loss: 0.5027, Val Acc: 70.00%\n",
      "Early stopping triggered.\n",
      "--------------------------------\n",
      "Best validation accuracy of 0.00% achieved, model saved as best_model.pth\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(trainset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    train_indices = [i for i, (_, label) in enumerate(trainset) if label in selected_classes]\n",
    "\n",
    "    N = 25  # Assuming we want at most N samples per selected class\n",
    "    class_counts = {label: 0 for label in selected_classes}\n",
    "    filtered_train_indices = []\n",
    "\n",
    "    for i in train_indices:\n",
    "        _, label = trainset[i]\n",
    "        if class_counts[label] < N:\n",
    "            filtered_train_indices.append(i)\n",
    "            class_counts[label] += 1\n",
    "    \n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    np.random.seed(42)  # Ensure reproducibility\n",
    "    np.random.shuffle(filtered_train_indices)  # Shuffle the indices\n",
    "    split = int(0.8 * len(filtered_train_indices))  # 80% of indices for training\n",
    "    train_idx, val_idx = filtered_train_indices[:split], filtered_train_indices[split:]\n",
    "    \n",
    "    train_subset = Subset(trainset, train_idx)\n",
    "    transformed_train_subset = TransformSubset(train_subset, transform=train_transform)\n",
    "\n",
    "    val_subset = Subset(trainset, val_idx)\n",
    "    transformed_val_subset = TransformSubset(val_subset, transform=test_transform)\n",
    "    \n",
    "    train_loader = DataLoader(transformed_train_subset, batch_size=5, shuffle=True)\n",
    "    val_loader = DataLoader(transformed_val_subset, batch_size=5, shuffle=False)\n",
    "    \n",
    "    \n",
    "    # Init the neural network\n",
    "    model = CustomCNN().to(device)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.005) \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 25\n",
    "\n",
    "    \n",
    "    # Run the training loop for defined number of epochs\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "        \n",
    "        # Perform training and validation\n",
    "        train_loss, train_accuracy = train(model, device, train_loader, optimizer, criterion)\n",
    "        val_loss, val_accuracy = validate(model, device, val_loader, criterion)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "        \n",
    "        # Save the model if it has the best val accuracy so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_weights = model.state_dict().copy()  # Save the best model weights\n",
    "            patience_counter = 0  # Reset patience\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break  # Stop training if no improvement\n",
    "        \n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step(val_loss)\n",
    "            \n",
    "    print('--------------------------------')\n",
    "    \n",
    "# Save the best model weights\n",
    "torch.save(best_model_weights, 'best_model.pth')\n",
    "print(f'Best validation accuracy of {best_val_accuracy:.2f}% achieved, model saved as best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 1.0580, Train Acc: 55.00%, Val Loss: 2.5660, Val Acc: 70.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 1.6135, Train Acc: 52.50%, Val Loss: 3.6990, Val Acc: 30.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 0.8888, Train Acc: 72.50%, Val Loss: 0.3134, Val Acc: 80.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 1.6261, Train Acc: 60.00%, Val Loss: 0.6641, Val Acc: 80.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 0.6477, Train Acc: 77.50%, Val Loss: 0.5118, Val Acc: 70.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 0.8897, Train Acc: 72.50%, Val Loss: 1.1230, Val Acc: 50.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 0.5005, Train Acc: 82.50%, Val Loss: 1.2962, Val Acc: 40.00%\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 8\n",
      "Train Loss: 1.0436, Train Acc: 67.50%, Val Loss: 1.1051, Val Acc: 50.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 1.0331, Train Acc: 60.00%, Val Loss: 1.0098, Val Acc: 50.00%\n",
      "Starting epoch 10\n",
      "Train Loss: 0.8613, Train Acc: 62.50%, Val Loss: 0.8529, Val Acc: 50.00%\n",
      "Starting epoch 11\n",
      "Train Loss: 0.3735, Train Acc: 87.50%, Val Loss: 0.7378, Val Acc: 60.00%\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 12\n",
      "Train Loss: 0.5511, Train Acc: 72.50%, Val Loss: 0.7284, Val Acc: 60.00%\n",
      "Starting epoch 13\n",
      "Train Loss: 0.8253, Train Acc: 67.50%, Val Loss: 0.7119, Val Acc: 60.00%\n",
      "Starting epoch 14\n",
      "Train Loss: 0.5636, Train Acc: 77.50%, Val Loss: 0.7147, Val Acc: 60.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.5362, Train Acc: 82.50%, Val Loss: 0.7067, Val Acc: 60.00%\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 16\n",
      "Train Loss: 0.4750, Train Acc: 80.00%, Val Loss: 0.7150, Val Acc: 60.00%\n",
      "Starting epoch 17\n",
      "Train Loss: 0.4919, Train Acc: 77.50%, Val Loss: 0.7041, Val Acc: 60.00%\n",
      "Starting epoch 18\n",
      "Train Loss: 0.7022, Train Acc: 80.00%, Val Loss: 0.7206, Val Acc: 60.00%\n",
      "Starting epoch 19\n",
      "Train Loss: 0.4214, Train Acc: 85.00%, Val Loss: 0.6984, Val Acc: 60.00%\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 20\n",
      "Train Loss: 0.7255, Train Acc: 72.50%, Val Loss: 0.6827, Val Acc: 60.00%\n",
      "Starting epoch 21\n",
      "Train Loss: 0.6234, Train Acc: 70.00%, Val Loss: 0.6598, Val Acc: 60.00%\n",
      "Starting epoch 22\n",
      "Train Loss: 0.6693, Train Acc: 72.50%, Val Loss: 0.6786, Val Acc: 60.00%\n",
      "Starting epoch 23\n",
      "Train Loss: 0.7450, Train Acc: 70.00%, Val Loss: 0.6690, Val Acc: 60.00%\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 24\n",
      "Train Loss: 0.4115, Train Acc: 85.00%, Val Loss: 0.6635, Val Acc: 60.00%\n",
      "Starting epoch 25\n",
      "Train Loss: 0.5668, Train Acc: 72.50%, Val Loss: 0.6616, Val Acc: 60.00%\n",
      "Starting epoch 26\n",
      "Train Loss: 0.6635, Train Acc: 77.50%, Val Loss: 0.6827, Val Acc: 60.00%\n",
      "Starting epoch 27\n",
      "Train Loss: 0.8658, Train Acc: 65.00%, Val Loss: 0.6855, Val Acc: 60.00%\n",
      "Epoch 00027: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 28\n",
      "Train Loss: 0.4838, Train Acc: 75.00%, Val Loss: 0.7130, Val Acc: 60.00%\n",
      "Early stopping triggered.\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 1.5306, Train Acc: 47.50%, Val Loss: 3.4807, Val Acc: 70.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 1.2316, Train Acc: 55.00%, Val Loss: 0.8984, Val Acc: 80.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 1.2489, Train Acc: 70.00%, Val Loss: 0.7786, Val Acc: 90.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 0.5585, Train Acc: 70.00%, Val Loss: 0.9250, Val Acc: 80.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 0.7506, Train Acc: 67.50%, Val Loss: 1.3401, Val Acc: 80.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 0.8379, Train Acc: 67.50%, Val Loss: 1.0143, Val Acc: 60.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 1.0297, Train Acc: 50.00%, Val Loss: 0.4181, Val Acc: 80.00%\n",
      "Starting epoch 8\n",
      "Train Loss: 0.9568, Train Acc: 52.50%, Val Loss: 0.4675, Val Acc: 80.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 0.8797, Train Acc: 65.00%, Val Loss: 0.6118, Val Acc: 90.00%\n",
      "Starting epoch 10\n",
      "Train Loss: 1.0112, Train Acc: 62.50%, Val Loss: 0.6278, Val Acc: 60.00%\n",
      "Starting epoch 11\n",
      "Train Loss: 0.7932, Train Acc: 77.50%, Val Loss: 0.4656, Val Acc: 80.00%\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 12\n",
      "Train Loss: 1.1037, Train Acc: 65.00%, Val Loss: 0.5711, Val Acc: 70.00%\n",
      "Starting epoch 13\n",
      "Train Loss: 1.0195, Train Acc: 57.50%, Val Loss: 0.6330, Val Acc: 90.00%\n",
      "Starting epoch 14\n",
      "Train Loss: 0.7740, Train Acc: 72.50%, Val Loss: 0.6922, Val Acc: 90.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.6293, Train Acc: 67.50%, Val Loss: 0.7061, Val Acc: 80.00%\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 16\n",
      "Train Loss: 0.7620, Train Acc: 65.00%, Val Loss: 0.6512, Val Acc: 90.00%\n",
      "Starting epoch 17\n",
      "Train Loss: 0.6466, Train Acc: 70.00%, Val Loss: 0.6745, Val Acc: 90.00%\n",
      "Starting epoch 18\n",
      "Train Loss: 0.6471, Train Acc: 70.00%, Val Loss: 0.6515, Val Acc: 90.00%\n",
      "Starting epoch 19\n",
      "Train Loss: 0.5301, Train Acc: 75.00%, Val Loss: 0.6162, Val Acc: 90.00%\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 20\n",
      "Train Loss: 0.6766, Train Acc: 55.00%, Val Loss: 0.6707, Val Acc: 90.00%\n",
      "Starting epoch 21\n",
      "Train Loss: 0.7642, Train Acc: 62.50%, Val Loss: 0.6802, Val Acc: 90.00%\n",
      "Starting epoch 22\n",
      "Train Loss: 0.5455, Train Acc: 82.50%, Val Loss: 0.6423, Val Acc: 90.00%\n",
      "Starting epoch 23\n",
      "Train Loss: 0.5342, Train Acc: 77.50%, Val Loss: 0.6531, Val Acc: 90.00%\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 24\n",
      "Train Loss: 0.5386, Train Acc: 80.00%, Val Loss: 0.6556, Val Acc: 90.00%\n",
      "Starting epoch 25\n",
      "Train Loss: 0.7842, Train Acc: 62.50%, Val Loss: 0.6201, Val Acc: 90.00%\n",
      "Starting epoch 26\n",
      "Train Loss: 0.7559, Train Acc: 67.50%, Val Loss: 0.6342, Val Acc: 90.00%\n",
      "Starting epoch 27\n",
      "Train Loss: 0.9632, Train Acc: 62.50%, Val Loss: 0.6438, Val Acc: 90.00%\n",
      "Epoch 00027: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 28\n",
      "Train Loss: 0.5554, Train Acc: 75.00%, Val Loss: 0.6410, Val Acc: 90.00%\n",
      "Starting epoch 29\n",
      "Train Loss: 0.5529, Train Acc: 72.50%, Val Loss: 0.6339, Val Acc: 90.00%\n",
      "Starting epoch 30\n",
      "Train Loss: 0.5353, Train Acc: 72.50%, Val Loss: 0.6541, Val Acc: 90.00%\n",
      "Starting epoch 31\n",
      "Train Loss: 0.4815, Train Acc: 85.00%, Val Loss: 0.6880, Val Acc: 90.00%\n",
      "Epoch 00031: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 32\n",
      "Train Loss: 0.4461, Train Acc: 75.00%, Val Loss: 0.6818, Val Acc: 90.00%\n",
      "Early stopping triggered.\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 2.5069, Train Acc: 52.50%, Val Loss: 20.3882, Val Acc: 70.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 2.0722, Train Acc: 57.50%, Val Loss: 7.3086, Val Acc: 50.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 0.9144, Train Acc: 60.00%, Val Loss: 0.5967, Val Acc: 90.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 0.8531, Train Acc: 70.00%, Val Loss: 0.7264, Val Acc: 90.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 0.7323, Train Acc: 72.50%, Val Loss: 0.9898, Val Acc: 70.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 0.6873, Train Acc: 72.50%, Val Loss: 0.9038, Val Acc: 60.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 0.6226, Train Acc: 65.00%, Val Loss: 1.2843, Val Acc: 50.00%\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 8\n",
      "Train Loss: 0.6178, Train Acc: 77.50%, Val Loss: 0.8730, Val Acc: 60.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 0.6144, Train Acc: 65.00%, Val Loss: 0.7466, Val Acc: 80.00%\n",
      "Starting epoch 10\n",
      "Train Loss: 0.6416, Train Acc: 65.00%, Val Loss: 0.6569, Val Acc: 80.00%\n",
      "Starting epoch 11\n",
      "Train Loss: 0.7900, Train Acc: 60.00%, Val Loss: 0.5843, Val Acc: 80.00%\n",
      "Starting epoch 12\n",
      "Train Loss: 0.8106, Train Acc: 70.00%, Val Loss: 0.5565, Val Acc: 80.00%\n",
      "Starting epoch 13\n",
      "Train Loss: 0.6494, Train Acc: 67.50%, Val Loss: 0.5877, Val Acc: 80.00%\n",
      "Starting epoch 14\n",
      "Train Loss: 0.5810, Train Acc: 82.50%, Val Loss: 0.5669, Val Acc: 70.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.6252, Train Acc: 72.50%, Val Loss: 0.5567, Val Acc: 80.00%\n",
      "Starting epoch 16\n",
      "Train Loss: 0.5807, Train Acc: 77.50%, Val Loss: 0.5647, Val Acc: 70.00%\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 17\n",
      "Train Loss: 0.5670, Train Acc: 70.00%, Val Loss: 0.5867, Val Acc: 70.00%\n",
      "Starting epoch 18\n",
      "Train Loss: 0.5491, Train Acc: 77.50%, Val Loss: 0.6234, Val Acc: 70.00%\n",
      "Starting epoch 19\n",
      "Train Loss: 0.3765, Train Acc: 87.50%, Val Loss: 0.6291, Val Acc: 70.00%\n",
      "Starting epoch 20\n",
      "Train Loss: 0.3927, Train Acc: 80.00%, Val Loss: 0.6466, Val Acc: 70.00%\n",
      "Epoch 00020: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 21\n",
      "Train Loss: 0.5341, Train Acc: 77.50%, Val Loss: 0.6390, Val Acc: 80.00%\n",
      "Starting epoch 22\n",
      "Train Loss: 0.2721, Train Acc: 92.50%, Val Loss: 0.6324, Val Acc: 80.00%\n",
      "Starting epoch 23\n",
      "Train Loss: 0.5124, Train Acc: 85.00%, Val Loss: 0.6500, Val Acc: 80.00%\n",
      "Starting epoch 24\n",
      "Train Loss: 0.4839, Train Acc: 75.00%, Val Loss: 0.6616, Val Acc: 70.00%\n",
      "Epoch 00024: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 25\n",
      "Train Loss: 0.4075, Train Acc: 82.50%, Val Loss: 0.6414, Val Acc: 80.00%\n",
      "Starting epoch 26\n",
      "Train Loss: 0.4352, Train Acc: 77.50%, Val Loss: 0.6492, Val Acc: 70.00%\n",
      "Starting epoch 27\n",
      "Train Loss: 0.5594, Train Acc: 72.50%, Val Loss: 0.6288, Val Acc: 80.00%\n",
      "Starting epoch 28\n",
      "Train Loss: 0.5401, Train Acc: 77.50%, Val Loss: 0.5991, Val Acc: 80.00%\n",
      "Epoch 00028: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 29\n",
      "Train Loss: 0.4762, Train Acc: 80.00%, Val Loss: 0.6309, Val Acc: 80.00%\n",
      "Starting epoch 30\n",
      "Train Loss: 0.4987, Train Acc: 75.00%, Val Loss: 0.6299, Val Acc: 80.00%\n",
      "Starting epoch 31\n",
      "Train Loss: 0.5180, Train Acc: 77.50%, Val Loss: 0.6364, Val Acc: 80.00%\n",
      "Starting epoch 32\n",
      "Train Loss: 0.6479, Train Acc: 77.50%, Val Loss: 0.6229, Val Acc: 80.00%\n",
      "Epoch 00032: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 33\n",
      "Train Loss: 0.3657, Train Acc: 85.00%, Val Loss: 0.6403, Val Acc: 70.00%\n",
      "Starting epoch 34\n",
      "Train Loss: 0.5095, Train Acc: 75.00%, Val Loss: 0.6311, Val Acc: 70.00%\n",
      "Starting epoch 35\n",
      "Train Loss: 0.5195, Train Acc: 72.50%, Val Loss: 0.6191, Val Acc: 80.00%\n",
      "Starting epoch 36\n",
      "Train Loss: 0.4323, Train Acc: 72.50%, Val Loss: 0.6267, Val Acc: 70.00%\n",
      "Starting epoch 37\n",
      "Train Loss: 0.4250, Train Acc: 77.50%, Val Loss: 0.6160, Val Acc: 70.00%\n",
      "Early stopping triggered.\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 1.3277, Train Acc: 57.50%, Val Loss: 1.0650, Val Acc: 90.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 0.9616, Train Acc: 70.00%, Val Loss: 0.8594, Val Acc: 70.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 1.4160, Train Acc: 65.00%, Val Loss: 1.0764, Val Acc: 50.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 1.2739, Train Acc: 62.50%, Val Loss: 0.8330, Val Acc: 70.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 0.6437, Train Acc: 77.50%, Val Loss: 0.4176, Val Acc: 70.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 1.3291, Train Acc: 57.50%, Val Loss: 0.6882, Val Acc: 70.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 0.6270, Train Acc: 65.00%, Val Loss: 1.5112, Val Acc: 60.00%\n",
      "Starting epoch 8\n",
      "Train Loss: 0.7781, Train Acc: 75.00%, Val Loss: 1.5895, Val Acc: 40.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 0.6623, Train Acc: 72.50%, Val Loss: 1.0285, Val Acc: 50.00%\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 10\n",
      "Train Loss: 0.8654, Train Acc: 70.00%, Val Loss: 0.8365, Val Acc: 60.00%\n",
      "Starting epoch 11\n",
      "Train Loss: 0.7158, Train Acc: 70.00%, Val Loss: 0.6320, Val Acc: 70.00%\n",
      "Starting epoch 12\n",
      "Train Loss: 0.6361, Train Acc: 65.00%, Val Loss: 0.5840, Val Acc: 70.00%\n",
      "Starting epoch 13\n",
      "Train Loss: 0.3436, Train Acc: 85.00%, Val Loss: 0.5268, Val Acc: 70.00%\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 14\n",
      "Train Loss: 0.5854, Train Acc: 75.00%, Val Loss: 0.5615, Val Acc: 70.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.5292, Train Acc: 67.50%, Val Loss: 0.5266, Val Acc: 70.00%\n",
      "Starting epoch 16\n",
      "Train Loss: 0.5429, Train Acc: 72.50%, Val Loss: 0.5370, Val Acc: 70.00%\n",
      "Starting epoch 17\n",
      "Train Loss: 0.7313, Train Acc: 72.50%, Val Loss: 0.5849, Val Acc: 60.00%\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 18\n",
      "Train Loss: 0.8961, Train Acc: 65.00%, Val Loss: 0.6087, Val Acc: 60.00%\n",
      "Starting epoch 19\n",
      "Train Loss: 0.5250, Train Acc: 75.00%, Val Loss: 0.5848, Val Acc: 70.00%\n",
      "Starting epoch 20\n",
      "Train Loss: 0.5041, Train Acc: 80.00%, Val Loss: 0.5939, Val Acc: 60.00%\n",
      "Starting epoch 21\n",
      "Train Loss: 0.7643, Train Acc: 65.00%, Val Loss: 0.6171, Val Acc: 60.00%\n",
      "Epoch 00021: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 22\n",
      "Train Loss: 0.5241, Train Acc: 82.50%, Val Loss: 0.5809, Val Acc: 70.00%\n",
      "Starting epoch 23\n",
      "Train Loss: 0.4714, Train Acc: 82.50%, Val Loss: 0.6127, Val Acc: 60.00%\n",
      "Starting epoch 24\n",
      "Train Loss: 0.6563, Train Acc: 72.50%, Val Loss: 0.6181, Val Acc: 60.00%\n",
      "Starting epoch 25\n",
      "Train Loss: 0.6735, Train Acc: 72.50%, Val Loss: 0.6193, Val Acc: 60.00%\n",
      "Epoch 00025: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 26\n",
      "Train Loss: 1.0207, Train Acc: 62.50%, Val Loss: 0.6582, Val Acc: 60.00%\n",
      "Starting epoch 27\n",
      "Train Loss: 0.6322, Train Acc: 70.00%, Val Loss: 0.6190, Val Acc: 60.00%\n",
      "Starting epoch 28\n",
      "Train Loss: 0.9074, Train Acc: 62.50%, Val Loss: 0.6121, Val Acc: 60.00%\n",
      "Starting epoch 29\n",
      "Train Loss: 0.7791, Train Acc: 70.00%, Val Loss: 0.6352, Val Acc: 60.00%\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 30\n",
      "Train Loss: 0.7339, Train Acc: 72.50%, Val Loss: 0.6051, Val Acc: 60.00%\n",
      "Early stopping triggered.\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Starting epoch 1\n",
      "Train Loss: 1.5877, Train Acc: 35.00%, Val Loss: 29.0677, Val Acc: 30.00%\n",
      "Starting epoch 2\n",
      "Train Loss: 1.2348, Train Acc: 50.00%, Val Loss: 1.4256, Val Acc: 70.00%\n",
      "Starting epoch 3\n",
      "Train Loss: 1.0064, Train Acc: 62.50%, Val Loss: 5.2976, Val Acc: 30.00%\n",
      "Starting epoch 4\n",
      "Train Loss: 1.2069, Train Acc: 57.50%, Val Loss: 1.1858, Val Acc: 80.00%\n",
      "Starting epoch 5\n",
      "Train Loss: 0.6945, Train Acc: 75.00%, Val Loss: 0.8926, Val Acc: 80.00%\n",
      "Starting epoch 6\n",
      "Train Loss: 0.7545, Train Acc: 62.50%, Val Loss: 0.7275, Val Acc: 80.00%\n",
      "Starting epoch 7\n",
      "Train Loss: 0.6965, Train Acc: 65.00%, Val Loss: 0.6451, Val Acc: 90.00%\n",
      "Starting epoch 8\n",
      "Train Loss: 1.0569, Train Acc: 72.50%, Val Loss: 0.5208, Val Acc: 90.00%\n",
      "Starting epoch 9\n",
      "Train Loss: 0.5243, Train Acc: 85.00%, Val Loss: 0.7950, Val Acc: 80.00%\n",
      "Starting epoch 10\n",
      "Train Loss: 1.1942, Train Acc: 52.50%, Val Loss: 0.7280, Val Acc: 40.00%\n",
      "Starting epoch 11\n",
      "Train Loss: 0.5191, Train Acc: 70.00%, Val Loss: 0.5530, Val Acc: 80.00%\n",
      "Starting epoch 12\n",
      "Train Loss: 0.7163, Train Acc: 60.00%, Val Loss: 0.6966, Val Acc: 50.00%\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Starting epoch 13\n",
      "Train Loss: 0.4563, Train Acc: 80.00%, Val Loss: 0.5676, Val Acc: 60.00%\n",
      "Starting epoch 14\n",
      "Train Loss: 0.6856, Train Acc: 55.00%, Val Loss: 0.5178, Val Acc: 90.00%\n",
      "Starting epoch 15\n",
      "Train Loss: 0.6465, Train Acc: 65.00%, Val Loss: 0.5116, Val Acc: 90.00%\n",
      "Starting epoch 16\n",
      "Train Loss: 0.4480, Train Acc: 75.00%, Val Loss: 0.5678, Val Acc: 60.00%\n",
      "Starting epoch 17\n",
      "Train Loss: 0.4939, Train Acc: 77.50%, Val Loss: 0.5421, Val Acc: 60.00%\n",
      "Starting epoch 18\n",
      "Train Loss: 0.4757, Train Acc: 75.00%, Val Loss: 0.5636, Val Acc: 60.00%\n",
      "Starting epoch 19\n",
      "Train Loss: 0.5099, Train Acc: 77.50%, Val Loss: 0.5848, Val Acc: 60.00%\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Starting epoch 20\n",
      "Train Loss: 0.5210, Train Acc: 72.50%, Val Loss: 0.5422, Val Acc: 60.00%\n",
      "Starting epoch 21\n",
      "Train Loss: 0.4911, Train Acc: 72.50%, Val Loss: 0.5464, Val Acc: 60.00%\n",
      "Starting epoch 22\n",
      "Train Loss: 0.6176, Train Acc: 70.00%, Val Loss: 0.5685, Val Acc: 60.00%\n",
      "Starting epoch 23\n",
      "Train Loss: 0.4757, Train Acc: 80.00%, Val Loss: 0.5117, Val Acc: 60.00%\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Starting epoch 24\n",
      "Train Loss: 0.5467, Train Acc: 77.50%, Val Loss: 0.5341, Val Acc: 60.00%\n",
      "Starting epoch 25\n",
      "Train Loss: 0.4592, Train Acc: 80.00%, Val Loss: 0.5239, Val Acc: 60.00%\n",
      "Starting epoch 26\n",
      "Train Loss: 0.6497, Train Acc: 80.00%, Val Loss: 0.5056, Val Acc: 70.00%\n",
      "Starting epoch 27\n",
      "Train Loss: 0.4940, Train Acc: 77.50%, Val Loss: 0.5144, Val Acc: 60.00%\n",
      "Starting epoch 28\n",
      "Train Loss: 0.4136, Train Acc: 82.50%, Val Loss: 0.5143, Val Acc: 60.00%\n",
      "Starting epoch 29\n",
      "Train Loss: 0.5198, Train Acc: 72.50%, Val Loss: 0.5210, Val Acc: 60.00%\n",
      "Starting epoch 30\n",
      "Train Loss: 0.7867, Train Acc: 62.50%, Val Loss: 0.4814, Val Acc: 70.00%\n",
      "Starting epoch 31\n",
      "Train Loss: 0.4098, Train Acc: 80.00%, Val Loss: 0.5040, Val Acc: 70.00%\n",
      "Starting epoch 32\n",
      "Train Loss: 0.6367, Train Acc: 80.00%, Val Loss: 0.5078, Val Acc: 60.00%\n",
      "Starting epoch 33\n",
      "Train Loss: 0.4567, Train Acc: 80.00%, Val Loss: 0.5168, Val Acc: 60.00%\n",
      "Starting epoch 34\n",
      "Train Loss: 0.6353, Train Acc: 65.00%, Val Loss: 0.5566, Val Acc: 60.00%\n",
      "Epoch 00034: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Starting epoch 35\n",
      "Train Loss: 0.6389, Train Acc: 75.00%, Val Loss: 0.5751, Val Acc: 60.00%\n",
      "Starting epoch 36\n",
      "Train Loss: 0.5649, Train Acc: 75.00%, Val Loss: 0.5442, Val Acc: 60.00%\n",
      "Starting epoch 37\n",
      "Train Loss: 0.4290, Train Acc: 85.00%, Val Loss: 0.5070, Val Acc: 70.00%\n",
      "Starting epoch 38\n",
      "Train Loss: 0.3477, Train Acc: 90.00%, Val Loss: 0.4993, Val Acc: 70.00%\n",
      "Epoch 00038: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Starting epoch 39\n",
      "Train Loss: 0.4558, Train Acc: 80.00%, Val Loss: 0.5157, Val Acc: 60.00%\n",
      "Starting epoch 40\n",
      "Train Loss: 0.4473, Train Acc: 77.50%, Val Loss: 0.4934, Val Acc: 70.00%\n",
      "Starting epoch 41\n",
      "Train Loss: 0.6139, Train Acc: 70.00%, Val Loss: 0.4890, Val Acc: 70.00%\n",
      "Starting epoch 42\n",
      "Train Loss: 0.3806, Train Acc: 82.50%, Val Loss: 0.4696, Val Acc: 70.00%\n",
      "Starting epoch 43\n",
      "Train Loss: 0.4423, Train Acc: 82.50%, Val Loss: 0.5018, Val Acc: 70.00%\n",
      "Starting epoch 44\n",
      "Train Loss: 0.4716, Train Acc: 80.00%, Val Loss: 0.4981, Val Acc: 70.00%\n",
      "Starting epoch 45\n",
      "Train Loss: 0.4257, Train Acc: 82.50%, Val Loss: 0.5311, Val Acc: 60.00%\n",
      "Starting epoch 46\n",
      "Train Loss: 0.4512, Train Acc: 75.00%, Val Loss: 0.5052, Val Acc: 70.00%\n",
      "Epoch 00046: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Starting epoch 47\n",
      "Train Loss: 0.4380, Train Acc: 85.00%, Val Loss: 0.5099, Val Acc: 70.00%\n",
      "Starting epoch 48\n",
      "Train Loss: 0.5391, Train Acc: 75.00%, Val Loss: 0.5237, Val Acc: 60.00%\n",
      "Starting epoch 49\n",
      "Train Loss: 0.5057, Train Acc: 77.50%, Val Loss: 0.5359, Val Acc: 60.00%\n",
      "Starting epoch 50\n",
      "Train Loss: 0.4299, Train Acc: 82.50%, Val Loss: 0.5082, Val Acc: 70.00%\n",
      "--------------------------------\n",
      "Best validation accuracy of 0.00% achieved, model saved as best_model.pth\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(trainset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    train_indices = [i for i, (_, label) in enumerate(trainset) if label in selected_classes]\n",
    "\n",
    "    N = 25  # Assuming we want at most N samples per selected class\n",
    "    class_counts = {label: 0 for label in selected_classes}\n",
    "    filtered_train_indices = []\n",
    "\n",
    "    for i in train_indices:\n",
    "        _, label = trainset[i]\n",
    "        if class_counts[label] < N:\n",
    "            filtered_train_indices.append(i)\n",
    "            class_counts[label] += 1\n",
    "    \n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    np.random.seed(42)  # Ensure reproducibility\n",
    "    np.random.shuffle(filtered_train_indices)  # Shuffle the indices\n",
    "    split = int(0.8 * len(filtered_train_indices))  # 80% of indices for training\n",
    "    train_idx, val_idx = filtered_train_indices[:split], filtered_train_indices[split:]\n",
    "    \n",
    "    train_subset = Subset(trainset, train_idx)\n",
    "    transformed_train_subset = TransformSubset(train_subset, transform=train_transform)\n",
    "\n",
    "    val_subset = Subset(trainset, val_idx)\n",
    "    transformed_val_subset = TransformSubset(val_subset, transform=test_transform)\n",
    "    \n",
    "    train_loader = DataLoader(transformed_train_subset, batch_size=5, shuffle=True)\n",
    "    val_loader = DataLoader(transformed_val_subset, batch_size=5, shuffle=False)\n",
    "    \n",
    "    \n",
    "    # Init the neural network\n",
    "    model = CustomCNN().to(device)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.005) \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 25\n",
    "\n",
    "    \n",
    "    # Run the training loop for defined number of epochs\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "        \n",
    "        # Perform training and validation\n",
    "        train_loss, train_accuracy = train(model, device, train_loader, optimizer, criterion)\n",
    "        val_loss, val_accuracy = validate(model, device, val_loader, criterion)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "        \n",
    "        # Save the model if it has the best val accuracy so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_weights = model.state_dict().copy()  # Save the best model weights\n",
    "            patience_counter = 0  # Reset patience\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break  # Stop training if no improvement\n",
    "        \n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step(val_loss)\n",
    "            \n",
    "    print('--------------------------------')\n",
    "    \n",
    "# Save the best model weights\n",
    "torch.save(best_model_weights, 'best_model.pth')\n",
    "print(f'Best validation accuracy of {best_val_accuracy:.2f}% achieved, model saved as best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomCNN()\n",
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = [i for i, (_, label) in enumerate(testset) if label in selected_classes]\n",
    "N = 2000  # Assuming we want at most N samples per selected class\n",
    "class_counts = {label: 0 for label in selected_classes}\n",
    "filtered_train_indices = []\n",
    "\n",
    "for i in test_indices:\n",
    "    _, label = testset[i]\n",
    "    if class_counts[label] < N:\n",
    "        filtered_train_indices.append(i)\n",
    "        class_counts[label] += 1\n",
    "\n",
    "test_subset = Subset(testset, filtered_train_indices)\n",
    "test_loader = DataLoader(test_subset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3422, Test Accuracy: 86.30%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Assuming the test_loader is already defined\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluation\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradient is needed for evaluation\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, targets)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "avg_loss = test_loss / len(test_loader)\n",
    "accuracy = 100. * correct / total\n",
    "\n",
    "print(f'Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f10e0bbdcb8a5227530b5aed21b374411d613e5cbe3bc0662ba6adc52ae7b0de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
