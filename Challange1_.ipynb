{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPn+H8dx/fhBJk3ToWjBYTc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhanup6663/COMP691_DL/blob/main/Challange1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST-Bayesian"
      ],
      "metadata": {
        "id": "j8ADh8WJxZRN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VL8nv8wixOh3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import Grayscale\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
        "])"
      ],
      "metadata": {
        "id": "rwIaJhJuxVN4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZxA6OVqxpIA",
        "outputId": "6d779365-dc2a-4fd0-c0ec-0c9717109b24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 40961279.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_classes = np.random.choice(range(10), 2, replace=False)"
      ],
      "metadata": {
        "id": "_3Uut8Yoxtkx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FfOtNldxwm4",
        "outputId": "6da6089a-4dde-4608-f5e1-6fe0b7a29ab8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_mapping = {original: new for new, original in enumerate(selected_classes)}"
      ],
      "metadata": {
        "id": "C-09supGx1rF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices = []\n",
        "test_indices = []\n",
        "\n",
        "for idx, (image, label) in enumerate(trainset):\n",
        "    if label in selected_classes:\n",
        "        train_indices.append(idx)\n",
        "\n",
        "for idx, (image, label) in enumerate(testset):\n",
        "    if label in selected_classes:\n",
        "        test_indices.append(idx)\n",
        "\n",
        "# Shuffle the indices\n",
        "np.random.shuffle(train_indices)\n",
        "np.random.shuffle(test_indices)\n",
        "\n",
        "# Check if enough samples are found for training and testing\n",
        "if len(train_indices) < 25 or len(test_indices) < 2000:\n",
        "    raise ValueError(\"Insufficient samples found for training or testing.\")"
      ],
      "metadata": {
        "id": "dgKVgYbGx5_u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices = train_indices[:25]\n",
        "test_indices = test_indices[:2000]\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=25, sampler=torch.utils.data.SubsetRandomSampler(train_indices))\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=2000, sampler=torch.utils.data.SubsetRandomSampler(test_indices))"
      ],
      "metadata": {
        "id": "HloGfVd9x-zw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "train_labels = []\n",
        "test_data = []\n",
        "test_labels = []\n",
        "\n",
        "for images, labels in trainloader:\n",
        "    for image, label in zip(images, labels):\n",
        "        train_data.append(image.numpy().flatten())\n",
        "        train_labels.append(label.item())\n",
        "\n",
        "for images, labels in testloader:\n",
        "    for image, label in zip(images, labels):\n",
        "        test_data.append(image.numpy().flatten())\n",
        "        test_labels.append(label.item())"
      ],
      "metadata": {
        "id": "XymWTPQcyCJA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.array(train_data)\n",
        "train_labels = np.array(train_labels)\n",
        "test_data = np.array(test_data)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "train_remapped = np.array([class_mapping[label] for label in train_labels])\n",
        "test_remapped = np.array([class_mapping[label] for label in test_labels])"
      ],
      "metadata": {
        "id": "qI1e7kNHyLJz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=0.70)\n",
        "X_train_pca = pca.fit_transform(np.array(train_data))\n",
        "X_test_pca = pca.transform(np.array(test_data))"
      ],
      "metadata": {
        "id": "1vYml3vJyN1O"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train_pca, np.array(train_remapped), test_size=0.2, stratify=train_remapped)"
      ],
      "metadata": {
        "id": "e6dyBUbTyQC0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(space):\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=int(space['n_estimators']),\n",
        "        max_depth=int(space['max_depth']),\n",
        "        learning_rate=space['learning_rate'],\n",
        "        subsample=space['subsample'],\n",
        "        colsample_bytree=space['colsample_bytree'],\n",
        "        reg_lambda=space['lambda'],\n",
        "        objective='multi:softmax',\n",
        "        eval_metric='mlogloss',\n",
        "        use_label_encoder=False,\n",
        "        num_class=2,  # Make sure this is correctly set\n",
        "        tree_method='gpu_hist',\n",
        "        device='gpu',  # Updated from gpu_id to device\n",
        "        seed=42,\n",
        "        early_stopping_rounds=10  # Moved here as per deprecation warning\n",
        "    )\n",
        "\n",
        "    eval_set = [(X_val, y_val)]\n",
        "    model.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n",
        "\n",
        "    predictions = model.predict(X_val)\n",
        "    accuracy = accuracy_score(y_val, predictions)\n",
        "    return {'loss': -accuracy, 'status': STATUS_OK}"
      ],
      "metadata": {
        "id": "8VqQr4ShyUbv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "space = {\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 300, 25),  # Widen the range to allow more trees\n",
        "    'max_depth': hp.choice('max_depth', [3, 4, 5, 6, 7]),  # Narrow down based on typical good performers\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),  # Focus on a range that's typically more effective\n",
        "    'subsample': hp.uniform('subsample', 0.5, 1.0),  # Narrow to focus on higher subsampling rates\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.4, 0.8),  # Adjust to focus on a moderate range\n",
        "    'lambda': hp.uniform('lambda', 0.5, 2),  # Broaden to explore the impact of regularization more\n",
        "}\n"
      ],
      "metadata": {
        "id": "ReQ3YJPjyp4s"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trials = Trials()\n",
        "best_hyperparams = fmin(fn=objective,\n",
        "                        space=space,\n",
        "                        algo=tpe.suggest,\n",
        "                        max_evals=100,\n",
        "                        trials=trials)\n",
        "\n",
        "print(f\"Best hyperparameters: {best_hyperparams}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yJNe-2wyt4Q",
        "outputId": "7efbd12f-d1d6-4c9f-ca79-818d37cb9d78"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1%|          | 1/100 [00:00<01:25,  1.15trial/s, best loss: -0.8]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:42] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  3%|▎         | 3/100 [00:01<00:31,  3.06trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  5%|▌         | 5/100 [00:01<00:30,  3.10trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  6%|▌         | 6/100 [00:02<00:32,  2.92trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  7%|▋         | 7/100 [00:02<00:34,  2.66trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  9%|▉         | 9/100 [00:03<00:26,  3.46trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10%|█         | 10/100 [00:03<00:29,  3.10trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 12%|█▏        | 12/100 [00:03<00:22,  3.85trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 13%|█▎        | 13/100 [00:04<00:24,  3.49trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 14%|█▍        | 14/100 [00:04<00:24,  3.53trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 15%|█▌        | 15/100 [00:05<00:37,  2.29trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 16%|█▌        | 16/100 [00:05<00:32,  2.56trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 17%|█▋        | 17/100 [00:05<00:28,  2.88trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 18%|█▊        | 18/100 [00:06<00:25,  3.18trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 19%|█▉        | 19/100 [00:06<00:35,  2.28trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 21%|██        | 21/100 [00:07<00:25,  3.08trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 22%|██▏       | 22/100 [00:07<00:22,  3.39trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 24%|██▍       | 24/100 [00:08<00:22,  3.35trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 25%|██▌       | 25/100 [00:08<00:20,  3.74trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 26%|██▌       | 26/100 [00:08<00:20,  3.53trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 28%|██▊       | 28/100 [00:09<00:18,  3.81trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 29%|██▉       | 29/100 [00:09<00:22,  3.17trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 30%|███       | 30/100 [00:10<00:27,  2.54trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 31%|███       | 31/100 [00:10<00:28,  2.41trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 32%|███▏      | 32/100 [00:11<00:26,  2.55trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 33%|███▎      | 33/100 [00:11<00:29,  2.29trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 34%|███▍      | 34/100 [00:12<00:31,  2.12trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 35%|███▌      | 35/100 [00:12<00:32,  2.00trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 36%|███▌      | 36/100 [00:13<00:30,  2.07trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 37%|███▋      | 37/100 [00:13<00:27,  2.32trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 38%|███▊      | 38/100 [00:13<00:26,  2.36trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 39%|███▉      | 39/100 [00:14<00:29,  2.07trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40%|████      | 40/100 [00:15<00:34,  1.74trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 41%|████      | 41/100 [00:15<00:32,  1.84trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 42%|████▏     | 42/100 [00:16<00:31,  1.85trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 44%|████▍     | 44/100 [00:16<00:21,  2.57trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45%|████▌     | 45/100 [00:16<00:16,  3.24trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 46%|████▌     | 46/100 [00:17<00:15,  3.56trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 47%|████▋     | 47/100 [00:17<00:19,  2.71trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 49%|████▉     | 49/100 [00:18<00:15,  3.39trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:36:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 50%|█████     | 50/100 [00:18<00:13,  3.61trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 51%|█████     | 51/100 [00:18<00:18,  2.69trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 53%|█████▎    | 53/100 [00:19<00:13,  3.52trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 54%|█████▍    | 54/100 [00:19<00:11,  4.02trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 56%|█████▌    | 56/100 [00:19<00:09,  4.82trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 57%|█████▋    | 57/100 [00:20<00:08,  5.26trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 58%|█████▊    | 58/100 [00:20<00:09,  4.64trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 60%|██████    | 60/100 [00:21<00:10,  3.71trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 61%|██████    | 61/100 [00:21<00:09,  4.33trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 63%|██████▎   | 63/100 [00:21<00:08,  4.18trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 64%|██████▍   | 64/100 [00:21<00:08,  4.36trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 65%|██████▌   | 65/100 [00:22<00:09,  3.82trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 66%|██████▌   | 66/100 [00:22<00:08,  4.00trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 68%|██████▊   | 68/100 [00:23<00:08,  3.87trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 69%|██████▉   | 69/100 [00:23<00:08,  3.58trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 71%|███████   | 71/100 [00:23<00:06,  4.23trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 73%|███████▎  | 73/100 [00:24<00:05,  5.19trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 74%|███████▍  | 74/100 [00:24<00:05,  4.65trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 75%|███████▌  | 75/100 [00:24<00:06,  3.91trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 76%|███████▌  | 76/100 [00:24<00:06,  3.74trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 77%|███████▋  | 77/100 [00:25<00:06,  3.81trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 79%|███████▉  | 79/100 [00:25<00:06,  3.37trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 81%|████████  | 81/100 [00:26<00:04,  3.95trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 83%|████████▎ | 83/100 [00:26<00:03,  4.84trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 85%|████████▌ | 85/100 [00:26<00:02,  5.96trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 87%|████████▋ | 87/100 [00:27<00:01,  6.82trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 88%|████████▊ | 88/100 [00:27<00:02,  5.45trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 89%|████████▉ | 89/100 [00:27<00:02,  4.63trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 91%|█████████ | 91/100 [00:28<00:01,  4.64trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 93%|█████████▎| 93/100 [00:28<00:01,  5.54trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 95%|█████████▌| 95/100 [00:28<00:00,  6.05trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 97%|█████████▋| 97/100 [00:29<00:00,  5.75trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 99%|█████████▉| 99/100 [00:29<00:00,  6.08trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 100/100 [00:29<00:00,  3.37trial/s, best loss: -1.0]\n",
            "Best hyperparameters: {'colsample_bytree': 0.5272014327939425, 'lambda': 0.8596654690757137, 'learning_rate': 0.12108884914164553, 'max_depth': 0, 'n_estimators': 250.0, 'subsample': 0.5028602630358373}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_n_estimators = int(best_hyperparams['n_estimators'])\n",
        "best_max_depth = int(best_hyperparams['max_depth'])\n",
        "best_learning_rate = best_hyperparams['learning_rate']\n",
        "best_subsample = best_hyperparams['subsample']\n",
        "best_colsample_bytree = best_hyperparams['colsample_bytree']\n",
        "best_lambda = best_hyperparams['lambda']"
      ],
      "metadata": {
        "id": "m8hb_33py0Nb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = XGBClassifier(\n",
        "    n_estimators=best_n_estimators,\n",
        "    max_depth=best_max_depth,\n",
        "    learning_rate=best_learning_rate,\n",
        "    subsample=best_subsample,\n",
        "    colsample_bytree=best_colsample_bytree,\n",
        "    reg_lambda=best_lambda,\n",
        "    objective='multi:softmax',\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False,\n",
        "    num_class=2,  # Assuming binary or two-class classification\n",
        "    tree_method='gpu_hist',\n",
        "    device='gpu',  # Or 'cpu' if not using GPU\n",
        "    seed=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "4H0TsBMTy4Mg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model.fit(X_train_pca, train_remapped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "SsLvD98Sy61T",
        "outputId": "a857a2c6-c41d-43f2-f1f7-dd24f5b7c120"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:37:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.5272014327939425, device='gpu',\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric='mlogloss', feature_types=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.12108884914164553,\n",
              "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=0, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=250, n_jobs=None, num_class=2,\n",
              "              num_parallel_tree=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.5272014327939425, device=&#x27;gpu&#x27;,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=&#x27;mlogloss&#x27;, feature_types=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.12108884914164553,\n",
              "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=0, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=250, n_jobs=None, num_class=2,\n",
              "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.5272014327939425, device=&#x27;gpu&#x27;,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=&#x27;mlogloss&#x27;, feature_types=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.12108884914164553,\n",
              "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=0, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=250, n_jobs=None, num_class=2,\n",
              "              num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trained_model.predict(X_test_pca)"
      ],
      "metadata": {
        "id": "jiMP28U-y9pl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XGBoost_accuracy = accuracy_score(test_remapped, predictions)\n",
        "print(f'XGBoost Test Accuracy: {XGBoost_accuracy*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEHeXC4dzBMY",
        "outputId": "06aa9fd1-7e82-43a3-e8f6-11de8021bed7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Test Accuracy: 67.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom CNN"
      ],
      "metadata": {
        "id": "ae3e2NTgzaVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset,DataLoader, Subset, random_split\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "Lv2lkstnzdke"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT1zsMaRziqi",
        "outputId": "3c5f95da-b2a6-40a6-c012-9d57aeeb84be"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
        "])"
      ],
      "metadata": {
        "id": "3PcZBRcczn3W"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZLpijKXzr7w",
        "outputId": "44f66199-6639-4dda-c88b-fc7b9825cb71"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformSubset(Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.subset[idx]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "xQrT2HiszunH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "iLk_Cfl8zxAK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_folds = 5\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "hi6Ppgnzz06v"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_accuracy = 0\n",
        "best_model_weights = None"
      ],
      "metadata": {
        "id": "-GnSzhulz3nF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "fsVuNHkcz6Gf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, device, val_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, targets) in enumerate(val_loader):\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, targets)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "95RXjepHz81S"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold, (train_ids, val_ids) in enumerate(kfold.split(trainset)):\n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "\n",
        "    train_indices = [i for i, (_, label) in enumerate(trainset) if label in selected_classes]\n",
        "\n",
        "    N = 25\n",
        "    class_counts = {label: 0 for label in selected_classes}\n",
        "    filtered_train_indices = []\n",
        "\n",
        "    for i in train_indices:\n",
        "        _, label = trainset[i]\n",
        "        if class_counts[label] < N:\n",
        "            filtered_train_indices.append(i)\n",
        "            class_counts[label] += 1\n",
        "\n",
        "\n",
        "    np.random.seed(42)\n",
        "    np.random.shuffle(filtered_train_indices)\n",
        "    split = int(0.8 * len(filtered_train_indices))\n",
        "    train_idx, val_idx = filtered_train_indices[:split], filtered_train_indices[split:]\n",
        "\n",
        "    train_subset = Subset(trainset, train_idx)\n",
        "    transformed_train_subset = TransformSubset(train_subset, transform=train_transform)\n",
        "\n",
        "    val_subset = Subset(trainset, val_idx)\n",
        "    transformed_val_subset = TransformSubset(val_subset, transform=test_transform)\n",
        "\n",
        "    train_loader = DataLoader(transformed_train_subset, batch_size=5, shuffle=True)\n",
        "    val_loader = DataLoader(transformed_val_subset, batch_size=5, shuffle=False)\n",
        "\n",
        "\n",
        "    # Init the neural network\n",
        "    model = CustomCNN().to(device)\n",
        "\n",
        "    # Initialize optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.005)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Initilization of scheduler\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    patience = 25\n",
        "\n",
        "\n",
        "    # Run the training loop for defined number of epochs\n",
        "    num_epochs = 50\n",
        "    for epoch in range(num_epochs):\n",
        "        # Print epoch\n",
        "        print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "        # Perform training and validation\n",
        "        train_loss, train_accuracy = train(model, device, train_loader, optimizer, criterion)\n",
        "        val_loss, val_accuracy = validate(model, device, val_loader, criterion)\n",
        "\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
        "\n",
        "        # Save the model if it has the best val accuracy so far\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "             # Save the best model weights\n",
        "            best_model_weights = model.state_dict().copy()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            # Stop training if no improvement\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Step the learning rate scheduler\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "    print('--------------------------------')\n",
        "\n",
        "# Save the best model weights\n",
        "torch.save(best_model_weights, 'CNN_best_model.pth')\n",
        "print(f'Best validation accuracy of {best_val_accuracy:.2f}% achieved, model saved as CNN_best_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqTLV2H6z_hT",
        "outputId": "f1e30022-76c5-4916-e169-d8fd9fe67788"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 0\n",
            "--------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "Train Loss: 1.3393, Train Acc: 40.00%, Val Loss: 1.5199, Val Acc: 80.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.8589, Train Acc: 72.50%, Val Loss: 1.8797, Val Acc: 40.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 0.6696, Train Acc: 67.50%, Val Loss: 0.3986, Val Acc: 90.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 0.7166, Train Acc: 70.00%, Val Loss: 0.4260, Val Acc: 80.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.6617, Train Acc: 72.50%, Val Loss: 0.4396, Val Acc: 80.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.9355, Train Acc: 80.00%, Val Loss: 0.4178, Val Acc: 80.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.8882, Train Acc: 65.00%, Val Loss: 0.2145, Val Acc: 90.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.4151, Train Acc: 82.50%, Val Loss: 0.2993, Val Acc: 90.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.8163, Train Acc: 80.00%, Val Loss: 0.3189, Val Acc: 80.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.9376, Train Acc: 62.50%, Val Loss: 0.3338, Val Acc: 90.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.6438, Train Acc: 75.00%, Val Loss: 0.3375, Val Acc: 80.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.3766, Train Acc: 80.00%, Val Loss: 0.3858, Val Acc: 70.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.5231, Train Acc: 82.50%, Val Loss: 0.3735, Val Acc: 80.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.3568, Train Acc: 85.00%, Val Loss: 0.3318, Val Acc: 90.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.3425, Train Acc: 87.50%, Val Loss: 0.3289, Val Acc: 90.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.5786, Train Acc: 80.00%, Val Loss: 0.3138, Val Acc: 90.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.3218, Train Acc: 85.00%, Val Loss: 0.3092, Val Acc: 90.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.7998, Train Acc: 87.50%, Val Loss: 0.3228, Val Acc: 90.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.3456, Train Acc: 82.50%, Val Loss: 0.3242, Val Acc: 90.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.4965, Train Acc: 87.50%, Val Loss: 0.2948, Val Acc: 90.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.2864, Train Acc: 82.50%, Val Loss: 0.3117, Val Acc: 90.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.3929, Train Acc: 80.00%, Val Loss: 0.2932, Val Acc: 90.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.4831, Train Acc: 82.50%, Val Loss: 0.2993, Val Acc: 90.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.4102, Train Acc: 77.50%, Val Loss: 0.3160, Val Acc: 90.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.4838, Train Acc: 82.50%, Val Loss: 0.3273, Val Acc: 90.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.7830, Train Acc: 80.00%, Val Loss: 0.2943, Val Acc: 90.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.5906, Train Acc: 80.00%, Val Loss: 0.3019, Val Acc: 90.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.5034, Train Acc: 80.00%, Val Loss: 0.3037, Val Acc: 90.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.5251, Train Acc: 80.00%, Val Loss: 0.3175, Val Acc: 90.00%\n",
            "Starting epoch 30\n",
            "Train Loss: 0.5369, Train Acc: 75.00%, Val Loss: 0.3319, Val Acc: 90.00%\n",
            "Starting epoch 31\n",
            "Train Loss: 0.5193, Train Acc: 82.50%, Val Loss: 0.3172, Val Acc: 90.00%\n",
            "Starting epoch 32\n",
            "Train Loss: 0.3792, Train Acc: 90.00%, Val Loss: 0.3192, Val Acc: 90.00%\n",
            "Early stopping triggered.\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 0.9381, Train Acc: 52.50%, Val Loss: 9.9525, Val Acc: 40.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.9241, Train Acc: 80.00%, Val Loss: 0.7699, Val Acc: 90.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 1.5878, Train Acc: 57.50%, Val Loss: 0.6245, Val Acc: 60.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 1.4927, Train Acc: 60.00%, Val Loss: 0.8276, Val Acc: 90.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 1.6653, Train Acc: 70.00%, Val Loss: 0.4748, Val Acc: 80.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.4804, Train Acc: 72.50%, Val Loss: 0.6420, Val Acc: 70.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.4558, Train Acc: 82.50%, Val Loss: 0.6568, Val Acc: 70.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.4276, Train Acc: 80.00%, Val Loss: 0.6297, Val Acc: 70.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.3593, Train Acc: 80.00%, Val Loss: 0.3054, Val Acc: 90.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.6307, Train Acc: 77.50%, Val Loss: 0.3995, Val Acc: 90.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.5410, Train Acc: 67.50%, Val Loss: 0.5472, Val Acc: 80.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.4692, Train Acc: 87.50%, Val Loss: 0.4344, Val Acc: 70.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.5659, Train Acc: 72.50%, Val Loss: 0.7402, Val Acc: 70.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.5025, Train Acc: 77.50%, Val Loss: 0.3618, Val Acc: 80.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.3683, Train Acc: 80.00%, Val Loss: 0.2163, Val Acc: 90.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.2024, Train Acc: 92.50%, Val Loss: 0.1716, Val Acc: 100.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.5485, Train Acc: 75.00%, Val Loss: 0.1943, Val Acc: 90.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.3729, Train Acc: 85.00%, Val Loss: 0.1982, Val Acc: 90.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.3536, Train Acc: 82.50%, Val Loss: 0.1971, Val Acc: 90.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.5481, Train Acc: 82.50%, Val Loss: 0.2097, Val Acc: 90.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.3732, Train Acc: 80.00%, Val Loss: 0.1801, Val Acc: 100.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.4366, Train Acc: 90.00%, Val Loss: 0.1621, Val Acc: 100.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.2755, Train Acc: 80.00%, Val Loss: 0.1670, Val Acc: 100.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.3129, Train Acc: 87.50%, Val Loss: 0.1561, Val Acc: 100.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.2957, Train Acc: 87.50%, Val Loss: 0.1633, Val Acc: 100.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.2692, Train Acc: 87.50%, Val Loss: 0.1561, Val Acc: 100.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.6531, Train Acc: 72.50%, Val Loss: 0.1588, Val Acc: 100.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.2486, Train Acc: 87.50%, Val Loss: 0.1547, Val Acc: 100.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.5115, Train Acc: 75.00%, Val Loss: 0.1509, Val Acc: 100.00%\n",
            "Starting epoch 30\n",
            "Train Loss: 0.4732, Train Acc: 90.00%, Val Loss: 0.1552, Val Acc: 100.00%\n",
            "Starting epoch 31\n",
            "Train Loss: 0.3558, Train Acc: 90.00%, Val Loss: 0.1606, Val Acc: 100.00%\n",
            "Starting epoch 32\n",
            "Train Loss: 0.6327, Train Acc: 72.50%, Val Loss: 0.1568, Val Acc: 100.00%\n",
            "Starting epoch 33\n",
            "Train Loss: 0.3346, Train Acc: 87.50%, Val Loss: 0.1641, Val Acc: 100.00%\n",
            "Starting epoch 34\n",
            "Train Loss: 0.4140, Train Acc: 82.50%, Val Loss: 0.1568, Val Acc: 100.00%\n",
            "Starting epoch 35\n",
            "Train Loss: 0.3977, Train Acc: 85.00%, Val Loss: 0.1639, Val Acc: 100.00%\n",
            "Starting epoch 36\n",
            "Train Loss: 0.2102, Train Acc: 92.50%, Val Loss: 0.1597, Val Acc: 100.00%\n",
            "Starting epoch 37\n",
            "Train Loss: 0.3285, Train Acc: 85.00%, Val Loss: 0.1622, Val Acc: 100.00%\n",
            "Starting epoch 38\n",
            "Train Loss: 0.6268, Train Acc: 75.00%, Val Loss: 0.1465, Val Acc: 100.00%\n",
            "Starting epoch 39\n",
            "Train Loss: 0.3326, Train Acc: 82.50%, Val Loss: 0.1421, Val Acc: 100.00%\n",
            "Starting epoch 40\n",
            "Train Loss: 0.4099, Train Acc: 82.50%, Val Loss: 0.1503, Val Acc: 100.00%\n",
            "Starting epoch 41\n",
            "Train Loss: 0.2641, Train Acc: 90.00%, Val Loss: 0.1528, Val Acc: 100.00%\n",
            "Starting epoch 42\n",
            "Train Loss: 0.3007, Train Acc: 90.00%, Val Loss: 0.1539, Val Acc: 100.00%\n",
            "Starting epoch 43\n",
            "Train Loss: 0.3514, Train Acc: 90.00%, Val Loss: 0.1506, Val Acc: 100.00%\n",
            "Starting epoch 44\n",
            "Train Loss: 0.1922, Train Acc: 97.50%, Val Loss: 0.1522, Val Acc: 100.00%\n",
            "Starting epoch 45\n",
            "Train Loss: 0.2727, Train Acc: 87.50%, Val Loss: 0.1586, Val Acc: 100.00%\n",
            "Starting epoch 46\n",
            "Train Loss: 0.4640, Train Acc: 82.50%, Val Loss: 0.1604, Val Acc: 100.00%\n",
            "Starting epoch 47\n",
            "Train Loss: 0.6409, Train Acc: 80.00%, Val Loss: 0.1573, Val Acc: 100.00%\n",
            "Starting epoch 48\n",
            "Train Loss: 0.2292, Train Acc: 92.50%, Val Loss: 0.1537, Val Acc: 100.00%\n",
            "Starting epoch 49\n",
            "Train Loss: 0.3383, Train Acc: 85.00%, Val Loss: 0.1560, Val Acc: 100.00%\n",
            "Starting epoch 50\n",
            "Train Loss: 0.4029, Train Acc: 80.00%, Val Loss: 0.1597, Val Acc: 100.00%\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 1.0025, Train Acc: 62.50%, Val Loss: 0.2697, Val Acc: 80.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.8677, Train Acc: 72.50%, Val Loss: 2.4118, Val Acc: 80.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 1.5807, Train Acc: 67.50%, Val Loss: 0.4189, Val Acc: 80.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 1.0286, Train Acc: 77.50%, Val Loss: 0.2917, Val Acc: 90.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.9131, Train Acc: 57.50%, Val Loss: 0.3596, Val Acc: 80.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.4849, Train Acc: 80.00%, Val Loss: 0.3636, Val Acc: 70.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.3088, Train Acc: 87.50%, Val Loss: 0.3481, Val Acc: 70.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.3175, Train Acc: 87.50%, Val Loss: 0.3307, Val Acc: 80.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.3408, Train Acc: 87.50%, Val Loss: 0.3393, Val Acc: 80.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.6372, Train Acc: 82.50%, Val Loss: 0.3381, Val Acc: 80.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.6719, Train Acc: 65.00%, Val Loss: 0.3157, Val Acc: 80.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.5654, Train Acc: 82.50%, Val Loss: 0.3208, Val Acc: 80.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.5199, Train Acc: 80.00%, Val Loss: 0.3096, Val Acc: 80.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.4849, Train Acc: 82.50%, Val Loss: 0.3064, Val Acc: 80.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.7321, Train Acc: 72.50%, Val Loss: 0.3042, Val Acc: 80.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.3671, Train Acc: 82.50%, Val Loss: 0.3123, Val Acc: 80.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.7895, Train Acc: 77.50%, Val Loss: 0.3075, Val Acc: 80.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.2747, Train Acc: 87.50%, Val Loss: 0.3235, Val Acc: 80.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.6503, Train Acc: 77.50%, Val Loss: 0.3340, Val Acc: 80.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.4194, Train Acc: 77.50%, Val Loss: 0.3265, Val Acc: 80.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.4662, Train Acc: 82.50%, Val Loss: 0.3230, Val Acc: 80.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.4403, Train Acc: 75.00%, Val Loss: 0.3188, Val Acc: 80.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.3899, Train Acc: 90.00%, Val Loss: 0.3167, Val Acc: 80.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.5734, Train Acc: 85.00%, Val Loss: 0.3188, Val Acc: 80.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.6541, Train Acc: 75.00%, Val Loss: 0.3258, Val Acc: 80.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.5779, Train Acc: 75.00%, Val Loss: 0.3192, Val Acc: 80.00%\n",
            "Early stopping triggered.\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 0.8442, Train Acc: 62.50%, Val Loss: 0.0024, Val Acc: 100.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 1.4166, Train Acc: 65.00%, Val Loss: 5.1036, Val Acc: 60.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 0.9857, Train Acc: 82.50%, Val Loss: 0.2139, Val Acc: 90.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 0.7276, Train Acc: 72.50%, Val Loss: 0.8760, Val Acc: 80.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.7079, Train Acc: 72.50%, Val Loss: 0.5129, Val Acc: 80.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.5397, Train Acc: 87.50%, Val Loss: 0.3927, Val Acc: 80.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.9238, Train Acc: 72.50%, Val Loss: 0.4158, Val Acc: 80.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.3847, Train Acc: 85.00%, Val Loss: 0.4696, Val Acc: 80.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 1.0630, Train Acc: 87.50%, Val Loss: 0.3810, Val Acc: 80.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.3952, Train Acc: 90.00%, Val Loss: 0.4123, Val Acc: 80.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.3594, Train Acc: 92.50%, Val Loss: 0.4224, Val Acc: 80.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.4279, Train Acc: 82.50%, Val Loss: 0.4130, Val Acc: 80.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.6340, Train Acc: 87.50%, Val Loss: 0.3916, Val Acc: 80.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.5679, Train Acc: 80.00%, Val Loss: 0.4272, Val Acc: 80.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.3802, Train Acc: 90.00%, Val Loss: 0.4493, Val Acc: 70.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.7650, Train Acc: 77.50%, Val Loss: 0.4162, Val Acc: 80.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.5536, Train Acc: 85.00%, Val Loss: 0.3979, Val Acc: 80.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.2297, Train Acc: 92.50%, Val Loss: 0.4046, Val Acc: 80.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 1.2265, Train Acc: 67.50%, Val Loss: 0.3993, Val Acc: 80.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.4864, Train Acc: 82.50%, Val Loss: 0.3917, Val Acc: 80.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.3833, Train Acc: 80.00%, Val Loss: 0.4119, Val Acc: 80.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.8087, Train Acc: 77.50%, Val Loss: 0.4455, Val Acc: 80.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.2386, Train Acc: 95.00%, Val Loss: 0.4232, Val Acc: 80.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.3005, Train Acc: 87.50%, Val Loss: 0.4168, Val Acc: 80.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.4712, Train Acc: 85.00%, Val Loss: 0.4531, Val Acc: 70.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.3686, Train Acc: 85.00%, Val Loss: 0.4279, Val Acc: 80.00%\n",
            "Early stopping triggered.\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 1.2054, Train Acc: 60.00%, Val Loss: 5.2991, Val Acc: 70.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 1.4173, Train Acc: 65.00%, Val Loss: 1.7529, Val Acc: 90.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 1.3432, Train Acc: 72.50%, Val Loss: 0.0135, Val Acc: 100.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 1.3325, Train Acc: 70.00%, Val Loss: 0.4131, Val Acc: 80.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 1.0962, Train Acc: 67.50%, Val Loss: 0.8814, Val Acc: 70.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.7752, Train Acc: 72.50%, Val Loss: 1.9103, Val Acc: 80.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.6266, Train Acc: 87.50%, Val Loss: 0.5008, Val Acc: 80.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.7445, Train Acc: 70.00%, Val Loss: 0.4068, Val Acc: 80.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 1.1070, Train Acc: 72.50%, Val Loss: 0.3475, Val Acc: 80.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.5302, Train Acc: 85.00%, Val Loss: 0.2933, Val Acc: 80.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.4414, Train Acc: 85.00%, Val Loss: 0.2677, Val Acc: 80.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.5797, Train Acc: 75.00%, Val Loss: 0.2597, Val Acc: 80.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.6789, Train Acc: 75.00%, Val Loss: 0.3001, Val Acc: 80.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.4510, Train Acc: 82.50%, Val Loss: 0.3440, Val Acc: 90.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.5386, Train Acc: 72.50%, Val Loss: 0.3058, Val Acc: 90.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.2908, Train Acc: 85.00%, Val Loss: 0.2482, Val Acc: 80.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.4874, Train Acc: 82.50%, Val Loss: 0.2811, Val Acc: 80.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.5648, Train Acc: 80.00%, Val Loss: 0.3133, Val Acc: 90.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.4851, Train Acc: 87.50%, Val Loss: 0.3003, Val Acc: 90.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.2521, Train Acc: 95.00%, Val Loss: 0.2950, Val Acc: 90.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.2998, Train Acc: 87.50%, Val Loss: 0.2863, Val Acc: 90.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.6903, Train Acc: 82.50%, Val Loss: 0.2913, Val Acc: 80.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.4801, Train Acc: 85.00%, Val Loss: 0.3376, Val Acc: 90.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.5091, Train Acc: 82.50%, Val Loss: 0.2821, Val Acc: 80.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.6056, Train Acc: 80.00%, Val Loss: 0.2487, Val Acc: 80.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.4277, Train Acc: 82.50%, Val Loss: 0.2853, Val Acc: 80.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.6931, Train Acc: 75.00%, Val Loss: 0.2836, Val Acc: 80.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.4746, Train Acc: 80.00%, Val Loss: 0.2731, Val Acc: 80.00%\n",
            "Early stopping triggered.\n",
            "--------------------------------\n",
            "Best validation accuracy of 0.00% achieved, model saved as CNN_best_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomCNN().to(device)\n",
        "model.load_state_dict(torch.load('CNN_best_model.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d26EESam0Ra_",
        "outputId": "56008348-0bf3-46ae-ce42-00b2762f7a18"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_indices = [i for i, (_, label) in enumerate(testset) if label in selected_classes]\n",
        "N = 1000\n",
        "class_counts = {label: 0 for label in selected_classes}\n",
        "filtered_train_indices = []\n",
        "\n",
        "for i in test_indices:\n",
        "    _, label = testset[i]\n",
        "    if class_counts[label] < N:\n",
        "        filtered_train_indices.append(i)\n",
        "        class_counts[label] += 1\n",
        "\n",
        "test_subset = Subset(testset, filtered_train_indices)\n",
        "test_loader = DataLoader(test_subset, batch_size=50, shuffle=False)"
      ],
      "metadata": {
        "id": "Q4lA20QG0VDj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Assuming the test_loader and the device are already defined\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Evaluation\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# No gradient is needed for evaluation\n",
        "with torch.no_grad():\n",
        "    for data, targets in test_loader:\n",
        "        # Move data and targets to the correct device\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Compute the model output\n",
        "        output = model(data)\n",
        "        loss = criterion(output, targets)\n",
        "\n",
        "        # Accumulate the loss and calculate accuracy\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "# Calculate average loss and accuracy percentage\n",
        "Custom_CNN_avg_loss = test_loss / len(test_loader)\n",
        "Custom_CNN_accuracy = 100. * correct / total\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f'Test Loss: {Custom_CNN_avg_loss:.4f}, Test Accuracy: {Custom_CNN_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U04_oE20Xoy",
        "outputId": "21619d35-4670-4e37-a011-22b2c66dd154"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.4922, Test Accuracy: 83.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIT"
      ],
      "metadata": {
        "id": "XebeXoNM08xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "metadata": {
        "id": "Z6rplEZO1LtQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(224, padding=4),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
        "])"
      ],
      "metadata": {
        "id": "GSqrt1sI1kYn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vit_b_16(pretrained=False)\n",
        "\n",
        "num_classes = 10\n",
        "dropout_rate = 0.5\n",
        "\n",
        "model.heads = nn.Sequential(\n",
        "    nn.Dropout(p=dropout_rate),\n",
        "    nn.Linear(model.heads[0].in_features, num_classes)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0eZmkGO08gt",
        "outputId": "204f72dc-cc9d-4054-fa77-ddfc39d7bdea"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_accuracy = 0\n",
        "best_model_weights = None"
      ],
      "metadata": {
        "id": "Spq1rIw20qNS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold, (train_ids, val_ids) in enumerate(kfold.split(trainset)):\n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "\n",
        "    train_indices = [i for i, (_, label) in enumerate(trainset) if label in selected_classes]\n",
        "\n",
        "    N = 25\n",
        "    class_counts = {label: 0 for label in selected_classes}\n",
        "    filtered_train_indices = []\n",
        "\n",
        "    for i in train_indices:\n",
        "        _, label = trainset[i]\n",
        "        if class_counts[label] < N:\n",
        "            filtered_train_indices.append(i)\n",
        "            class_counts[label] += 1\n",
        "\n",
        "\n",
        "    np.random.seed(42)\n",
        "    np.random.shuffle(filtered_train_indices)\n",
        "    split = int(0.8 * len(filtered_train_indices))\n",
        "    train_idx, val_idx = filtered_train_indices[:split], filtered_train_indices[split:]\n",
        "\n",
        "    train_subset = Subset(trainset, train_idx)\n",
        "    transformed_train_subset = TransformSubset(train_subset, transform=train_transform)\n",
        "\n",
        "    val_subset = Subset(trainset, val_idx)\n",
        "    transformed_val_subset = TransformSubset(val_subset, transform=test_transform)\n",
        "\n",
        "    train_loader = DataLoader(transformed_train_subset, batch_size=5, shuffle=True)\n",
        "    val_loader = DataLoader(transformed_val_subset, batch_size=5, shuffle=False)\n",
        "\n",
        "\n",
        "    # Init the neural network\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Initialize optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=2e-5, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    patience = 25\n",
        "\n",
        "\n",
        "    # Run the training loop for defined number of epochs\n",
        "    num_epochs = 50\n",
        "    for epoch in range(num_epochs):\n",
        "        # Print epoch\n",
        "        print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "        # Perform training and validation\n",
        "        train_loss, train_accuracy = train(model, device, train_loader, optimizer, criterion)\n",
        "        val_loss, val_accuracy = validate(model, device, val_loader, criterion)\n",
        "\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
        "\n",
        "        # Save the model if it has the best val accuracy so far\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_weights = model.state_dict().copy()  # Save the best model weights\n",
        "            patience_counter = 0  # Reset patience\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break  # Stop training if no improvement\n",
        "\n",
        "        # Step the learning rate scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "    print('--------------------------------')\n",
        "\n",
        "# Save the best model weights\n",
        "torch.save(best_model_weights, 'VIT_best_model.pth')\n",
        "print(f'Best validation accuracy of {best_val_accuracy:.2f}% achieved, model saved as VIT_best_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP-3mRNA1V0w",
        "outputId": "4aa64729-a410-4342-cf1f-9bc415d4cf09"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 0\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 0.9218, Train Acc: 67.50%, Val Loss: 0.1587, Val Acc: 90.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.2067, Train Acc: 87.50%, Val Loss: 0.1711, Val Acc: 90.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 0.2526, Train Acc: 95.00%, Val Loss: 0.0976, Val Acc: 100.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 0.2904, Train Acc: 90.00%, Val Loss: 0.0871, Val Acc: 100.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.2953, Train Acc: 82.50%, Val Loss: 0.0653, Val Acc: 100.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.1474, Train Acc: 95.00%, Val Loss: 0.1687, Val Acc: 90.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.3307, Train Acc: 87.50%, Val Loss: 0.0576, Val Acc: 100.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.2096, Train Acc: 90.00%, Val Loss: 0.0436, Val Acc: 100.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.1899, Train Acc: 90.00%, Val Loss: 0.0357, Val Acc: 100.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.1076, Train Acc: 97.50%, Val Loss: 0.0524, Val Acc: 100.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.1804, Train Acc: 95.00%, Val Loss: 0.0433, Val Acc: 100.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.0549, Train Acc: 100.00%, Val Loss: 0.0455, Val Acc: 100.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.2015, Train Acc: 95.00%, Val Loss: 0.0497, Val Acc: 100.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.2123, Train Acc: 90.00%, Val Loss: 0.0735, Val Acc: 100.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.2447, Train Acc: 92.50%, Val Loss: 0.0525, Val Acc: 100.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.1312, Train Acc: 92.50%, Val Loss: 0.0508, Val Acc: 100.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.1863, Train Acc: 95.00%, Val Loss: 0.0568, Val Acc: 100.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.0831, Train Acc: 100.00%, Val Loss: 0.0534, Val Acc: 100.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.1872, Train Acc: 97.50%, Val Loss: 0.0378, Val Acc: 100.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.1184, Train Acc: 95.00%, Val Loss: 0.0673, Val Acc: 100.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.1285, Train Acc: 95.00%, Val Loss: 0.0264, Val Acc: 100.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.0220, Train Acc: 100.00%, Val Loss: 0.0167, Val Acc: 100.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.0701, Train Acc: 95.00%, Val Loss: 0.0127, Val Acc: 100.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.1150, Train Acc: 97.50%, Val Loss: 0.0207, Val Acc: 100.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.0814, Train Acc: 97.50%, Val Loss: 0.0327, Val Acc: 100.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.0396, Train Acc: 100.00%, Val Loss: 0.0443, Val Acc: 100.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.1029, Train Acc: 95.00%, Val Loss: 0.0499, Val Acc: 100.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.0621, Train Acc: 97.50%, Val Loss: 0.0192, Val Acc: 100.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.0584, Train Acc: 97.50%, Val Loss: 0.0104, Val Acc: 100.00%\n",
            "Starting epoch 30\n",
            "Train Loss: 0.0257, Train Acc: 97.50%, Val Loss: 0.0211, Val Acc: 100.00%\n",
            "Starting epoch 31\n",
            "Train Loss: 0.0208, Train Acc: 100.00%, Val Loss: 0.0425, Val Acc: 100.00%\n",
            "Starting epoch 32\n",
            "Train Loss: 0.0102, Train Acc: 100.00%, Val Loss: 0.0481, Val Acc: 100.00%\n",
            "Starting epoch 33\n",
            "Train Loss: 0.0199, Train Acc: 100.00%, Val Loss: 0.0399, Val Acc: 100.00%\n",
            "Starting epoch 34\n",
            "Train Loss: 0.0626, Train Acc: 97.50%, Val Loss: 0.0321, Val Acc: 100.00%\n",
            "Starting epoch 35\n",
            "Train Loss: 0.0191, Train Acc: 100.00%, Val Loss: 0.0315, Val Acc: 100.00%\n",
            "Starting epoch 36\n",
            "Train Loss: 0.0115, Train Acc: 100.00%, Val Loss: 0.0338, Val Acc: 100.00%\n",
            "Starting epoch 37\n",
            "Train Loss: 0.0455, Train Acc: 97.50%, Val Loss: 0.0370, Val Acc: 100.00%\n",
            "Starting epoch 38\n",
            "Train Loss: 0.0316, Train Acc: 97.50%, Val Loss: 0.0635, Val Acc: 100.00%\n",
            "Starting epoch 39\n",
            "Train Loss: 0.0184, Train Acc: 100.00%, Val Loss: 0.0809, Val Acc: 90.00%\n",
            "Starting epoch 40\n",
            "Train Loss: 0.0125, Train Acc: 100.00%, Val Loss: 0.0795, Val Acc: 90.00%\n",
            "Starting epoch 41\n",
            "Train Loss: 0.0239, Train Acc: 100.00%, Val Loss: 0.0854, Val Acc: 90.00%\n",
            "Starting epoch 42\n",
            "Train Loss: 0.0147, Train Acc: 100.00%, Val Loss: 0.0818, Val Acc: 90.00%\n",
            "Starting epoch 43\n",
            "Train Loss: 0.0125, Train Acc: 100.00%, Val Loss: 0.0704, Val Acc: 100.00%\n",
            "Starting epoch 44\n",
            "Train Loss: 0.0236, Train Acc: 100.00%, Val Loss: 0.0519, Val Acc: 100.00%\n",
            "Starting epoch 45\n",
            "Train Loss: 0.0079, Train Acc: 100.00%, Val Loss: 0.0373, Val Acc: 100.00%\n",
            "Starting epoch 46\n",
            "Train Loss: 0.0471, Train Acc: 97.50%, Val Loss: 0.0320, Val Acc: 100.00%\n",
            "Starting epoch 47\n",
            "Train Loss: 0.0289, Train Acc: 100.00%, Val Loss: 0.0236, Val Acc: 100.00%\n",
            "Starting epoch 48\n",
            "Train Loss: 0.0247, Train Acc: 100.00%, Val Loss: 0.0181, Val Acc: 100.00%\n",
            "Starting epoch 49\n",
            "Train Loss: 0.0496, Train Acc: 97.50%, Val Loss: 0.0230, Val Acc: 100.00%\n",
            "Starting epoch 50\n",
            "Train Loss: 0.0620, Train Acc: 97.50%, Val Loss: 0.0327, Val Acc: 100.00%\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 0.3356, Train Acc: 90.00%, Val Loss: 0.0086, Val Acc: 100.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.0282, Train Acc: 100.00%, Val Loss: 0.0197, Val Acc: 100.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 0.1529, Train Acc: 95.00%, Val Loss: 0.0840, Val Acc: 90.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 0.1373, Train Acc: 92.50%, Val Loss: 0.1690, Val Acc: 90.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.0935, Train Acc: 97.50%, Val Loss: 0.0783, Val Acc: 100.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.0876, Train Acc: 97.50%, Val Loss: 0.0418, Val Acc: 100.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.0219, Train Acc: 100.00%, Val Loss: 0.0203, Val Acc: 100.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.0501, Train Acc: 97.50%, Val Loss: 0.0037, Val Acc: 100.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.1998, Train Acc: 90.00%, Val Loss: 0.0083, Val Acc: 100.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.0324, Train Acc: 100.00%, Val Loss: 0.0535, Val Acc: 100.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.0338, Train Acc: 97.50%, Val Loss: 0.1130, Val Acc: 90.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.0795, Train Acc: 97.50%, Val Loss: 0.0370, Val Acc: 100.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.0157, Train Acc: 100.00%, Val Loss: 0.0090, Val Acc: 100.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.0574, Train Acc: 97.50%, Val Loss: 0.0042, Val Acc: 100.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.0108, Train Acc: 100.00%, Val Loss: 0.0032, Val Acc: 100.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.0780, Train Acc: 97.50%, Val Loss: 0.0031, Val Acc: 100.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.0355, Train Acc: 97.50%, Val Loss: 0.0042, Val Acc: 100.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.0098, Train Acc: 100.00%, Val Loss: 0.0028, Val Acc: 100.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.0171, Train Acc: 100.00%, Val Loss: 0.0018, Val Acc: 100.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.0119, Train Acc: 100.00%, Val Loss: 0.0011, Val Acc: 100.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.0138, Train Acc: 100.00%, Val Loss: 0.0010, Val Acc: 100.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.0025, Train Acc: 100.00%, Val Loss: 0.0010, Val Acc: 100.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.0565, Train Acc: 97.50%, Val Loss: 0.0009, Val Acc: 100.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.0026, Train Acc: 100.00%, Val Loss: 0.0034, Val Acc: 100.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.0310, Train Acc: 97.50%, Val Loss: 0.0062, Val Acc: 100.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.0048, Train Acc: 100.00%, Val Loss: 0.0030, Val Acc: 100.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.0095, Train Acc: 100.00%, Val Loss: 0.0023, Val Acc: 100.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.0084, Train Acc: 100.00%, Val Loss: 0.0020, Val Acc: 100.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.0017, Train Acc: 100.00%, Val Loss: 0.0019, Val Acc: 100.00%\n",
            "Starting epoch 30\n",
            "Train Loss: 0.1092, Train Acc: 97.50%, Val Loss: 0.0025, Val Acc: 100.00%\n",
            "Starting epoch 31\n",
            "Train Loss: 0.0013, Train Acc: 100.00%, Val Loss: 0.0031, Val Acc: 100.00%\n",
            "Starting epoch 32\n",
            "Train Loss: 0.0165, Train Acc: 100.00%, Val Loss: 0.0059, Val Acc: 100.00%\n",
            "Starting epoch 33\n",
            "Train Loss: 0.0074, Train Acc: 100.00%, Val Loss: 0.0066, Val Acc: 100.00%\n",
            "Starting epoch 34\n",
            "Train Loss: 0.0059, Train Acc: 100.00%, Val Loss: 0.0056, Val Acc: 100.00%\n",
            "Starting epoch 35\n",
            "Train Loss: 0.0020, Train Acc: 100.00%, Val Loss: 0.0050, Val Acc: 100.00%\n",
            "Starting epoch 36\n",
            "Train Loss: 0.0071, Train Acc: 100.00%, Val Loss: 0.0043, Val Acc: 100.00%\n",
            "Starting epoch 37\n",
            "Train Loss: 0.0023, Train Acc: 100.00%, Val Loss: 0.0038, Val Acc: 100.00%\n",
            "Starting epoch 38\n",
            "Train Loss: 0.0050, Train Acc: 100.00%, Val Loss: 0.0029, Val Acc: 100.00%\n",
            "Starting epoch 39\n",
            "Train Loss: 0.0008, Train Acc: 100.00%, Val Loss: 0.0023, Val Acc: 100.00%\n",
            "Starting epoch 40\n",
            "Train Loss: 0.0257, Train Acc: 97.50%, Val Loss: 0.0020, Val Acc: 100.00%\n",
            "Starting epoch 41\n",
            "Train Loss: 0.0021, Train Acc: 100.00%, Val Loss: 0.0021, Val Acc: 100.00%\n",
            "Starting epoch 42\n",
            "Train Loss: 0.0093, Train Acc: 100.00%, Val Loss: 0.0024, Val Acc: 100.00%\n",
            "Starting epoch 43\n",
            "Train Loss: 0.0052, Train Acc: 100.00%, Val Loss: 0.0029, Val Acc: 100.00%\n",
            "Starting epoch 44\n",
            "Train Loss: 0.0011, Train Acc: 100.00%, Val Loss: 0.0031, Val Acc: 100.00%\n",
            "Starting epoch 45\n",
            "Train Loss: 0.0090, Train Acc: 100.00%, Val Loss: 0.0033, Val Acc: 100.00%\n",
            "Starting epoch 46\n",
            "Train Loss: 0.0007, Train Acc: 100.00%, Val Loss: 0.0034, Val Acc: 100.00%\n",
            "Starting epoch 47\n",
            "Train Loss: 0.0106, Train Acc: 100.00%, Val Loss: 0.0036, Val Acc: 100.00%\n",
            "Starting epoch 48\n",
            "Train Loss: 0.0026, Train Acc: 100.00%, Val Loss: 0.0036, Val Acc: 100.00%\n",
            "Early stopping triggered.\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 0.2948, Train Acc: 90.00%, Val Loss: 0.1472, Val Acc: 90.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.0322, Train Acc: 100.00%, Val Loss: 0.1396, Val Acc: 90.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 0.0324, Train Acc: 97.50%, Val Loss: 0.3439, Val Acc: 90.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 0.0313, Train Acc: 100.00%, Val Loss: 0.0753, Val Acc: 100.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.1041, Train Acc: 97.50%, Val Loss: 0.0893, Val Acc: 100.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.0357, Train Acc: 97.50%, Val Loss: 0.0500, Val Acc: 100.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.1379, Train Acc: 95.00%, Val Loss: 0.0185, Val Acc: 100.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.3087, Train Acc: 90.00%, Val Loss: 0.0004, Val Acc: 100.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.1545, Train Acc: 92.50%, Val Loss: 0.0051, Val Acc: 100.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.3998, Train Acc: 95.00%, Val Loss: 0.0013, Val Acc: 100.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.1461, Train Acc: 95.00%, Val Loss: 0.0014, Val Acc: 100.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.1189, Train Acc: 92.50%, Val Loss: 0.0038, Val Acc: 100.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.1275, Train Acc: 97.50%, Val Loss: 0.0124, Val Acc: 100.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.0902, Train Acc: 97.50%, Val Loss: 0.0063, Val Acc: 100.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.0512, Train Acc: 97.50%, Val Loss: 0.0030, Val Acc: 100.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.0205, Train Acc: 100.00%, Val Loss: 0.0017, Val Acc: 100.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.0537, Train Acc: 97.50%, Val Loss: 0.0031, Val Acc: 100.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.0293, Train Acc: 97.50%, Val Loss: 0.0020, Val Acc: 100.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.0171, Train Acc: 100.00%, Val Loss: 0.0013, Val Acc: 100.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.0847, Train Acc: 92.50%, Val Loss: 0.0012, Val Acc: 100.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.0041, Train Acc: 100.00%, Val Loss: 0.0012, Val Acc: 100.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.0035, Train Acc: 100.00%, Val Loss: 0.0011, Val Acc: 100.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.0074, Train Acc: 100.00%, Val Loss: 0.0011, Val Acc: 100.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.0026, Train Acc: 100.00%, Val Loss: 0.0010, Val Acc: 100.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.0140, Train Acc: 100.00%, Val Loss: 0.0009, Val Acc: 100.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.0045, Train Acc: 100.00%, Val Loss: 0.0008, Val Acc: 100.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.0102, Train Acc: 100.00%, Val Loss: 0.0008, Val Acc: 100.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.0077, Train Acc: 100.00%, Val Loss: 0.0009, Val Acc: 100.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.0510, Train Acc: 97.50%, Val Loss: 0.0009, Val Acc: 100.00%\n",
            "Starting epoch 30\n",
            "Train Loss: 0.0086, Train Acc: 100.00%, Val Loss: 0.0019, Val Acc: 100.00%\n",
            "Starting epoch 31\n",
            "Train Loss: 0.0058, Train Acc: 100.00%, Val Loss: 0.0022, Val Acc: 100.00%\n",
            "Starting epoch 32\n",
            "Train Loss: 0.0282, Train Acc: 97.50%, Val Loss: 0.0012, Val Acc: 100.00%\n",
            "Starting epoch 33\n",
            "Train Loss: 0.0047, Train Acc: 100.00%, Val Loss: 0.0010, Val Acc: 100.00%\n",
            "Early stopping triggered.\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 0.3972, Train Acc: 95.00%, Val Loss: 0.3052, Val Acc: 90.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.3693, Train Acc: 92.50%, Val Loss: 0.0009, Val Acc: 100.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 0.2815, Train Acc: 97.50%, Val Loss: 0.0216, Val Acc: 100.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 0.2806, Train Acc: 95.00%, Val Loss: 0.0034, Val Acc: 100.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.0571, Train Acc: 97.50%, Val Loss: 0.0105, Val Acc: 100.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.1601, Train Acc: 95.00%, Val Loss: 0.0155, Val Acc: 100.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.0849, Train Acc: 97.50%, Val Loss: 0.0171, Val Acc: 100.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.0393, Train Acc: 97.50%, Val Loss: 0.0047, Val Acc: 100.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.0911, Train Acc: 95.00%, Val Loss: 0.0032, Val Acc: 100.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.0393, Train Acc: 100.00%, Val Loss: 0.0381, Val Acc: 100.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.0330, Train Acc: 100.00%, Val Loss: 0.0124, Val Acc: 100.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.0126, Train Acc: 100.00%, Val Loss: 0.0044, Val Acc: 100.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.0035, Train Acc: 100.00%, Val Loss: 0.0028, Val Acc: 100.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.0343, Train Acc: 97.50%, Val Loss: 0.0113, Val Acc: 100.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.0057, Train Acc: 100.00%, Val Loss: 0.0279, Val Acc: 100.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.0079, Train Acc: 100.00%, Val Loss: 0.0194, Val Acc: 100.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.0050, Train Acc: 100.00%, Val Loss: 0.0120, Val Acc: 100.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.0039, Train Acc: 100.00%, Val Loss: 0.0057, Val Acc: 100.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.0007, Train Acc: 100.00%, Val Loss: 0.0033, Val Acc: 100.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.0020, Train Acc: 100.00%, Val Loss: 0.0025, Val Acc: 100.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.0020, Train Acc: 100.00%, Val Loss: 0.0021, Val Acc: 100.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.0020, Train Acc: 100.00%, Val Loss: 0.0019, Val Acc: 100.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.0027, Train Acc: 100.00%, Val Loss: 0.0016, Val Acc: 100.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.0035, Train Acc: 100.00%, Val Loss: 0.0014, Val Acc: 100.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.0036, Train Acc: 100.00%, Val Loss: 0.0012, Val Acc: 100.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.0028, Train Acc: 100.00%, Val Loss: 0.0012, Val Acc: 100.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.0013, Train Acc: 100.00%, Val Loss: 0.0011, Val Acc: 100.00%\n",
            "Early stopping triggered.\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 0.3167, Train Acc: 95.00%, Val Loss: 0.0013, Val Acc: 100.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.3024, Train Acc: 90.00%, Val Loss: 0.0014, Val Acc: 100.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 0.0150, Train Acc: 100.00%, Val Loss: 0.0048, Val Acc: 100.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 0.2027, Train Acc: 90.00%, Val Loss: 0.0006, Val Acc: 100.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.0095, Train Acc: 100.00%, Val Loss: 0.0253, Val Acc: 100.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.0312, Train Acc: 97.50%, Val Loss: 0.0431, Val Acc: 100.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.2488, Train Acc: 95.00%, Val Loss: 0.0018, Val Acc: 100.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.0461, Train Acc: 97.50%, Val Loss: 0.0011, Val Acc: 100.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.0138, Train Acc: 100.00%, Val Loss: 0.0016, Val Acc: 100.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.0103, Train Acc: 100.00%, Val Loss: 0.0024, Val Acc: 100.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.0412, Train Acc: 97.50%, Val Loss: 0.0022, Val Acc: 100.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.0251, Train Acc: 100.00%, Val Loss: 0.0008, Val Acc: 100.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.0115, Train Acc: 100.00%, Val Loss: 0.0006, Val Acc: 100.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.0077, Train Acc: 100.00%, Val Loss: 0.0005, Val Acc: 100.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.0062, Train Acc: 100.00%, Val Loss: 0.0004, Val Acc: 100.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.0065, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.0016, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.0015, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.0558, Train Acc: 97.50%, Val Loss: 0.0009, Val Acc: 100.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.0600, Train Acc: 97.50%, Val Loss: 0.0076, Val Acc: 100.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.1889, Train Acc: 97.50%, Val Loss: 0.0072, Val Acc: 100.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.0050, Train Acc: 100.00%, Val Loss: 0.0032, Val Acc: 100.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.0173, Train Acc: 100.00%, Val Loss: 0.0016, Val Acc: 100.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.0193, Train Acc: 100.00%, Val Loss: 0.0011, Val Acc: 100.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.0029, Train Acc: 100.00%, Val Loss: 0.0008, Val Acc: 100.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.0036, Train Acc: 100.00%, Val Loss: 0.0007, Val Acc: 100.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.0148, Train Acc: 100.00%, Val Loss: 0.0006, Val Acc: 100.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.0018, Train Acc: 100.00%, Val Loss: 0.0006, Val Acc: 100.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.0043, Train Acc: 100.00%, Val Loss: 0.0005, Val Acc: 100.00%\n",
            "Starting epoch 30\n",
            "Train Loss: 0.0262, Train Acc: 97.50%, Val Loss: 0.0004, Val Acc: 100.00%\n",
            "Starting epoch 31\n",
            "Train Loss: 0.0044, Train Acc: 100.00%, Val Loss: 0.0004, Val Acc: 100.00%\n",
            "Starting epoch 32\n",
            "Train Loss: 0.0179, Train Acc: 100.00%, Val Loss: 0.0004, Val Acc: 100.00%\n",
            "Starting epoch 33\n",
            "Train Loss: 0.0024, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 34\n",
            "Train Loss: 0.0020, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 35\n",
            "Train Loss: 0.0011, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 36\n",
            "Train Loss: 0.0004, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 37\n",
            "Train Loss: 0.0006, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 38\n",
            "Train Loss: 0.0008, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 39\n",
            "Train Loss: 0.0005, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 40\n",
            "Train Loss: 0.0004, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 41\n",
            "Train Loss: 0.0003, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 42\n",
            "Train Loss: 0.0007, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 43\n",
            "Train Loss: 0.0019, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 44\n",
            "Train Loss: 0.0004, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 45\n",
            "Train Loss: 0.0004, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 46\n",
            "Train Loss: 0.0010, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 47\n",
            "Train Loss: 0.0036, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 48\n",
            "Train Loss: 0.0012, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 49\n",
            "Train Loss: 0.0011, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Starting epoch 50\n",
            "Train Loss: 0.0011, Train Acc: 100.00%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "--------------------------------\n",
            "Best validation accuracy of 0.00% achieved, model saved as VIT_best_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load('VIT_best_model.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWMb6wj110q0",
        "outputId": "b5efffab-d5a0-4ddb-e2b4-c0d2ba13a154"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SkDQDL43-7i",
        "outputId": "a212d218-d49d-4966-b0d8-e0d2ddc60697"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_indices = [i for i, (_, label) in enumerate(testset) if label in selected_classes]\n",
        "N = 1000\n",
        "class_counts = {label: 0 for label in selected_classes}\n",
        "filtered_train_indices = []\n",
        "\n",
        "for i in test_indices:\n",
        "    _, label = testset[i]\n",
        "    if class_counts[label] < N:\n",
        "        filtered_train_indices.append(i)\n",
        "        class_counts[label] += 1\n",
        "\n",
        "test_subset = Subset(testset, filtered_train_indices)\n",
        "test_loader = DataLoader(test_subset, batch_size=50, shuffle=False)"
      ],
      "metadata": {
        "id": "cwgkb-K814jT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Assuming the test_loader and the device are already defined\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Evaluation\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# No gradient is needed for evaluation\n",
        "with torch.no_grad():\n",
        "    for data, targets in test_loader:\n",
        "        # Move data and targets to the correct device\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Compute the model output\n",
        "        output = model(data)\n",
        "        loss = criterion(output, targets)\n",
        "\n",
        "        # Accumulate the loss and calculate accuracy\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "# Calculate average loss and accuracy percentage\n",
        "VIT_avg_loss = test_loss / len(test_loader)\n",
        "VIT_accuracy = 100. * correct / total\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f'Test Loss: {VIT_avg_loss:.4f}, Test Accuracy: {VIT_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RohrSzM819eo",
        "outputId": "03853067-5743-4f61-b086-c2c4199176f9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.7496, Test Accuracy: 87.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graphs"
      ],
      "metadata": {
        "id": "NVUnWfpS5Q6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_classes_mapping = {0: \"Cat\", 1: \"Dog\", 2: \"Bird\", 3: \"Horse\", 4: \"Ship\", 5: \"Truck\", 6: \"Frog\", 7: \"Airplane\", 8: \"Deer\", 9: \"Automobile\"}\n",
        "selected_classes = [selected_classes_mapping[class_num] for class_num in selected_classes]\n",
        "print(f'Randomly selected from CIFAR-10 are {selected_classes}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FATVgQSn6xRy",
        "outputId": "6302eeab-4898-4a56-e7f4-1a807eaa2a70"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomly selected from CIFAR-10 are ['Ship', 'Deer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "A502A3vS5SEq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "bars = plt.bar(['XGBoost', 'Custom CNN', 'Vision Transformer'], [XGBoost_accuracy * 100, Custom_CNN_accuracy, VIT_accuracy], color=['blue', 'orange', 'green'])\n",
        "plt.title('Accuracy Comparison')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.ylim(0, 110)\n",
        "\n",
        "# Annotate bars with values\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval, round(yval, 2), va='bottom')\n",
        "\n",
        "# Loss comparison\n",
        "plt.subplot(1, 2, 2)\n",
        "bars = plt.bar(['Custom CNN', 'Vision Transformer'], [Custom_CNN_avg_loss, VIT_avg_loss], color=['orange', 'green'])\n",
        "plt.title('Average Loss Comparison')\n",
        "plt.ylabel('Average Loss')\n",
        "plt.ylim(0, 3.2)\n",
        "\n",
        "# Annotate bars with values\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval, round(yval, 2), va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "GalqyuQl5S8K",
        "outputId": "7455a515-d80e-4bc9-eec6-2bbea5617eb3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}