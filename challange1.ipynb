{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10), \n",
    "    transforms.RandomCrop(32, padding=4),  \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_classes = np.random.choice(range(10), 2, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for idx, (image, label) in enumerate(trainset):\n",
    "    if label in selected_classes:  # Include all samples from selected classes for training\n",
    "        train_indices.append(idx)\n",
    "\n",
    "for idx, (image, label) in enumerate(testset):\n",
    "    if label in selected_classes:  # Include all samples from selected classes for testing\n",
    "        test_indices.append(idx)\n",
    "\n",
    "# Shuffle the indices\n",
    "np.random.shuffle(train_indices)\n",
    "np.random.shuffle(test_indices)\n",
    "\n",
    "# Check if enough samples are found for training and testing\n",
    "if len(train_indices) < 25 or len(test_indices) < 2000:\n",
    "    raise ValueError(\"Insufficient samples found for training or testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classes: [5 9]\n",
      "Number of training samples per class: 12\n",
      "Number of testing samples per class: 1000\n"
     ]
    }
   ],
   "source": [
    "train_indices = train_indices[:25]\n",
    "test_indices = test_indices[:2000]\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=25, sampler=torch.utils.data.SubsetRandomSampler(train_indices))\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=2000, sampler=torch.utils.data.SubsetRandomSampler(test_indices))\n",
    "\n",
    "print(\"Selected classes:\", selected_classes)\n",
    "\n",
    "# Print the number of samples selected for training and testing\n",
    "print(\"Number of training samples per class:\", len(train_indices) // len(selected_classes))\n",
    "print(\"Number of testing samples per class:\", len(test_indices) // len(selected_classes))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in trainloader:\n",
    "    for image, label in zip(images, labels):\n",
    "        train_data.append(image.numpy().flatten())  # Flatten the image tensor\n",
    "        train_labels.append(label.item())\n",
    "\n",
    "for images, labels in testloader:\n",
    "    for image, label in zip(images, labels):\n",
    "        test_data.append(image.numpy().flatten())  # Flatten the image tensor\n",
    "        test_labels.append(label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.70)  # Retain 95% of variance\n",
    "X_train_reduced = pca.fit_transform(train_data)\n",
    "X_test_reduced = pca.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'SVM': SVC(probability=True),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'SVM': {'C': [0.1, 0.5, 1, 5,7, 10], 'gamma': ['scale', 'auto'], 'kernel': ['rbf', 'poly']},\n",
    "    'Random Forest': {'n_estimators': [50, 100, 150], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]},\n",
    "    'KNN': {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree']}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for SVM: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "SVM Test Accuracy: 73.25%\n",
      "Best hyperparameters for Random Forest: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Random Forest Test Accuracy: 78.50%\n",
      "Best hyperparameters for KNN: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "KNN Test Accuracy: 70.90%\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train_reduced, train_labels)\n",
    "    \n",
    "    print(f'Best hyperparameters for {name}: {grid_search.best_params_}')\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Train on the entire training set and evaluate on the unseen test set\n",
    "    best_model.fit(X_train_reduced, train_labels)\n",
    "    predictions = best_model.predict(X_test_reduced)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f'{name} Test Accuracy: {accuracy*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f10e0bbdcb8a5227530b5aed21b374411d613e5cbe3bc0662ba6adc52ae7b0de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
