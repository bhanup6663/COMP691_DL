{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPAjoqpP/OaIwhiXXuO7Cku",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhanup6663/COMP691_DL/blob/main/Challange1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST-Bayesian"
      ],
      "metadata": {
        "id": "j8ADh8WJxZRN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VL8nv8wixOh3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import Grayscale\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
        "])"
      ],
      "metadata": {
        "id": "rwIaJhJuxVN4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZxA6OVqxpIA",
        "outputId": "afd869ca-b4d3-44ab-b6c0-e57140760203"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:06<00:00, 28086393.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_classes = np.random.choice(range(10), 2, replace=False)"
      ],
      "metadata": {
        "id": "_3Uut8Yoxtkx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FfOtNldxwm4",
        "outputId": "2cfc6735-34d3-414d-b68e-339e86f5774c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_mapping = {original: new for new, original in enumerate(selected_classes)}"
      ],
      "metadata": {
        "id": "C-09supGx1rF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices = []\n",
        "test_indices = []\n",
        "\n",
        "for idx, (image, label) in enumerate(trainset):\n",
        "    if label in selected_classes:\n",
        "        train_indices.append(idx)\n",
        "\n",
        "for idx, (image, label) in enumerate(testset):\n",
        "    if label in selected_classes:\n",
        "        test_indices.append(idx)\n",
        "\n",
        "# Shuffle the indices\n",
        "np.random.shuffle(train_indices)\n",
        "np.random.shuffle(test_indices)\n",
        "\n",
        "# Check if enough samples are found for training and testing\n",
        "if len(train_indices) < 25 or len(test_indices) < 2000:\n",
        "    raise ValueError(\"Insufficient samples found for training or testing.\")"
      ],
      "metadata": {
        "id": "dgKVgYbGx5_u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices = train_indices[:25]\n",
        "test_indices = test_indices[:2000]\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=25, sampler=torch.utils.data.SubsetRandomSampler(train_indices))\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=2000, sampler=torch.utils.data.SubsetRandomSampler(test_indices))"
      ],
      "metadata": {
        "id": "HloGfVd9x-zw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "train_labels = []\n",
        "test_data = []\n",
        "test_labels = []\n",
        "\n",
        "for images, labels in trainloader:\n",
        "    for image, label in zip(images, labels):\n",
        "        train_data.append(image.numpy().flatten())\n",
        "        train_labels.append(label.item())\n",
        "\n",
        "for images, labels in testloader:\n",
        "    for image, label in zip(images, labels):\n",
        "        test_data.append(image.numpy().flatten())\n",
        "        test_labels.append(label.item())"
      ],
      "metadata": {
        "id": "XymWTPQcyCJA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.array(train_data)\n",
        "train_labels = np.array(train_labels)\n",
        "test_data = np.array(test_data)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "train_remapped = np.array([class_mapping[label] for label in train_labels])\n",
        "test_remapped = np.array([class_mapping[label] for label in test_labels])"
      ],
      "metadata": {
        "id": "qI1e7kNHyLJz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=0.70)\n",
        "X_train_pca = pca.fit_transform(np.array(train_data))\n",
        "X_test_pca = pca.transform(np.array(test_data))"
      ],
      "metadata": {
        "id": "1vYml3vJyN1O"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train_pca, np.array(train_remapped), test_size=0.2, stratify=train_remapped)"
      ],
      "metadata": {
        "id": "e6dyBUbTyQC0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(space):\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=int(space['n_estimators']),\n",
        "        max_depth=int(space['max_depth']),\n",
        "        learning_rate=space['learning_rate'],\n",
        "        subsample=space['subsample'],\n",
        "        colsample_bytree=space['colsample_bytree'],\n",
        "        reg_lambda=space['lambda'],\n",
        "        objective='multi:softmax',\n",
        "        eval_metric='mlogloss',\n",
        "        use_label_encoder=False,\n",
        "        num_class=2,  # Make sure this is correctly set\n",
        "        tree_method='gpu_hist',\n",
        "        device='gpu',  # Updated from gpu_id to device\n",
        "        seed=42,\n",
        "        early_stopping_rounds=10  # Moved here as per deprecation warning\n",
        "    )\n",
        "\n",
        "    eval_set = [(X_val, y_val)]\n",
        "    model.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n",
        "\n",
        "    predictions = model.predict(X_val)\n",
        "    accuracy = accuracy_score(y_val, predictions)\n",
        "    return {'loss': -accuracy, 'status': STATUS_OK}"
      ],
      "metadata": {
        "id": "8VqQr4ShyUbv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "space = {\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 300, 25),  # Widen the range to allow more trees\n",
        "    'max_depth': hp.choice('max_depth', [3, 4, 5, 6, 7]),  # Narrow down based on typical good performers\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),  # Focus on a range that's typically more effective\n",
        "    'subsample': hp.uniform('subsample', 0.5, 1.0),  # Narrow to focus on higher subsampling rates\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.4, 0.8),  # Adjust to focus on a moderate range\n",
        "    'lambda': hp.uniform('lambda', 0.5, 2),  # Broaden to explore the impact of regularization more\n",
        "}\n"
      ],
      "metadata": {
        "id": "ReQ3YJPjyp4s"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trials = Trials()\n",
        "best_hyperparams = fmin(fn=objective,\n",
        "                        space=space,\n",
        "                        algo=tpe.suggest,\n",
        "                        max_evals=100,\n",
        "                        trials=trials)\n",
        "\n",
        "print(f\"Best hyperparameters: {best_hyperparams}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yJNe-2wyt4Q",
        "outputId": "795988e4-5242-4879-8b43-cb2bddb9b902"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  2%|▏         | 2/100 [00:00<00:28,  3.38trial/s, best loss: -0.8]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:43] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  5%|▌         | 5/100 [00:01<00:14,  6.73trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  6%|▌         | 6/100 [00:01<00:15,  5.98trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  8%|▊         | 8/100 [00:01<00:18,  4.90trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10%|█         | 10/100 [00:01<00:14,  6.25trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 11%|█         | 11/100 [00:02<00:12,  6.85trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 13%|█▎        | 13/100 [00:02<00:15,  5.75trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 16%|█▌        | 16/100 [00:03<00:14,  5.96trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 19%|█▉        | 19/100 [00:03<00:12,  6.51trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 20%|██        | 20/100 [00:03<00:11,  6.98trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 22%|██▏       | 22/100 [00:03<00:11,  6.77trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 24%|██▍       | 24/100 [00:04<00:10,  7.27trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 26%|██▌       | 26/100 [00:04<00:10,  6.95trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 27%|██▋       | 27/100 [00:04<00:13,  5.38trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 29%|██▉       | 29/100 [00:05<00:13,  5.38trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 30%|███       | 30/100 [00:05<00:14,  4.97trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 32%|███▏      | 32/100 [00:05<00:15,  4.26trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 34%|███▍      | 34/100 [00:06<00:13,  4.72trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 36%|███▌      | 36/100 [00:06<00:12,  5.31trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 37%|███▋      | 37/100 [00:06<00:12,  5.24trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 38%|███▊      | 38/100 [00:06<00:10,  5.71trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 39%|███▉      | 39/100 [00:07<00:14,  4.29trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 41%|████      | 41/100 [00:07<00:12,  4.84trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 42%|████▏     | 42/100 [00:07<00:10,  5.31trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 45%|████▌     | 45/100 [00:08<00:08,  6.29trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 46%|████▌     | 46/100 [00:08<00:11,  4.82trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 47%|████▋     | 47/100 [00:08<00:11,  4.61trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 49%|████▉     | 49/100 [00:09<00:10,  4.69trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 51%|█████     | 51/100 [00:09<00:08,  5.72trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 53%|█████▎    | 53/100 [00:09<00:07,  6.53trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 55%|█████▌    | 55/100 [00:09<00:05,  7.94trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 57%|█████▋    | 57/100 [00:10<00:08,  5.08trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 58%|█████▊    | 58/100 [00:10<00:08,  5.18trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 60%|██████    | 60/100 [00:11<00:06,  6.11trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 61%|██████    | 61/100 [00:11<00:07,  5.55trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 62%|██████▏   | 62/100 [00:11<00:08,  4.60trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 64%|██████▍   | 64/100 [00:12<00:08,  4.43trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 66%|██████▌   | 66/100 [00:12<00:05,  5.89trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 68%|██████▊   | 68/100 [00:12<00:04,  6.47trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 69%|██████▉   | 69/100 [00:12<00:04,  6.35trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 71%|███████   | 71/100 [00:13<00:04,  5.86trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 73%|███████▎  | 73/100 [00:13<00:03,  7.04trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 75%|███████▌  | 75/100 [00:13<00:04,  6.00trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 76%|███████▌  | 76/100 [00:13<00:04,  5.49trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 77%|███████▋  | 77/100 [00:14<00:03,  6.18trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 79%|███████▉  | 79/100 [00:14<00:03,  5.87trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 81%|████████  | 81/100 [00:14<00:02,  6.46trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 83%|████████▎ | 83/100 [00:14<00:02,  6.95trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 85%|████████▌ | 85/100 [00:15<00:02,  6.97trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 86%|████████▌ | 86/100 [00:15<00:02,  6.02trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 88%|████████▊ | 88/100 [00:15<00:02,  5.45trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 90%|█████████ | 90/100 [00:16<00:01,  5.57trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 91%|█████████ | 91/100 [00:16<00:01,  5.81trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 92%|█████████▏| 92/100 [00:16<00:01,  4.08trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 94%|█████████▍| 94/100 [00:17<00:01,  3.79trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 95%|█████████▌| 95/100 [00:17<00:01,  4.49trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:04:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 96%|█████████▌| 96/100 [00:17<00:00,  4.85trial/s, best loss: -1.0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:05:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:05:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:05:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.53trial/s, best loss: -1.0]\n",
            "Best hyperparameters: {'colsample_bytree': 0.4545988285613425, 'lambda': 0.6241402514502195, 'learning_rate': 0.06071096159282887, 'max_depth': 2, 'n_estimators': 175.0, 'subsample': 0.5466893366576624}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:05:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:05:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_n_estimators = int(best_hyperparams['n_estimators'])\n",
        "best_max_depth = int(best_hyperparams['max_depth'])\n",
        "best_learning_rate = best_hyperparams['learning_rate']\n",
        "best_subsample = best_hyperparams['subsample']\n",
        "best_colsample_bytree = best_hyperparams['colsample_bytree']\n",
        "best_lambda = best_hyperparams['lambda']"
      ],
      "metadata": {
        "id": "m8hb_33py0Nb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = XGBClassifier(\n",
        "    n_estimators=best_n_estimators,\n",
        "    max_depth=best_max_depth,\n",
        "    learning_rate=best_learning_rate,\n",
        "    subsample=best_subsample,\n",
        "    colsample_bytree=best_colsample_bytree,\n",
        "    reg_lambda=best_lambda,\n",
        "    objective='multi:softmax',\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False,\n",
        "    num_class=2,  # Assuming binary or two-class classification\n",
        "    tree_method='gpu_hist',\n",
        "    device='gpu',  # Or 'cpu' if not using GPU\n",
        "    seed=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "4H0TsBMTy4Mg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model.fit(X_train_pca, train_remapped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "SsLvD98Sy61T",
        "outputId": "43a8779e-b8e2-4aba-9acb-1b57df35e05a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:05:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.4545988285613425, device='gpu',\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric='mlogloss', feature_types=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.06071096159282887,\n",
              "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=175, n_jobs=None, num_class=2,\n",
              "              num_parallel_tree=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.4545988285613425, device=&#x27;gpu&#x27;,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=&#x27;mlogloss&#x27;, feature_types=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.06071096159282887,\n",
              "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=175, n_jobs=None, num_class=2,\n",
              "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.4545988285613425, device=&#x27;gpu&#x27;,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=&#x27;mlogloss&#x27;, feature_types=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.06071096159282887,\n",
              "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=175, n_jobs=None, num_class=2,\n",
              "              num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trained_model.predict(X_test_pca)"
      ],
      "metadata": {
        "id": "jiMP28U-y9pl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XGBoost_accuracy = accuracy_score(test_remapped, predictions)\n",
        "print(f'XGBoost Test Accuracy: {XGBoost_accuracy*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEHeXC4dzBMY",
        "outputId": "e526c1eb-52e1-4f47-f2d7-d9963b53fd74"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Test Accuracy: 79.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "fLofRf2I-RyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Subset"
      ],
      "metadata": {
        "id": "cZxAkytZ-xtL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [0.4914, 0.4822, 0.4465]\n",
        "std = [0.2023, 0.1994, 0.2010]\n",
        "\n",
        "# Define transformations for training and validation data\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])"
      ],
      "metadata": {
        "id": "a5ObI7zq-TDj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "num_samples_per_class = 25\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "cifar_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "\n",
        "selected_indices_train = []\n",
        "selected_indices_val = []\n",
        "\n",
        "# Select samples for training and validation\n",
        "for i in selected_classes:\n",
        "    class_indices = np.where(np.array(cifar_data.targets) == i)[0]\n",
        "    selected_indices_train.extend(np.random.choice(class_indices, num_samples_per_class, replace=False))\n",
        "    remaining_indices = list(set(class_indices) - set(selected_indices_train))\n",
        "    selected_indices_val.extend(remaining_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNR66FC4-T9v",
        "outputId": "7814374a-e92c-4c90-d24f-bdcc67694346"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Subset datasets for training and validation\n",
        "train_data = Subset(cifar_data, selected_indices_train)\n",
        "val_data = Subset(cifar_data, selected_indices_val)\n",
        "\n",
        "# Create DataLoader for training and validation datasets\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=len(train_data), shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=len(val_data), shuffle=False)\n",
        "\n",
        "# Extract features and labels from training and validation datasets\n",
        "train_features, train_labels = next(iter(train_loader))\n",
        "val_features, val_labels = next(iter(val_loader))\n",
        "\n",
        "train_features = train_features.view(train_features.size(0), -1).numpy()\n",
        "val_features = val_features.view(val_features.size(0), -1).numpy()\n",
        "\n",
        "# Normalize features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "train_features_scaled = scaler.fit_transform(train_features)\n",
        "val_features_scaled = scaler.transform(val_features)"
      ],
      "metadata": {
        "id": "xJjpBq7Q-rRh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = [\n",
        "    {'C': 0.5, 'gamma': 'scale', 'random_seed': 2},\n",
        "    {'C': 1.0, 'gamma': 'scale', 'random_seed': 1},\n",
        "    {'C': 2.0, 'gamma': 'scale', 'random_seed': 2},\n",
        "    {'C': 3.0, 'gamma': 'scale', 'random_seed': 1},\n",
        "    {'C': 0.5, 'gamma': 'scale', 'random_seed': 1},\n",
        "    {'C': 1.0, 'gamma': 'auto', 'random_seed': 2},\n",
        "    {'C': 2.0, 'gamma': 'auto', 'random_seed': 1},\n",
        "    {'C': 3.0, 'gamma': 'auto', 'random_seed': 2},\n",
        "]\n"
      ],
      "metadata": {
        "id": "2msUeanX-8Wa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SVM models with different hyperparameters\n",
        "svm_models = []\n",
        "svm_accuracies = []\n",
        "for params in hyperparameters:\n",
        "    # Initialize SVM model with specified hyperparameters\n",
        "    model = SVC(kernel='rbf', C=params['C'], gamma=params['gamma'], random_state=params['random_seed'])\n",
        "\n",
        "    # Train model\n",
        "    model.fit(train_features_scaled, train_labels)\n",
        "\n",
        "    # Add trained model to list\n",
        "    svm_models.append(model)\n",
        "\n",
        "    # Predict on validation set\n",
        "    val_predictions = model.predict(val_features_scaled)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(val_labels, val_predictions)\n",
        "    print(\"Taken Parameters: {}\".format(params))\n",
        "    print(\"Accuracy: {}\".format(accuracy))\n",
        "    svm_accuracies.append(accuracy)\n",
        "\n",
        "# Find the best hyperparameter combination and its accuracy\n",
        "best_idx = np.argmax(svm_accuracies)\n",
        "best_hyperparams = hyperparameters[best_idx]\n",
        "best_accuracy = svm_accuracies[best_idx]\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_hyperparams)\n",
        "print(f\"Best Accuracy: {best_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_XqISUt-s_5",
        "outputId": "bc375360-20f1-4306-faf6-f539a75101c2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taken Parameters: {'C': 0.5, 'gamma': 'scale', 'random_seed': 2}\n",
            "Accuracy: 0.7530653266331658\n",
            "Taken Parameters: {'C': 1.0, 'gamma': 'scale', 'random_seed': 1}\n",
            "Accuracy: 0.7839195979899497\n",
            "Taken Parameters: {'C': 2.0, 'gamma': 'scale', 'random_seed': 2}\n",
            "Accuracy: 0.7962814070351759\n",
            "Taken Parameters: {'C': 3.0, 'gamma': 'scale', 'random_seed': 1}\n",
            "Accuracy: 0.79356783919598\n",
            "Taken Parameters: {'C': 0.5, 'gamma': 'scale', 'random_seed': 1}\n",
            "Accuracy: 0.7530653266331658\n",
            "Taken Parameters: {'C': 1.0, 'gamma': 'auto', 'random_seed': 2}\n",
            "Accuracy: 0.7839195979899497\n",
            "Taken Parameters: {'C': 2.0, 'gamma': 'auto', 'random_seed': 1}\n",
            "Accuracy: 0.7962814070351759\n",
            "Taken Parameters: {'C': 3.0, 'gamma': 'auto', 'random_seed': 2}\n",
            "Accuracy: 0.79356783919598\n",
            "Best Hyperparameters:\n",
            "{'C': 2.0, 'gamma': 'scale', 'random_seed': 2}\n",
            "Best Accuracy: 79.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions from individual SVM models\n",
        "individual_predictions = [model.predict(val_features_scaled) for model in svm_models]\n",
        "\n",
        "# Ensemble predictions by averaging\n",
        "ensemble_predictions_avg = np.mean(individual_predictions, axis=0)\n",
        "\n",
        "# Ensemble predictions by voting\n",
        "ensemble_predictions_vote = np.round(np.mean(individual_predictions, axis=0))\n",
        "\n",
        "# Convert ensemble predictions to discrete values (0 or 1)\n",
        "ensemble_predictions_avg_discrete = np.round(ensemble_predictions_avg)\n",
        "ensemble_predictions_vote_discrete = np.round(ensemble_predictions_vote)\n",
        "\n",
        "# Calculate accuracy for ensemble predictions\n",
        "accuracy_avg_discrete = accuracy_score(val_labels, ensemble_predictions_avg_discrete)\n",
        "SVM_accuracy_vote_discrete = accuracy_score(val_labels, ensemble_predictions_vote_discrete)\n",
        "\n",
        "print(\"Ensemble Accuracy (Averaging) after conversion: {:.2f}%\".format(accuracy_avg_discrete * 100))\n",
        "print(\"Ensemble Accuracy (Voting) after conversion: {:.2f}%\".format(SVM_accuracy_vote_discrete * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw_Oi5P2_DUc",
        "outputId": "1a7da23a-be4d-4e84-9205-2e0b63e68a1c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Accuracy (Averaging) after conversion: 72.38%\n",
            "Ensemble Accuracy (Voting) after conversion: 72.38%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom CNN"
      ],
      "metadata": {
        "id": "ae3e2NTgzaVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset,DataLoader, Subset, random_split\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "Lv2lkstnzdke"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT1zsMaRziqi",
        "outputId": "51443cf6-c680-4d24-d8e9-7945aba8f16d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
        "])"
      ],
      "metadata": {
        "id": "3PcZBRcczn3W"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZLpijKXzr7w",
        "outputId": "25cd4afd-b387-486b-9aba-9e56c1a42301"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformSubset(Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.subset[idx]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "xQrT2HiszunH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "iLk_Cfl8zxAK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_folds = 5\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "hi6Ppgnzz06v"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_accuracy = 0\n",
        "best_model_weights = None"
      ],
      "metadata": {
        "id": "-GnSzhulz3nF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "fsVuNHkcz6Gf"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, device, val_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, targets) in enumerate(val_loader):\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, targets)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "95RXjepHz81S"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold, (train_ids, val_ids) in enumerate(kfold.split(trainset)):\n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "\n",
        "    train_indices = [i for i, (_, label) in enumerate(trainset) if label in selected_classes]\n",
        "\n",
        "    N = 25\n",
        "    class_counts = {label: 0 for label in selected_classes}\n",
        "    filtered_train_indices = []\n",
        "\n",
        "    for i in train_indices:\n",
        "        _, label = trainset[i]\n",
        "        if class_counts[label] < N:\n",
        "            filtered_train_indices.append(i)\n",
        "            class_counts[label] += 1\n",
        "\n",
        "\n",
        "    np.random.seed(42)\n",
        "    np.random.shuffle(filtered_train_indices)\n",
        "    split = int(0.8 * len(filtered_train_indices))\n",
        "    train_idx, val_idx = filtered_train_indices[:split], filtered_train_indices[split:]\n",
        "\n",
        "    train_subset = Subset(trainset, train_idx)\n",
        "    transformed_train_subset = TransformSubset(train_subset, transform=train_transform)\n",
        "\n",
        "    val_subset = Subset(trainset, val_idx)\n",
        "    transformed_val_subset = TransformSubset(val_subset, transform=test_transform)\n",
        "\n",
        "    train_loader = DataLoader(transformed_train_subset, batch_size=5, shuffle=True)\n",
        "    val_loader = DataLoader(transformed_val_subset, batch_size=5, shuffle=False)\n",
        "\n",
        "\n",
        "    # Init the neural network\n",
        "    model = CustomCNN().to(device)\n",
        "\n",
        "    # Initialize optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.005)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Initilization of scheduler\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    patience = 25\n",
        "\n",
        "\n",
        "    # Run the training loop for defined number of epochs\n",
        "    num_epochs = 50\n",
        "    for epoch in range(num_epochs):\n",
        "        # Print epoch\n",
        "        print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "        # Perform training and validation\n",
        "        train_loss, train_accuracy = train(model, device, train_loader, optimizer, criterion)\n",
        "        val_loss, val_accuracy = validate(model, device, val_loader, criterion)\n",
        "\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
        "\n",
        "        # Save the model if it has the best val accuracy so far\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "             # Save the best model weights\n",
        "            best_model_weights = model.state_dict().copy()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            # Stop training if no improvement\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Step the learning rate scheduler\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "    print('--------------------------------')\n",
        "\n",
        "# Save the best model weights\n",
        "torch.save(best_model_weights, 'CNN_best_model.pth')\n",
        "print(f'Best validation accuracy of {best_val_accuracy:.2f}% achieved, model saved as CNN_best_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqTLV2H6z_hT",
        "outputId": "c767f92a-6d39-4153-b6c9-3705d3221370"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 0\n",
            "--------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "Train Loss: 1.6392, Train Acc: 45.00%, Val Loss: 6.6432, Val Acc: 70.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 1.3654, Train Acc: 57.50%, Val Loss: 4.9183, Val Acc: 50.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 1.5111, Train Acc: 57.50%, Val Loss: 2.6562, Val Acc: 50.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 1.7141, Train Acc: 60.00%, Val Loss: 1.9212, Val Acc: 30.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.9353, Train Acc: 52.50%, Val Loss: 0.4701, Val Acc: 80.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 1.1356, Train Acc: 47.50%, Val Loss: 0.4933, Val Acc: 70.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.6907, Train Acc: 70.00%, Val Loss: 0.9504, Val Acc: 60.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.6925, Train Acc: 65.00%, Val Loss: 0.7055, Val Acc: 60.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.7149, Train Acc: 67.50%, Val Loss: 0.9551, Val Acc: 60.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.5995, Train Acc: 77.50%, Val Loss: 0.8368, Val Acc: 60.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.7980, Train Acc: 67.50%, Val Loss: 0.8053, Val Acc: 60.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.4673, Train Acc: 85.00%, Val Loss: 0.8005, Val Acc: 60.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.6421, Train Acc: 72.50%, Val Loss: 0.7122, Val Acc: 60.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.6309, Train Acc: 72.50%, Val Loss: 0.7374, Val Acc: 60.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.6384, Train Acc: 72.50%, Val Loss: 0.7016, Val Acc: 60.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.7059, Train Acc: 57.50%, Val Loss: 0.7003, Val Acc: 60.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.5029, Train Acc: 65.00%, Val Loss: 0.7248, Val Acc: 60.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.4591, Train Acc: 82.50%, Val Loss: 0.6932, Val Acc: 70.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.6376, Train Acc: 72.50%, Val Loss: 0.6875, Val Acc: 70.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.7723, Train Acc: 62.50%, Val Loss: 0.6866, Val Acc: 70.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.6437, Train Acc: 75.00%, Val Loss: 0.6912, Val Acc: 70.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.4531, Train Acc: 77.50%, Val Loss: 0.7138, Val Acc: 60.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.6104, Train Acc: 72.50%, Val Loss: 0.7573, Val Acc: 60.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.6291, Train Acc: 70.00%, Val Loss: 0.7514, Val Acc: 60.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.5812, Train Acc: 72.50%, Val Loss: 0.7419, Val Acc: 60.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.6473, Train Acc: 77.50%, Val Loss: 0.7341, Val Acc: 60.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.4316, Train Acc: 82.50%, Val Loss: 0.7140, Val Acc: 60.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.5705, Train Acc: 72.50%, Val Loss: 0.7136, Val Acc: 60.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.3763, Train Acc: 80.00%, Val Loss: 0.7234, Val Acc: 60.00%\n",
            "Starting epoch 30\n",
            "Train Loss: 0.5766, Train Acc: 72.50%, Val Loss: 0.6851, Val Acc: 70.00%\n",
            "Early stopping triggered.\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 1.2885, Train Acc: 57.50%, Val Loss: 4.7565, Val Acc: 70.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 1.1910, Train Acc: 67.50%, Val Loss: 1.8745, Val Acc: 90.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 1.9083, Train Acc: 45.00%, Val Loss: 1.6067, Val Acc: 70.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 1.0026, Train Acc: 57.50%, Val Loss: 0.5079, Val Acc: 70.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.9680, Train Acc: 67.50%, Val Loss: 0.5771, Val Acc: 80.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.7429, Train Acc: 67.50%, Val Loss: 0.3475, Val Acc: 80.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.7006, Train Acc: 72.50%, Val Loss: 1.0760, Val Acc: 60.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.5784, Train Acc: 77.50%, Val Loss: 0.9373, Val Acc: 70.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.6739, Train Acc: 72.50%, Val Loss: 0.7427, Val Acc: 70.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.8267, Train Acc: 57.50%, Val Loss: 2.5974, Val Acc: 30.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.7340, Train Acc: 65.00%, Val Loss: 1.1603, Val Acc: 30.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.6724, Train Acc: 67.50%, Val Loss: 0.5327, Val Acc: 90.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.6405, Train Acc: 67.50%, Val Loss: 0.3987, Val Acc: 90.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.5449, Train Acc: 80.00%, Val Loss: 0.3985, Val Acc: 90.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.7653, Train Acc: 72.50%, Val Loss: 0.3935, Val Acc: 90.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.5712, Train Acc: 80.00%, Val Loss: 0.3945, Val Acc: 80.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.5345, Train Acc: 77.50%, Val Loss: 0.3841, Val Acc: 80.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.5915, Train Acc: 65.00%, Val Loss: 0.4056, Val Acc: 80.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.6671, Train Acc: 70.00%, Val Loss: 0.3981, Val Acc: 80.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.6044, Train Acc: 75.00%, Val Loss: 0.4046, Val Acc: 80.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.5113, Train Acc: 75.00%, Val Loss: 0.4010, Val Acc: 80.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.6263, Train Acc: 70.00%, Val Loss: 0.4099, Val Acc: 80.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.6124, Train Acc: 75.00%, Val Loss: 0.4125, Val Acc: 80.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.5106, Train Acc: 77.50%, Val Loss: 0.4051, Val Acc: 80.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.3680, Train Acc: 90.00%, Val Loss: 0.4102, Val Acc: 80.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.6680, Train Acc: 62.50%, Val Loss: 0.3963, Val Acc: 90.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.6760, Train Acc: 72.50%, Val Loss: 0.3803, Val Acc: 80.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.6960, Train Acc: 70.00%, Val Loss: 0.3997, Val Acc: 80.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.4362, Train Acc: 77.50%, Val Loss: 0.3953, Val Acc: 80.00%\n",
            "Starting epoch 30\n",
            "Train Loss: 0.3937, Train Acc: 72.50%, Val Loss: 0.3890, Val Acc: 90.00%\n",
            "Starting epoch 31\n",
            "Train Loss: 0.4568, Train Acc: 77.50%, Val Loss: 0.3917, Val Acc: 80.00%\n",
            "Early stopping triggered.\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 1.5225, Train Acc: 47.50%, Val Loss: 4.6295, Val Acc: 70.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 1.0351, Train Acc: 60.00%, Val Loss: 2.0230, Val Acc: 70.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 1.2403, Train Acc: 67.50%, Val Loss: 1.4720, Val Acc: 60.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 1.3446, Train Acc: 47.50%, Val Loss: 0.6442, Val Acc: 70.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 1.0773, Train Acc: 65.00%, Val Loss: 0.4998, Val Acc: 70.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.7123, Train Acc: 80.00%, Val Loss: 0.5734, Val Acc: 70.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.4828, Train Acc: 80.00%, Val Loss: 0.7839, Val Acc: 60.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.9296, Train Acc: 55.00%, Val Loss: 0.9670, Val Acc: 60.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.6418, Train Acc: 72.50%, Val Loss: 1.8065, Val Acc: 30.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.5273, Train Acc: 82.50%, Val Loss: 1.2695, Val Acc: 50.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.5138, Train Acc: 77.50%, Val Loss: 0.9329, Val Acc: 60.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.3917, Train Acc: 82.50%, Val Loss: 0.7480, Val Acc: 70.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.5767, Train Acc: 82.50%, Val Loss: 0.7652, Val Acc: 60.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.4298, Train Acc: 87.50%, Val Loss: 0.7098, Val Acc: 70.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.4895, Train Acc: 77.50%, Val Loss: 0.6741, Val Acc: 70.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.7669, Train Acc: 67.50%, Val Loss: 0.6809, Val Acc: 70.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.4150, Train Acc: 82.50%, Val Loss: 0.7288, Val Acc: 70.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.3459, Train Acc: 87.50%, Val Loss: 0.7451, Val Acc: 60.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.4225, Train Acc: 85.00%, Val Loss: 0.7293, Val Acc: 60.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.5045, Train Acc: 75.00%, Val Loss: 0.7315, Val Acc: 70.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.6379, Train Acc: 70.00%, Val Loss: 0.7102, Val Acc: 70.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.3087, Train Acc: 85.00%, Val Loss: 0.6909, Val Acc: 70.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.6812, Train Acc: 62.50%, Val Loss: 0.6918, Val Acc: 70.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.6042, Train Acc: 75.00%, Val Loss: 0.7081, Val Acc: 70.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.4917, Train Acc: 82.50%, Val Loss: 0.7281, Val Acc: 70.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.4526, Train Acc: 77.50%, Val Loss: 0.7285, Val Acc: 70.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.4402, Train Acc: 82.50%, Val Loss: 0.7241, Val Acc: 70.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.4652, Train Acc: 75.00%, Val Loss: 0.6920, Val Acc: 70.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.3532, Train Acc: 82.50%, Val Loss: 0.6983, Val Acc: 70.00%\n",
            "Starting epoch 30\n",
            "Train Loss: 0.4336, Train Acc: 75.00%, Val Loss: 0.6952, Val Acc: 70.00%\n",
            "Early stopping triggered.\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 1.4446, Train Acc: 57.50%, Val Loss: 15.6496, Val Acc: 70.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 1.7664, Train Acc: 60.00%, Val Loss: 1.1199, Val Acc: 70.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 1.2073, Train Acc: 62.50%, Val Loss: 0.4106, Val Acc: 80.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 0.8105, Train Acc: 72.50%, Val Loss: 0.6212, Val Acc: 80.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 1.0008, Train Acc: 75.00%, Val Loss: 1.1036, Val Acc: 70.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.8415, Train Acc: 67.50%, Val Loss: 0.6128, Val Acc: 70.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.6092, Train Acc: 70.00%, Val Loss: 0.6838, Val Acc: 60.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.9118, Train Acc: 52.50%, Val Loss: 0.5406, Val Acc: 70.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.5141, Train Acc: 77.50%, Val Loss: 0.4869, Val Acc: 70.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 1.1519, Train Acc: 65.00%, Val Loss: 0.5678, Val Acc: 70.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 1.1708, Train Acc: 70.00%, Val Loss: 0.6936, Val Acc: 70.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.8077, Train Acc: 77.50%, Val Loss: 0.6713, Val Acc: 70.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.7038, Train Acc: 72.50%, Val Loss: 0.6363, Val Acc: 70.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.9604, Train Acc: 67.50%, Val Loss: 0.6555, Val Acc: 70.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.8569, Train Acc: 57.50%, Val Loss: 0.6661, Val Acc: 70.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.5659, Train Acc: 82.50%, Val Loss: 0.6738, Val Acc: 70.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.9920, Train Acc: 65.00%, Val Loss: 0.6151, Val Acc: 70.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.9407, Train Acc: 70.00%, Val Loss: 0.6157, Val Acc: 70.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 1.3168, Train Acc: 65.00%, Val Loss: 0.6479, Val Acc: 70.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.9630, Train Acc: 72.50%, Val Loss: 0.6182, Val Acc: 70.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.8140, Train Acc: 70.00%, Val Loss: 0.6370, Val Acc: 70.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.6583, Train Acc: 72.50%, Val Loss: 0.6390, Val Acc: 70.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.5270, Train Acc: 77.50%, Val Loss: 0.6696, Val Acc: 70.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.9596, Train Acc: 65.00%, Val Loss: 0.6558, Val Acc: 70.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.7958, Train Acc: 67.50%, Val Loss: 0.6475, Val Acc: 70.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.7326, Train Acc: 65.00%, Val Loss: 0.6353, Val Acc: 70.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.5075, Train Acc: 77.50%, Val Loss: 0.6462, Val Acc: 70.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.6355, Train Acc: 70.00%, Val Loss: 0.6582, Val Acc: 70.00%\n",
            "Early stopping triggered.\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 1.5682, Train Acc: 42.50%, Val Loss: 3.0077, Val Acc: 70.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.8816, Train Acc: 65.00%, Val Loss: 2.1984, Val Acc: 30.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 0.9361, Train Acc: 62.50%, Val Loss: 0.3498, Val Acc: 80.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 1.0867, Train Acc: 65.00%, Val Loss: 0.3372, Val Acc: 80.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.8609, Train Acc: 67.50%, Val Loss: 1.4173, Val Acc: 50.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.6725, Train Acc: 65.00%, Val Loss: 1.1454, Val Acc: 50.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.9633, Train Acc: 65.00%, Val Loss: 0.5337, Val Acc: 70.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.6535, Train Acc: 70.00%, Val Loss: 0.5347, Val Acc: 70.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.6185, Train Acc: 70.00%, Val Loss: 0.4646, Val Acc: 80.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.4427, Train Acc: 80.00%, Val Loss: 0.5360, Val Acc: 70.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.9457, Train Acc: 65.00%, Val Loss: 0.6974, Val Acc: 60.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.7541, Train Acc: 60.00%, Val Loss: 0.6000, Val Acc: 70.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.7292, Train Acc: 60.00%, Val Loss: 0.5575, Val Acc: 70.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.3713, Train Acc: 85.00%, Val Loss: 0.5738, Val Acc: 70.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.5341, Train Acc: 72.50%, Val Loss: 0.5942, Val Acc: 70.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.6960, Train Acc: 70.00%, Val Loss: 0.6279, Val Acc: 70.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.4967, Train Acc: 80.00%, Val Loss: 0.5772, Val Acc: 70.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.4736, Train Acc: 80.00%, Val Loss: 0.5797, Val Acc: 70.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.6957, Train Acc: 70.00%, Val Loss: 0.5565, Val Acc: 70.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.8675, Train Acc: 65.00%, Val Loss: 0.5796, Val Acc: 70.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.5918, Train Acc: 72.50%, Val Loss: 0.6014, Val Acc: 70.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.7134, Train Acc: 72.50%, Val Loss: 0.6272, Val Acc: 70.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.4353, Train Acc: 82.50%, Val Loss: 0.5906, Val Acc: 70.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.3399, Train Acc: 87.50%, Val Loss: 0.5886, Val Acc: 70.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.5343, Train Acc: 82.50%, Val Loss: 0.6002, Val Acc: 70.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.5629, Train Acc: 80.00%, Val Loss: 0.6076, Val Acc: 70.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.5464, Train Acc: 75.00%, Val Loss: 0.6197, Val Acc: 70.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.5527, Train Acc: 90.00%, Val Loss: 0.6213, Val Acc: 70.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.8782, Train Acc: 65.00%, Val Loss: 0.5939, Val Acc: 70.00%\n",
            "Early stopping triggered.\n",
            "--------------------------------\n",
            "Best validation accuracy of 0.00% achieved, model saved as CNN_best_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomCNN().to(device)\n",
        "model.load_state_dict(torch.load('CNN_best_model.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d26EESam0Ra_",
        "outputId": "bb7faa36-295d-424d-b80e-b579788aa64a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_indices = [i for i, (_, label) in enumerate(testset) if label in selected_classes]\n",
        "N = 1000\n",
        "class_counts = {label: 0 for label in selected_classes}\n",
        "filtered_train_indices = []\n",
        "\n",
        "for i in test_indices:\n",
        "    _, label = testset[i]\n",
        "    if class_counts[label] < N:\n",
        "        filtered_train_indices.append(i)\n",
        "        class_counts[label] += 1\n",
        "\n",
        "test_subset = Subset(testset, filtered_train_indices)\n",
        "test_loader = DataLoader(test_subset, batch_size=50, shuffle=False)"
      ],
      "metadata": {
        "id": "Q4lA20QG0VDj"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Assuming the test_loader and the device are already defined\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Evaluation\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# No gradient is needed for evaluation\n",
        "with torch.no_grad():\n",
        "    for data, targets in test_loader:\n",
        "        # Move data and targets to the correct device\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Compute the model output\n",
        "        output = model(data)\n",
        "        loss = criterion(output, targets)\n",
        "\n",
        "        # Accumulate the loss and calculate accuracy\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "# Calculate average loss and accuracy percentage\n",
        "Custom_CNN_avg_loss = test_loss / len(test_loader)\n",
        "Custom_CNN_accuracy = 100. * correct / total\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f'Test Loss: {Custom_CNN_avg_loss:.4f}, Test Accuracy: {Custom_CNN_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U04_oE20Xoy",
        "outputId": "53eb3d34-d712-475a-87db-541324181c70"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.3441, Test Accuracy: 86.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIT"
      ],
      "metadata": {
        "id": "XebeXoNM08xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "metadata": {
        "id": "Z6rplEZO1LtQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(224, padding=4),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
        "])"
      ],
      "metadata": {
        "id": "GSqrt1sI1kYn"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vit_b_16(pretrained=False)\n",
        "\n",
        "num_classes = 10\n",
        "dropout_rate = 0.5\n",
        "\n",
        "model.heads = nn.Sequential(\n",
        "    nn.Dropout(p=dropout_rate),\n",
        "    nn.Linear(model.heads[0].in_features, num_classes)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0eZmkGO08gt",
        "outputId": "a31edffc-9ec2-4544-e88f-b63b9b1f6d2e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_accuracy = 0\n",
        "best_model_weights = None"
      ],
      "metadata": {
        "id": "Spq1rIw20qNS"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold, (train_ids, val_ids) in enumerate(kfold.split(trainset)):\n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "\n",
        "    train_indices = [i for i, (_, label) in enumerate(trainset) if label in selected_classes]\n",
        "\n",
        "    N = 25\n",
        "    class_counts = {label: 0 for label in selected_classes}\n",
        "    filtered_train_indices = []\n",
        "\n",
        "    for i in train_indices:\n",
        "        _, label = trainset[i]\n",
        "        if class_counts[label] < N:\n",
        "            filtered_train_indices.append(i)\n",
        "            class_counts[label] += 1\n",
        "\n",
        "\n",
        "    np.random.seed(42)\n",
        "    np.random.shuffle(filtered_train_indices)\n",
        "    split = int(0.8 * len(filtered_train_indices))\n",
        "    train_idx, val_idx = filtered_train_indices[:split], filtered_train_indices[split:]\n",
        "\n",
        "    train_subset = Subset(trainset, train_idx)\n",
        "    transformed_train_subset = TransformSubset(train_subset, transform=train_transform)\n",
        "\n",
        "    val_subset = Subset(trainset, val_idx)\n",
        "    transformed_val_subset = TransformSubset(val_subset, transform=test_transform)\n",
        "\n",
        "    train_loader = DataLoader(transformed_train_subset, batch_size=5, shuffle=True)\n",
        "    val_loader = DataLoader(transformed_val_subset, batch_size=5, shuffle=False)\n",
        "\n",
        "\n",
        "    # Init the neural network\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Initialize optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=2e-5, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    patience = 25\n",
        "\n",
        "\n",
        "    # Run the training loop for defined number of epochs\n",
        "    num_epochs = 50\n",
        "    for epoch in range(num_epochs):\n",
        "        # Print epoch\n",
        "        print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "        # Perform training and validation\n",
        "        train_loss, train_accuracy = train(model, device, train_loader, optimizer, criterion)\n",
        "        val_loss, val_accuracy = validate(model, device, val_loader, criterion)\n",
        "\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
        "\n",
        "        # Save the model if it has the best val accuracy so far\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_weights = model.state_dict().copy()  # Save the best model weights\n",
        "            patience_counter = 0  # Reset patience\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break  # Stop training if no improvement\n",
        "\n",
        "        # Step the learning rate scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "    print('--------------------------------')\n",
        "\n",
        "# Save the best model weights\n",
        "torch.save(best_model_weights, 'VIT_best_model.pth')\n",
        "print(f'Best validation accuracy of {best_val_accuracy:.2f}% achieved, model saved as VIT_best_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP-3mRNA1V0w",
        "outputId": "7c2014c2-26fb-42be-e86e-6740dc41679b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 0\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 1.7342, Train Acc: 45.00%, Val Loss: 0.5150, Val Acc: 80.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.8953, Train Acc: 75.00%, Val Loss: 1.3709, Val Acc: 60.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 0.6972, Train Acc: 75.00%, Val Loss: 0.8361, Val Acc: 80.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 0.5429, Train Acc: 77.50%, Val Loss: 0.5366, Val Acc: 90.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.4767, Train Acc: 75.00%, Val Loss: 0.7198, Val Acc: 70.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.3835, Train Acc: 87.50%, Val Loss: 0.5894, Val Acc: 70.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.4077, Train Acc: 87.50%, Val Loss: 0.5540, Val Acc: 70.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.4136, Train Acc: 80.00%, Val Loss: 0.6259, Val Acc: 70.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.4256, Train Acc: 85.00%, Val Loss: 0.4823, Val Acc: 90.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.3953, Train Acc: 87.50%, Val Loss: 0.7291, Val Acc: 70.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.4295, Train Acc: 80.00%, Val Loss: 0.4934, Val Acc: 80.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.3164, Train Acc: 82.50%, Val Loss: 0.4562, Val Acc: 70.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.2407, Train Acc: 90.00%, Val Loss: 0.4193, Val Acc: 80.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.2383, Train Acc: 90.00%, Val Loss: 0.3972, Val Acc: 80.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.3632, Train Acc: 87.50%, Val Loss: 0.4216, Val Acc: 70.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.2571, Train Acc: 90.00%, Val Loss: 0.3216, Val Acc: 80.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.2423, Train Acc: 90.00%, Val Loss: 0.3472, Val Acc: 80.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.2046, Train Acc: 90.00%, Val Loss: 0.3567, Val Acc: 80.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.2318, Train Acc: 90.00%, Val Loss: 0.3305, Val Acc: 80.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.2046, Train Acc: 90.00%, Val Loss: 0.3350, Val Acc: 80.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.3331, Train Acc: 90.00%, Val Loss: 0.3257, Val Acc: 80.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.2191, Train Acc: 95.00%, Val Loss: 0.3078, Val Acc: 80.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.1895, Train Acc: 95.00%, Val Loss: 0.2310, Val Acc: 90.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.1269, Train Acc: 97.50%, Val Loss: 0.2345, Val Acc: 90.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.2759, Train Acc: 90.00%, Val Loss: 0.3782, Val Acc: 80.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.1579, Train Acc: 97.50%, Val Loss: 0.3663, Val Acc: 80.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.1707, Train Acc: 95.00%, Val Loss: 0.2227, Val Acc: 90.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.1479, Train Acc: 95.00%, Val Loss: 0.2569, Val Acc: 80.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.1904, Train Acc: 92.50%, Val Loss: 0.2694, Val Acc: 80.00%\n",
            "Starting epoch 30\n",
            "Train Loss: 0.2262, Train Acc: 92.50%, Val Loss: 0.2293, Val Acc: 80.00%\n",
            "Starting epoch 31\n",
            "Train Loss: 0.1429, Train Acc: 97.50%, Val Loss: 0.2140, Val Acc: 80.00%\n",
            "Starting epoch 32\n",
            "Train Loss: 0.1636, Train Acc: 95.00%, Val Loss: 0.2348, Val Acc: 80.00%\n",
            "Starting epoch 33\n",
            "Train Loss: 0.1622, Train Acc: 95.00%, Val Loss: 0.2744, Val Acc: 80.00%\n",
            "Starting epoch 34\n",
            "Train Loss: 0.1651, Train Acc: 92.50%, Val Loss: 0.2558, Val Acc: 80.00%\n",
            "Starting epoch 35\n",
            "Train Loss: 0.1774, Train Acc: 95.00%, Val Loss: 0.2440, Val Acc: 80.00%\n",
            "Starting epoch 36\n",
            "Train Loss: 0.1785, Train Acc: 95.00%, Val Loss: 0.2527, Val Acc: 80.00%\n",
            "Starting epoch 37\n",
            "Train Loss: 0.1268, Train Acc: 95.00%, Val Loss: 0.2157, Val Acc: 80.00%\n",
            "Starting epoch 38\n",
            "Train Loss: 0.1050, Train Acc: 100.00%, Val Loss: 0.1968, Val Acc: 90.00%\n",
            "Starting epoch 39\n",
            "Train Loss: 0.1458, Train Acc: 95.00%, Val Loss: 0.1821, Val Acc: 90.00%\n",
            "Starting epoch 40\n",
            "Train Loss: 0.0737, Train Acc: 100.00%, Val Loss: 0.1894, Val Acc: 80.00%\n",
            "Starting epoch 41\n",
            "Train Loss: 0.1064, Train Acc: 97.50%, Val Loss: 0.2142, Val Acc: 80.00%\n",
            "Starting epoch 42\n",
            "Train Loss: 0.1605, Train Acc: 95.00%, Val Loss: 0.2256, Val Acc: 80.00%\n",
            "Starting epoch 43\n",
            "Train Loss: 0.0737, Train Acc: 97.50%, Val Loss: 0.2510, Val Acc: 80.00%\n",
            "Starting epoch 44\n",
            "Train Loss: 0.1604, Train Acc: 95.00%, Val Loss: 0.2550, Val Acc: 80.00%\n",
            "Starting epoch 45\n",
            "Train Loss: 0.1401, Train Acc: 95.00%, Val Loss: 0.2531, Val Acc: 80.00%\n",
            "Starting epoch 46\n",
            "Train Loss: 0.1443, Train Acc: 95.00%, Val Loss: 0.2310, Val Acc: 80.00%\n",
            "Starting epoch 47\n",
            "Train Loss: 0.1868, Train Acc: 95.00%, Val Loss: 0.2524, Val Acc: 80.00%\n",
            "Starting epoch 48\n",
            "Train Loss: 0.1308, Train Acc: 95.00%, Val Loss: 0.2698, Val Acc: 90.00%\n",
            "Starting epoch 49\n",
            "Train Loss: 0.1132, Train Acc: 95.00%, Val Loss: 0.2762, Val Acc: 90.00%\n",
            "Starting epoch 50\n",
            "Train Loss: 0.1596, Train Acc: 92.50%, Val Loss: 0.2837, Val Acc: 90.00%\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 0.7317, Train Acc: 80.00%, Val Loss: 0.4026, Val Acc: 80.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.5828, Train Acc: 80.00%, Val Loss: 0.7362, Val Acc: 70.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 0.3696, Train Acc: 85.00%, Val Loss: 0.1758, Val Acc: 100.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 0.2957, Train Acc: 82.50%, Val Loss: 0.3766, Val Acc: 80.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.3360, Train Acc: 87.50%, Val Loss: 0.2486, Val Acc: 90.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.2648, Train Acc: 90.00%, Val Loss: 0.3914, Val Acc: 80.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.2384, Train Acc: 87.50%, Val Loss: 0.4305, Val Acc: 80.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.1340, Train Acc: 95.00%, Val Loss: 0.3321, Val Acc: 80.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.1344, Train Acc: 95.00%, Val Loss: 0.2874, Val Acc: 90.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.3228, Train Acc: 92.50%, Val Loss: 0.1415, Val Acc: 90.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.2348, Train Acc: 92.50%, Val Loss: 0.2073, Val Acc: 80.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.1458, Train Acc: 95.00%, Val Loss: 0.2782, Val Acc: 80.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.0829, Train Acc: 97.50%, Val Loss: 0.1841, Val Acc: 90.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.1797, Train Acc: 97.50%, Val Loss: 0.1684, Val Acc: 90.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.1051, Train Acc: 97.50%, Val Loss: 0.0937, Val Acc: 100.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.0664, Train Acc: 100.00%, Val Loss: 0.0819, Val Acc: 100.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.0598, Train Acc: 97.50%, Val Loss: 0.0738, Val Acc: 100.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.1229, Train Acc: 92.50%, Val Loss: 0.0920, Val Acc: 90.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.1364, Train Acc: 95.00%, Val Loss: 0.1746, Val Acc: 90.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.1044, Train Acc: 95.00%, Val Loss: 0.2058, Val Acc: 90.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.1613, Train Acc: 95.00%, Val Loss: 0.1171, Val Acc: 90.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.0618, Train Acc: 100.00%, Val Loss: 0.0880, Val Acc: 100.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.1323, Train Acc: 95.00%, Val Loss: 0.1775, Val Acc: 90.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.1106, Train Acc: 95.00%, Val Loss: 0.1861, Val Acc: 90.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.0719, Train Acc: 97.50%, Val Loss: 0.0953, Val Acc: 100.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.0692, Train Acc: 100.00%, Val Loss: 0.0809, Val Acc: 100.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.0573, Train Acc: 97.50%, Val Loss: 0.0898, Val Acc: 100.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.0424, Train Acc: 100.00%, Val Loss: 0.0680, Val Acc: 100.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.0200, Train Acc: 100.00%, Val Loss: 0.0578, Val Acc: 100.00%\n",
            "Starting epoch 30\n",
            "Train Loss: 0.0388, Train Acc: 100.00%, Val Loss: 0.0550, Val Acc: 100.00%\n",
            "Starting epoch 31\n",
            "Train Loss: 0.0518, Train Acc: 97.50%, Val Loss: 0.0581, Val Acc: 100.00%\n",
            "Starting epoch 32\n",
            "Train Loss: 0.0427, Train Acc: 97.50%, Val Loss: 0.0618, Val Acc: 100.00%\n",
            "Starting epoch 33\n",
            "Train Loss: 0.0448, Train Acc: 100.00%, Val Loss: 0.0578, Val Acc: 100.00%\n",
            "Starting epoch 34\n",
            "Train Loss: 0.0930, Train Acc: 97.50%, Val Loss: 0.0955, Val Acc: 100.00%\n",
            "Starting epoch 35\n",
            "Train Loss: 0.0777, Train Acc: 95.00%, Val Loss: 0.1232, Val Acc: 90.00%\n",
            "Starting epoch 36\n",
            "Train Loss: 0.0863, Train Acc: 97.50%, Val Loss: 0.0782, Val Acc: 100.00%\n",
            "Starting epoch 37\n",
            "Train Loss: 0.0251, Train Acc: 100.00%, Val Loss: 0.0512, Val Acc: 100.00%\n",
            "Starting epoch 38\n",
            "Train Loss: 0.0997, Train Acc: 95.00%, Val Loss: 0.2304, Val Acc: 90.00%\n",
            "Starting epoch 39\n",
            "Train Loss: 0.0352, Train Acc: 97.50%, Val Loss: 0.2901, Val Acc: 90.00%\n",
            "Starting epoch 40\n",
            "Train Loss: 0.0185, Train Acc: 100.00%, Val Loss: 0.3062, Val Acc: 90.00%\n",
            "Starting epoch 41\n",
            "Train Loss: 0.1261, Train Acc: 95.00%, Val Loss: 0.2421, Val Acc: 90.00%\n",
            "Starting epoch 42\n",
            "Train Loss: 0.0225, Train Acc: 100.00%, Val Loss: 0.2238, Val Acc: 90.00%\n",
            "Starting epoch 43\n",
            "Train Loss: 0.0386, Train Acc: 100.00%, Val Loss: 0.2031, Val Acc: 90.00%\n",
            "Starting epoch 44\n",
            "Train Loss: 0.0431, Train Acc: 100.00%, Val Loss: 0.1808, Val Acc: 90.00%\n",
            "Starting epoch 45\n",
            "Train Loss: 0.0189, Train Acc: 100.00%, Val Loss: 0.1564, Val Acc: 90.00%\n",
            "Starting epoch 46\n",
            "Train Loss: 0.0109, Train Acc: 100.00%, Val Loss: 0.1418, Val Acc: 90.00%\n",
            "Starting epoch 47\n",
            "Train Loss: 0.0139, Train Acc: 100.00%, Val Loss: 0.1356, Val Acc: 90.00%\n",
            "Starting epoch 48\n",
            "Train Loss: 0.0256, Train Acc: 100.00%, Val Loss: 0.1243, Val Acc: 90.00%\n",
            "Starting epoch 49\n",
            "Train Loss: 0.0162, Train Acc: 100.00%, Val Loss: 0.1173, Val Acc: 90.00%\n",
            "Starting epoch 50\n",
            "Train Loss: 0.0247, Train Acc: 100.00%, Val Loss: 0.0868, Val Acc: 100.00%\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 0.3372, Train Acc: 92.50%, Val Loss: 0.0662, Val Acc: 100.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.1707, Train Acc: 95.00%, Val Loss: 0.0710, Val Acc: 100.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 0.2315, Train Acc: 87.50%, Val Loss: 0.0307, Val Acc: 100.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 0.3373, Train Acc: 95.00%, Val Loss: 0.0614, Val Acc: 100.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.2427, Train Acc: 92.50%, Val Loss: 0.1183, Val Acc: 90.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.0865, Train Acc: 97.50%, Val Loss: 0.0894, Val Acc: 100.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.1205, Train Acc: 92.50%, Val Loss: 0.1274, Val Acc: 100.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.1247, Train Acc: 95.00%, Val Loss: 0.0539, Val Acc: 100.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.0582, Train Acc: 97.50%, Val Loss: 0.1000, Val Acc: 90.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.0670, Train Acc: 97.50%, Val Loss: 0.1130, Val Acc: 90.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.0293, Train Acc: 97.50%, Val Loss: 0.0318, Val Acc: 100.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.0114, Train Acc: 100.00%, Val Loss: 0.0165, Val Acc: 100.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.0564, Train Acc: 97.50%, Val Loss: 0.0189, Val Acc: 100.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.0812, Train Acc: 95.00%, Val Loss: 0.0282, Val Acc: 100.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.0576, Train Acc: 97.50%, Val Loss: 0.0298, Val Acc: 100.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.0478, Train Acc: 97.50%, Val Loss: 0.0392, Val Acc: 100.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.0216, Train Acc: 100.00%, Val Loss: 0.0473, Val Acc: 100.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.0291, Train Acc: 100.00%, Val Loss: 0.0264, Val Acc: 100.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.0323, Train Acc: 97.50%, Val Loss: 0.0933, Val Acc: 90.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.0220, Train Acc: 100.00%, Val Loss: 0.2491, Val Acc: 90.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.0092, Train Acc: 100.00%, Val Loss: 0.2380, Val Acc: 90.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.0084, Train Acc: 100.00%, Val Loss: 0.2031, Val Acc: 90.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.0542, Train Acc: 97.50%, Val Loss: 0.1558, Val Acc: 90.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.0147, Train Acc: 100.00%, Val Loss: 0.2293, Val Acc: 90.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.0084, Train Acc: 100.00%, Val Loss: 0.1808, Val Acc: 90.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.0807, Train Acc: 97.50%, Val Loss: 0.1655, Val Acc: 90.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.0123, Train Acc: 100.00%, Val Loss: 0.1714, Val Acc: 90.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.0309, Train Acc: 100.00%, Val Loss: 0.0683, Val Acc: 100.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.0181, Train Acc: 100.00%, Val Loss: 0.0155, Val Acc: 100.00%\n",
            "Starting epoch 30\n",
            "Train Loss: 0.0021, Train Acc: 100.00%, Val Loss: 0.0083, Val Acc: 100.00%\n",
            "Starting epoch 31\n",
            "Train Loss: 0.0195, Train Acc: 100.00%, Val Loss: 0.0077, Val Acc: 100.00%\n",
            "Starting epoch 32\n",
            "Train Loss: 0.0381, Train Acc: 97.50%, Val Loss: 0.0097, Val Acc: 100.00%\n",
            "Starting epoch 33\n",
            "Train Loss: 0.0203, Train Acc: 97.50%, Val Loss: 0.0126, Val Acc: 100.00%\n",
            "Starting epoch 34\n",
            "Train Loss: 0.0258, Train Acc: 97.50%, Val Loss: 0.0076, Val Acc: 100.00%\n",
            "Starting epoch 35\n",
            "Train Loss: 0.0200, Train Acc: 100.00%, Val Loss: 0.0067, Val Acc: 100.00%\n",
            "Starting epoch 36\n",
            "Train Loss: 0.0364, Train Acc: 97.50%, Val Loss: 0.0098, Val Acc: 100.00%\n",
            "Starting epoch 37\n",
            "Train Loss: 0.0143, Train Acc: 100.00%, Val Loss: 0.0298, Val Acc: 100.00%\n",
            "Starting epoch 38\n",
            "Train Loss: 0.0135, Train Acc: 100.00%, Val Loss: 0.0251, Val Acc: 100.00%\n",
            "Starting epoch 39\n",
            "Train Loss: 0.0039, Train Acc: 100.00%, Val Loss: 0.0190, Val Acc: 100.00%\n",
            "Starting epoch 40\n",
            "Train Loss: 0.0038, Train Acc: 100.00%, Val Loss: 0.0166, Val Acc: 100.00%\n",
            "Starting epoch 41\n",
            "Train Loss: 0.0061, Train Acc: 100.00%, Val Loss: 0.0161, Val Acc: 100.00%\n",
            "Starting epoch 42\n",
            "Train Loss: 0.0087, Train Acc: 100.00%, Val Loss: 0.0156, Val Acc: 100.00%\n",
            "Starting epoch 43\n",
            "Train Loss: 0.0087, Train Acc: 100.00%, Val Loss: 0.0148, Val Acc: 100.00%\n",
            "Starting epoch 44\n",
            "Train Loss: 0.0047, Train Acc: 100.00%, Val Loss: 0.0141, Val Acc: 100.00%\n",
            "Starting epoch 45\n",
            "Train Loss: 0.0078, Train Acc: 100.00%, Val Loss: 0.0130, Val Acc: 100.00%\n",
            "Starting epoch 46\n",
            "Train Loss: 0.0047, Train Acc: 100.00%, Val Loss: 0.0120, Val Acc: 100.00%\n",
            "Starting epoch 47\n",
            "Train Loss: 0.0033, Train Acc: 100.00%, Val Loss: 0.0116, Val Acc: 100.00%\n",
            "Starting epoch 48\n",
            "Train Loss: 0.0046, Train Acc: 100.00%, Val Loss: 0.0112, Val Acc: 100.00%\n",
            "Starting epoch 49\n",
            "Train Loss: 0.0061, Train Acc: 100.00%, Val Loss: 0.0109, Val Acc: 100.00%\n",
            "Starting epoch 50\n",
            "Train Loss: 0.0045, Train Acc: 100.00%, Val Loss: 0.0105, Val Acc: 100.00%\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 0.0274, Train Acc: 97.50%, Val Loss: 1.1271, Val Acc: 80.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.3128, Train Acc: 87.50%, Val Loss: 0.0073, Val Acc: 100.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 0.0580, Train Acc: 97.50%, Val Loss: 0.0191, Val Acc: 100.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 0.1141, Train Acc: 92.50%, Val Loss: 0.0010, Val Acc: 100.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.0146, Train Acc: 100.00%, Val Loss: 0.0043, Val Acc: 100.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.0135, Train Acc: 100.00%, Val Loss: 0.1543, Val Acc: 90.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.2200, Train Acc: 97.50%, Val Loss: 0.0245, Val Acc: 100.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.0205, Train Acc: 100.00%, Val Loss: 0.0016, Val Acc: 100.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.0351, Train Acc: 97.50%, Val Loss: 0.0026, Val Acc: 100.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.0167, Train Acc: 100.00%, Val Loss: 0.0044, Val Acc: 100.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.0097, Train Acc: 100.00%, Val Loss: 0.0021, Val Acc: 100.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.0028, Train Acc: 100.00%, Val Loss: 0.0016, Val Acc: 100.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.0859, Train Acc: 97.50%, Val Loss: 0.0014, Val Acc: 100.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.0240, Train Acc: 97.50%, Val Loss: 0.0075, Val Acc: 100.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.0106, Train Acc: 100.00%, Val Loss: 0.0141, Val Acc: 100.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.0122, Train Acc: 100.00%, Val Loss: 0.0106, Val Acc: 100.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.0026, Train Acc: 100.00%, Val Loss: 0.0088, Val Acc: 100.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.0225, Train Acc: 100.00%, Val Loss: 0.0077, Val Acc: 100.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.0361, Train Acc: 97.50%, Val Loss: 0.0038, Val Acc: 100.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.0067, Train Acc: 100.00%, Val Loss: 0.0010, Val Acc: 100.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.0019, Train Acc: 100.00%, Val Loss: 0.0008, Val Acc: 100.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.0222, Train Acc: 97.50%, Val Loss: 0.0008, Val Acc: 100.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.0051, Train Acc: 100.00%, Val Loss: 0.0017, Val Acc: 100.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.0079, Train Acc: 100.00%, Val Loss: 0.0014, Val Acc: 100.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.0030, Train Acc: 100.00%, Val Loss: 0.0011, Val Acc: 100.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.0030, Train Acc: 100.00%, Val Loss: 0.0009, Val Acc: 100.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.0089, Train Acc: 100.00%, Val Loss: 0.0006, Val Acc: 100.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.0039, Train Acc: 100.00%, Val Loss: 0.0005, Val Acc: 100.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.0051, Train Acc: 100.00%, Val Loss: 0.0005, Val Acc: 100.00%\n",
            "Starting epoch 30\n",
            "Train Loss: 0.0031, Train Acc: 100.00%, Val Loss: 0.0005, Val Acc: 100.00%\n",
            "Starting epoch 31\n",
            "Train Loss: 0.0031, Train Acc: 100.00%, Val Loss: 0.0005, Val Acc: 100.00%\n",
            "Starting epoch 32\n",
            "Train Loss: 0.0102, Train Acc: 100.00%, Val Loss: 0.0006, Val Acc: 100.00%\n",
            "Starting epoch 33\n",
            "Train Loss: 0.0116, Train Acc: 100.00%, Val Loss: 0.0009, Val Acc: 100.00%\n",
            "Starting epoch 34\n",
            "Train Loss: 0.0018, Train Acc: 100.00%, Val Loss: 0.0011, Val Acc: 100.00%\n",
            "Starting epoch 35\n",
            "Train Loss: 0.0049, Train Acc: 100.00%, Val Loss: 0.0011, Val Acc: 100.00%\n",
            "Starting epoch 36\n",
            "Train Loss: 0.0013, Train Acc: 100.00%, Val Loss: 0.0010, Val Acc: 100.00%\n",
            "Starting epoch 37\n",
            "Train Loss: 0.0014, Train Acc: 100.00%, Val Loss: 0.0010, Val Acc: 100.00%\n",
            "Starting epoch 38\n",
            "Train Loss: 0.0015, Train Acc: 100.00%, Val Loss: 0.0009, Val Acc: 100.00%\n",
            "Starting epoch 39\n",
            "Train Loss: 0.0011, Train Acc: 100.00%, Val Loss: 0.0009, Val Acc: 100.00%\n",
            "Starting epoch 40\n",
            "Train Loss: 0.0805, Train Acc: 97.50%, Val Loss: 0.0021, Val Acc: 100.00%\n",
            "Starting epoch 41\n",
            "Train Loss: 0.0107, Train Acc: 100.00%, Val Loss: 0.0036, Val Acc: 100.00%\n",
            "Starting epoch 42\n",
            "Train Loss: 0.0053, Train Acc: 100.00%, Val Loss: 0.0046, Val Acc: 100.00%\n",
            "Starting epoch 43\n",
            "Train Loss: 0.0031, Train Acc: 100.00%, Val Loss: 0.0048, Val Acc: 100.00%\n",
            "Starting epoch 44\n",
            "Train Loss: 0.0111, Train Acc: 100.00%, Val Loss: 0.0041, Val Acc: 100.00%\n",
            "Starting epoch 45\n",
            "Train Loss: 0.0024, Train Acc: 100.00%, Val Loss: 0.0033, Val Acc: 100.00%\n",
            "Starting epoch 46\n",
            "Train Loss: 0.0044, Train Acc: 100.00%, Val Loss: 0.0029, Val Acc: 100.00%\n",
            "Starting epoch 47\n",
            "Train Loss: 0.0022, Train Acc: 100.00%, Val Loss: 0.0027, Val Acc: 100.00%\n",
            "Starting epoch 48\n",
            "Train Loss: 0.0008, Train Acc: 100.00%, Val Loss: 0.0025, Val Acc: 100.00%\n",
            "Starting epoch 49\n",
            "Train Loss: 0.0048, Train Acc: 100.00%, Val Loss: 0.0024, Val Acc: 100.00%\n",
            "Starting epoch 50\n",
            "Train Loss: 0.0026, Train Acc: 100.00%, Val Loss: 0.0023, Val Acc: 100.00%\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Train Loss: 0.1392, Train Acc: 95.00%, Val Loss: 0.2538, Val Acc: 90.00%\n",
            "Starting epoch 2\n",
            "Train Loss: 0.0668, Train Acc: 97.50%, Val Loss: 0.0020, Val Acc: 100.00%\n",
            "Starting epoch 3\n",
            "Train Loss: 0.0261, Train Acc: 100.00%, Val Loss: 0.0020, Val Acc: 100.00%\n",
            "Starting epoch 4\n",
            "Train Loss: 0.1384, Train Acc: 92.50%, Val Loss: 0.0019, Val Acc: 100.00%\n",
            "Starting epoch 5\n",
            "Train Loss: 0.1625, Train Acc: 95.00%, Val Loss: 0.0135, Val Acc: 100.00%\n",
            "Starting epoch 6\n",
            "Train Loss: 0.0083, Train Acc: 100.00%, Val Loss: 0.1446, Val Acc: 90.00%\n",
            "Starting epoch 7\n",
            "Train Loss: 0.0597, Train Acc: 95.00%, Val Loss: 0.0041, Val Acc: 100.00%\n",
            "Starting epoch 8\n",
            "Train Loss: 0.1011, Train Acc: 97.50%, Val Loss: 0.0270, Val Acc: 100.00%\n",
            "Starting epoch 9\n",
            "Train Loss: 0.0537, Train Acc: 97.50%, Val Loss: 0.0057, Val Acc: 100.00%\n",
            "Starting epoch 10\n",
            "Train Loss: 0.2440, Train Acc: 95.00%, Val Loss: 0.0068, Val Acc: 100.00%\n",
            "Starting epoch 11\n",
            "Train Loss: 0.1045, Train Acc: 97.50%, Val Loss: 0.0076, Val Acc: 100.00%\n",
            "Starting epoch 12\n",
            "Train Loss: 0.0065, Train Acc: 100.00%, Val Loss: 0.0066, Val Acc: 100.00%\n",
            "Starting epoch 13\n",
            "Train Loss: 0.0071, Train Acc: 100.00%, Val Loss: 0.0070, Val Acc: 100.00%\n",
            "Starting epoch 14\n",
            "Train Loss: 0.0078, Train Acc: 100.00%, Val Loss: 0.0067, Val Acc: 100.00%\n",
            "Starting epoch 15\n",
            "Train Loss: 0.0150, Train Acc: 100.00%, Val Loss: 0.0188, Val Acc: 100.00%\n",
            "Starting epoch 16\n",
            "Train Loss: 0.0108, Train Acc: 100.00%, Val Loss: 0.0393, Val Acc: 100.00%\n",
            "Starting epoch 17\n",
            "Train Loss: 0.0052, Train Acc: 100.00%, Val Loss: 0.0547, Val Acc: 100.00%\n",
            "Starting epoch 18\n",
            "Train Loss: 0.0047, Train Acc: 100.00%, Val Loss: 0.0347, Val Acc: 100.00%\n",
            "Starting epoch 19\n",
            "Train Loss: 0.0041, Train Acc: 100.00%, Val Loss: 0.0212, Val Acc: 100.00%\n",
            "Starting epoch 20\n",
            "Train Loss: 0.0104, Train Acc: 100.00%, Val Loss: 0.0103, Val Acc: 100.00%\n",
            "Starting epoch 21\n",
            "Train Loss: 0.0183, Train Acc: 97.50%, Val Loss: 0.0089, Val Acc: 100.00%\n",
            "Starting epoch 22\n",
            "Train Loss: 0.0036, Train Acc: 100.00%, Val Loss: 0.0103, Val Acc: 100.00%\n",
            "Starting epoch 23\n",
            "Train Loss: 0.0197, Train Acc: 100.00%, Val Loss: 0.0128, Val Acc: 100.00%\n",
            "Starting epoch 24\n",
            "Train Loss: 0.0066, Train Acc: 100.00%, Val Loss: 0.0192, Val Acc: 100.00%\n",
            "Starting epoch 25\n",
            "Train Loss: 0.0007, Train Acc: 100.00%, Val Loss: 0.0248, Val Acc: 100.00%\n",
            "Starting epoch 26\n",
            "Train Loss: 0.0068, Train Acc: 100.00%, Val Loss: 0.0208, Val Acc: 100.00%\n",
            "Starting epoch 27\n",
            "Train Loss: 0.0050, Train Acc: 100.00%, Val Loss: 0.0180, Val Acc: 100.00%\n",
            "Starting epoch 28\n",
            "Train Loss: 0.0067, Train Acc: 100.00%, Val Loss: 0.0156, Val Acc: 100.00%\n",
            "Starting epoch 29\n",
            "Train Loss: 0.0009, Train Acc: 100.00%, Val Loss: 0.0143, Val Acc: 100.00%\n",
            "Early stopping triggered.\n",
            "--------------------------------\n",
            "Best validation accuracy of 0.00% achieved, model saved as VIT_best_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load('VIT_best_model.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWMb6wj110q0",
        "outputId": "3971950e-0bf2-401b-f8ac-7e8d4aba19b8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SkDQDL43-7i",
        "outputId": "d925eba2-6a32-424c-e9b7-7e50bb1b087c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_indices = [i for i, (_, label) in enumerate(testset) if label in selected_classes]\n",
        "N = 1000\n",
        "class_counts = {label: 0 for label in selected_classes}\n",
        "filtered_train_indices = []\n",
        "\n",
        "for i in test_indices:\n",
        "    _, label = testset[i]\n",
        "    if class_counts[label] < N:\n",
        "        filtered_train_indices.append(i)\n",
        "        class_counts[label] += 1\n",
        "\n",
        "test_subset = Subset(testset, filtered_train_indices)\n",
        "test_loader = DataLoader(test_subset, batch_size=50, shuffle=False)"
      ],
      "metadata": {
        "id": "cwgkb-K814jT"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Assuming the test_loader and the device are already defined\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Evaluation\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# No gradient is needed for evaluation\n",
        "with torch.no_grad():\n",
        "    for data, targets in test_loader:\n",
        "        # Move data and targets to the correct device\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Compute the model output\n",
        "        output = model(data)\n",
        "        loss = criterion(output, targets)\n",
        "\n",
        "        # Accumulate the loss and calculate accuracy\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "# Calculate average loss and accuracy percentage\n",
        "VIT_avg_loss = test_loss / len(test_loader)\n",
        "VIT_accuracy = 100. * correct / total\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f'Test Loss: {VIT_avg_loss:.4f}, Test Accuracy: {VIT_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RohrSzM819eo",
        "outputId": "ea604256-e91a-4102-8e11-637a83f399cc"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.7818, Test Accuracy: 86.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graphs"
      ],
      "metadata": {
        "id": "NVUnWfpS5Q6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_classes_mapping = {0: \"Cat\", 1: \"Dog\", 2: \"Bird\", 3: \"Horse\", 4: \"Ship\", 5: \"Truck\", 6: \"Frog\", 7: \"Airplane\", 8: \"Deer\", 9: \"Automobile\"}\n",
        "selected_classes = [selected_classes_mapping[class_num] for class_num in selected_classes]\n",
        "print(f'Randomly selected from CIFAR-10 are {selected_classes}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FATVgQSn6xRy",
        "outputId": "cd30e0e2-0409-424f-a15e-7056bcab7073"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomly selected from CIFAR-10 are ['Cat', 'Frog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "A502A3vS5SEq"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "bars = plt.bar(['SVM','XGBoost', 'Custom CNN', 'Vision Transformer'], [SVM_accuracy_vote_discrete*100,XGBoost_accuracy * 100, Custom_CNN_accuracy, VIT_accuracy], color=['red','blue', 'orange', 'green'])\n",
        "plt.title('Accuracy Comparison')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.ylim(0, 110)\n",
        "\n",
        "# Annotate bars with values\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval, round(yval, 2), va='bottom')\n",
        "\n",
        "# Loss comparison\n",
        "plt.subplot(1, 2, 2)\n",
        "bars = plt.bar(['Custom CNN', 'Vision Transformer'], [Custom_CNN_avg_loss, VIT_avg_loss], color=['orange', 'green'])\n",
        "plt.title('Average Loss Comparison')\n",
        "plt.ylabel('Average Loss')\n",
        "plt.ylim(0, 3.2)\n",
        "\n",
        "# Annotate bars with values\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval, round(yval, 2), va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "GalqyuQl5S8K",
        "outputId": "b092a639-fd1c-467d-f375-4805c4b58839"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}